<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>raptor&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://raptor1998.top/"/>
  <updated>2022-08-15T13:32:04.571Z</updated>
  <id>http://raptor1998.top/</id>
  
  <author>
    <name>陳 ？</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ByteStudy ipv4到ipv6改造</title>
    <link href="http://raptor1998.top/2022/08/16/ByteStudy%20ipv4%E5%88%B0ipv6%E6%94%B9%E9%80%A0/"/>
    <id>http://raptor1998.top/2022/08/16/ByteStudy%20ipv4%E5%88%B0ipv6%E6%94%B9%E9%80%A0/</id>
    <published>2022-08-15T16:00:00.000Z</published>
    <updated>2022-08-15T13:32:04.571Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="IPv6的3种表示方法"><a href="#IPv6的3种表示方法" class="headerlink" title="IPv6的3种表示方法"></a>IPv6的3种表示方法</h1><ol><li><p>冒分十六进制表示法<br> 格式为X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示，例如：</p> <div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">    　　ABCD:EF01:2345:6789:ABCD:EF01:2345:6789</span><br></pre></td></tr></tbody></table></figure></div><p> 　　这种表示法中，每个X的前导0是可以省略的，例如：</p> <div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">    　　2001:0DB8:0000:0023:0008:0800:200C:417A→ 2001:DB8:0:23:8:800:200C:417A</span><br></pre></td></tr></tbody></table></figure></div></li><li><p>0位压缩表示法<br> 在某些情况下，一个IPv6地址中间可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中”::”只能出现一次，例如：</p> <div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    　　FF01:0:0:0:0:0:0:1101 → FF01::1101</span><br><span class="line">    　　0:0:0:0:0:0:0:1 → ::1</span><br><span class="line">    　　0:0:0:0:0:0:0:0 → ::</span><br></pre></td></tr></tbody></table></figure></div></li><li><p>内嵌IPv4地址表示法</p><p> 为了实现IPv4-IPv6互通，IPv4地址会嵌入IPv6地址中，此时地址常表示为：X:X:X:X:X:X:d.d.d.d，前96b采用冒分十六进制表示，而最后32b地址则使用IPv4的点分十进制表示，例如::192.168.0.1与::FFFF:192.168.0.1就是两个典型的例子，注意在前96b中，压缩0位的方法依旧适用 。</p></li></ol><h1 id="过度技术"><a href="#过度技术" class="headerlink" title="过度技术"></a>过度技术</h1><h2 id="双栈技术"><a href="#双栈技术" class="headerlink" title="双栈技术"></a>双栈技术</h2><p>主机或路由器同时装有IPV4 和 IPV6两个协议栈，因此，主机既能和IPV4通信，也能和IPv6网络通信。</p><p>IPv6和IPv4是功能相近的网络层协议，两者都基于相同的物理平台，而且加载于其上的传输层协议TCP和UDP又没有任何区别。如果一台主机同时支持IPv6和IPv4两种协议，那么该主机既能与支持IPv4协议的主机通信，又能与支持IPv6协议的主机通信，这就是双协议栈技术的工作机理。</p><h2 id="隧道技术"><a href="#隧道技术" class="headerlink" title="隧道技术"></a>隧道技术</h2><p>在IPV6分组进入IPV4网络时，将IPV6分组封装成IPV4分组；当封装成IPV4分组离开IPV4网络时，再装数据部分（IPV6部分）转发给目的节点。</p><p>利用隧道技术可以通过现有的运行IPv4协议的Internet骨干网络（即隧道）将局部的IPv6网络连接起来，因而是IPv4向IPv6过渡的初期最易于采用的技术。路由器将IPv6的数据分组封装入IPv4，IPv4分组的源地址和目的地址分别是隧道入口和出口的IPv4地址。在隧道的出口处，再将IPv6分组取出转发给目的站点。</p><h2 id="协议翻译技术"><a href="#协议翻译技术" class="headerlink" title="协议翻译技术"></a>协议翻译技术</h2><p>对IPV6和IPV4报头时行相互翻译，实现IPV4/IPV6协议和地址的转换。</p><p>网络地址转换/协议转换技术 NAT-PT 通过与SIIT协议转换和传统的IPv4下的动态地址翻译（NAT）以及适当的应用层网关（ALG）相结合，实现了只安装了IPv6的主机和只安装了IPv4机器的大部分应用的相互通信。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://www.mfisp.com/6796.html" target="_blank" rel="noopener">详细对比IPv4与IPv6的区别 - 梦飞科技</a></p><p><a href="https://www.docin.com/p-2600732241.html" target="_blank" rel="noopener">浅析ＩＰｖ４到ＩＰｖ６的过渡技术（论文范文）</a></p><p><a href="https://blog.csdn.net/weixin_40228200/article/details/118737890" target="_blank" rel="noopener">IPv6-IPv4过渡技术详解及配置实例_永远是少年啊的博客-CSDN博客_ipv6toipv4</a></p><p><a href="https://blog.csdn.net/AIwenIPgeolocation/article/details/122925047" target="_blank" rel="noopener">从IPv4 到 IPv6 的过渡技术_AIwenIPgeolocation的博客-CSDN博客_ipv4到ipv6的过渡技术</a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy CICD</title>
    <link href="http://raptor1998.top/2022/08/12/ByteStudy%20CICD/"/>
    <id>http://raptor1998.top/2022/08/12/ByteStudy%20CICD/</id>
    <published>2022-08-11T16:00:00.000Z</published>
    <updated>2022-08-15T13:23:08.049Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152120447.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h1><blockquote><p>continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day.</p></blockquote><p><strong>频繁的（一天多次的）将所有开发者的工作合并到主干上。</strong></p><p><strong>优点：</strong></p><ul><li>易于定位错误：每一次的代码集成都需要执行相关的测试工作，持续集成频繁的集成次数天然的将复杂的代码逻辑切割为了小块，也就使得每一次测试中遇到的错误能够更加容易的被定位；</li><li>易于控制开发流程：更为细致的工作提交也就意味着更容易判断当前的工作进度，这对于管理者规划开发流程而言提供了一个有效的参考，同时也为开发人员省下了汇报工作的时间；</li><li>易于CodeReview：对于大块工作的切分自然也有助于做 CodeReview；</li><li>易于减少不必要的工作：build 以及 test 过程的自动化可以为你节约一大票的时间，从而投入到有价值的工作中去。<h1 id="持续交付"><a href="#持续交付" class="headerlink" title="持续交付"></a>持续交付</h1><blockquote><p>Continuous delivery (CD or CDE) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time and, when releasing the software, doing so manually.</p></blockquote></li></ul><p><strong>一种能够使得软件在较短的循环中可靠的发布的软件工程方法。</strong> </p><p>与持续集成相比，持续交付的侧重点在于 交付，其核心对象不在于代码，而在于可交付的产物。由于持续集成仅仅针对于新旧代码的集成过程执行了一定的测试，其变动到持续交付后还需要一些额外的流程。</p><h1 id="持续部署"><a href="#持续部署" class="headerlink" title="持续部署"></a>持续部署</h1><blockquote><p>Continuous deployment (CD) is a software engineering approach in which software functionalities are delivered frequently through automated deployments.</p></blockquote><p><strong>通过自动化部署的手段将软件功能频繁的进行交付。</strong></p><p>与持续交付以及持续集成相比，持续部署强调了通过 automated deployment 的手段，对新的软件功能进行集成。</p><h1 id="基础泳道的规范"><a href="#基础泳道的规范" class="headerlink" title="基础泳道的规范"></a>基础泳道的规范</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152120464.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://blog.csdn.net/xp178171640/article/details/124379156" target="_blank" rel="noopener">持续集成、持续交付、持续部署(转载)_xupeng1644的博客-CSDN博客_持续集成持续交付持续部署</a></p><p>CICD </p><p>基础泳道流程规范 </p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance Month 2</title>
    <link href="http://raptor1998.top/2022/08/10/ByteDance6/"/>
    <id>http://raptor1998.top/2022/08/10/ByteDance6/</id>
    <published>2022-08-09T16:00:00.000Z</published>
    <updated>2022-08-15T12:39:10.824Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="一期上线"><a href="#一期上线" class="headerlink" title="一期上线"></a>一期上线</h1><p>正式开始第三个月，新小组满一个月，比之前小组的工作多多了，目前这条线只有我一个QA，所以会接触的更多一点，在一期需求上线过程中也是充满坎坷，一个是不熟悉bug流程规范，导致这之间的数据没有记录，到最后写报告啥也没得写；二是参与的团队极多，协调起来比较困难；三是上线过程中遇到的问题贼多，由于算法的能力没法在线下环境验证，所以只能等上下游均ready后，直接一刀切，生产商验证能力，导致产生了很多脏数据，由于搜索中台不稳定，导致很多脏数据遗留在了es中；最后是提供的物料不满足预期，只能三四个人大半夜的手动去处理。。。。上了几个12点后的班，这辈子没这么累过，谁也顶不住</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208151950107.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="吐槽"><a href="#吐槽" class="headerlink" title="吐槽"></a>吐槽</h1><p>如果对于技术有追求，确实不适合来做QA，业务上的经验对于应届来讲实际意义不大，而且不断地有消息出来，整个部门一个hc都没有，最近准备开始回忆八股了，感觉有点晚了，没办法了，只能硬着头皮上了，准备这周末投几个试试水了，今年可太难了，去年字节8000+hc，今年3000+，实际可能只有1000+，说是政治任务，难顶。。。</p><h2 id="西湖晚霞"><a href="#西湖晚霞" class="headerlink" title="西湖晚霞"></a>西湖晚霞</h2><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208151951314.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208151951521.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"hotkey":true,"preload":"metadata","video":{"url":"https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208151952688.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script> </body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy filebeat原理</title>
    <link href="http://raptor1998.top/2022/08/05/ByteStudy%20filebeat%E5%8E%9F%E7%90%86/"/>
    <id>http://raptor1998.top/2022/08/05/ByteStudy%20filebeat%E5%8E%9F%E7%90%86/</id>
    <published>2022-08-04T16:00:00.000Z</published>
    <updated>2022-08-15T13:18:43.700Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><ol><li>配置输入源, 可以是日志(log), 也可以是标准输入(stdin), 可以配置多个输入(input)</li><li>为每个日志启一个(Harvester) 收集器, 将不停的读取数据</li><li>数据卷轴, 将数据不断的输出到其它终端</li><li>终端, 如 es, kafaka, redis</li></ol><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152115374.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>工作原理是启动 filebeat 时, 它将启动一个或多个输入, 这些输入将在日志数据指定位置中查找, 对于 filebeat 所找到的每个日志, filebeat 都会启动收集器, 每个收割机都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="harvester-收割机"><a href="#harvester-收割机" class="headerlink" title="harvester(收割机)"></a>harvester(收割机)</h2><p>harvester :负责读取单个文件的内容。读取每个文件，并将内容发送到 the output</p><p>每个文件启动一个harvester, harvester 负责打开和关闭文件，这意味着在运行时文件描述符保持打开状态</p><p>如果文件在读取时被删除或重命名，Filebeat将继续读取文件。</p><p>这有副作用，即在harvester关闭之前，磁盘上的空间被保留。默认情况下，Filebeat将文件保持打开状态，直到达到close_inactive状态</p><p>关闭harvester会产生以下结果：</p><p>1）如果在harvester仍在读取文件时文件被删除，则关闭文件句柄，释放底层资源。</p><p>2）文件的采集只会在scan_frequency过后重新开始。</p><p>3）如果在harvester关闭的情况下移动或移除文件，则不会继续处理文件。</p><p>要控制收割机何时关闭，请使用close_ *配置选项</p><h2 id="prospector-采矿者"><a href="#prospector-采矿者" class="headerlink" title="prospector(采矿者)"></a>prospector(采矿者)</h2><p>prospector 负责管理harvester并找到所有要读取的文件来源。</p><p>如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个harvester。</p><p>每个prospector都在自己的Go协程中运行。</p><h1 id="Filebeat如何保持文件的状态？"><a href="#Filebeat如何保持文件的状态？" class="headerlink" title="Filebeat如何保持文件的状态？"></a>Filebeat如何保持文件的状态？</h1><p>Filebeat 保存每个文件的状态并经常将状态刷新到磁盘上的注册文件中。<br>该状态用于记住harvester正在读取的最后偏移量，并确保发送所有日志行。</p><p>如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可用时继续读取文件。</p><p>在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，<br>当重新启动Filebeat时，将使用注册文件的数据来重建文件状态，Filebeat将每个harvester在从保存的最后偏移量继续读取。</p><p>每个prospector为它找到的每个文件保留一个状态。</p><p>由于文件可以被重命名或移动，因此文件名和路径不足以识别文件。</p><p>对于每个文件，Filebeat存储唯一标识符以检测文件是否先前已采集过。</p><p>如果您的使用案例涉及每天创建大量新文件，您可能会发现注册文件增长过大。请参阅注册表文件太大？编辑有关您可以设置以解决此问题的配置选项的详细信息。</p><h1 id="Filebeat如何确保至少一次交付"><a href="#Filebeat如何确保至少一次交付" class="headerlink" title="Filebeat如何确保至少一次交付"></a>Filebeat如何确保至少一次交付</h1><p>Filebeat保证事件至少会被传送到配置的输出一次，并且不会丢失数据。 Filebeat能够实现此行为，因为它将每个事件的传递状态存储在注册文件中。</p><p>在输出阻塞或未确认所有事件的情况下，Filebeat将继续尝试发送事件，直<br>到接收端确认已收到。</p><p>如果Filebeat在发送事件的过程中关闭，它不会等待输出确认所有收到事件。</p><p>发送到输出但在Filebeat关闭前未确认的任何事件在重新启动Filebeat时会再次发送。</p><p>这可以确保每个事件至少发送一次，但最终会将重复事件发送到输出。<br>也可以通过设置shutdown_timeout选项来配置Filebeat以在关闭之前等待特定时间。</p><p>注意：</p><p>Filebeat的至少一次交付保证包括日志轮换和删除旧文件的限制。如果将日志文件写入磁盘并且写入速度超过Filebeat可以处理的速度，或者在输出不可用时删除了文件，则可能会丢失数据。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html</a></p><p><a href="https://blog.51cto.com/lansonli/5283480" target="_blank" rel="noopener">https://blog.51cto.com/lansonli/5283480</a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy ELK日志追踪</title>
    <link href="http://raptor1998.top/2022/08/04/ByteStudy%20ELK%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA/"/>
    <id>http://raptor1998.top/2022/08/04/ByteStudy%20ELK%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA/</id>
    <published>2022-08-03T16:00:00.000Z</published>
    <updated>2022-08-15T13:11:00.756Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>先食用此篇<br><a href="https://raptor1998.top/2022/07/28/ByteStudy%20ELK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/">ELK日志收集</a></p><p>MDC（Mapped Diagnostic Context）用于存储运行上下文的特定线程的上下文数据。因此，如果使用 log4j 进行日志记录，则每个线程都可以拥有自己的MDC，该 MDC 对整个线程是全局的。属于该线程的任何代码都可以轻松访问线程的 MDC 中存在的值。</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152105838.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="Nacos单节点启动"><a href="#Nacos单节点启动" class="headerlink" title="Nacos单节点启动"></a>Nacos单节点启动</h1><p><code>./bin/startup.sh -m standalone</code></p><h1 id="logback日志增加traceid"><a href="#logback日志增加traceid" class="headerlink" title="logback日志增加traceid"></a>logback日志增加traceid</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志输出格式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"log.pattern"</span></span></span><br><span class="line"><span class="tag">          <span class="attr">value</span>=<span class="string">"%d{yyyy-MM-dd HH:mm:ss.SSS} | [%thread] | %-5level | %logger{50} | %X{traceId} | [%method,%line] | %msg%n"</span>/&gt;</span></span><br></pre></td></tr></tbody></table></figure></div><h1 id="给上下游服务添加过滤器获取traceid"><a href="#给上下游服务添加过滤器获取traceid" class="headerlink" title="给上下游服务添加过滤器获取traceid"></a>给上下游服务添加过滤器获取traceid</h1><p><strong>启动类添加扫描</strong></p><p><strong>@ServletComponentScan</strong></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Order</span>(<span class="number">1</span>)</span><br><span class="line"><span class="meta">@WebFilter</span>(urlPatterns = <span class="string">"/*"</span>,filterName = <span class="string">"traceIdFilter"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TraceIdFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>{</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String MDC_TRACE_ID = <span class="string">"traceId"</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>{</span><br><span class="line">        HttpServletRequest httpRequest = (HttpServletRequest) request;</span><br><span class="line">        String traceId = httpRequest.getHeader(MDC_TRACE_ID);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(traceId)) {</span><br><span class="line">            traceId = IdUtil.fastSimpleUUID();;</span><br><span class="line">        }</span><br><span class="line">        System.out.println(<span class="keyword">this</span>.getClass().getName()+<span class="string">" traceId "</span> + traceId);</span><br><span class="line">        MDC.put(MDC_TRACE_ID, traceId);</span><br><span class="line">        ThreadLocalUtils.setTraceId(traceId);</span><br><span class="line">        HttpServletResponse httpResponse = (HttpServletResponse) response;</span><br><span class="line">        httpResponse.setHeader(MDC_TRACE_ID, traceId);</span><br><span class="line">        chain.doFilter(request, response);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h1 id="调用者改造OpenFeign"><a href="#调用者改造OpenFeign" class="headerlink" title="调用者改造OpenFeign"></a>调用者改造OpenFeign</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OpenFeignRequestInterceptor</span> <span class="keyword">implements</span> <span class="title">RequestInterceptor</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(RequestTemplate requestTemplate)</span> </span>{</span><br><span class="line">        String traceId = MDC.get(TraceIdFilter.MDC_TRACE_ID);</span><br><span class="line">        System.out.println(<span class="string">"OpenFeignRequestInterceptor traceId "</span> + traceId);</span><br><span class="line">        requestTemplate.header(TraceIdFilter.MDC_TRACE_ID, traceId);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h1 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152105857.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy ELK日志收集</title>
    <link href="http://raptor1998.top/2022/07/28/ByteStudy%20ELK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/"/>
    <id>http://raptor1998.top/2022/07/28/ByteStudy%20ELK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/</id>
    <published>2022-07-27T16:00:00.000Z</published>
    <updated>2022-08-15T13:04:09.666Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="日志收集意义"><a href="#日志收集意义" class="headerlink" title="日志收集意义"></a>日志收集意义</h1><p>分析日志是工程师发现问题，解决系统故障的主要手段。日志主要包括系统日志、应用程序日志和安全日志。</p><p>一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。</p><p>经常分析日志可以了解服务器的负荷，性能安全性，从而及时采取措施纠正错误。通常，日志被分散的储存在不同的设备上。如果管理数十上百台服务器，还在使用依次登录每台机器的传统方法查阅日志，既繁琐又效率低下。为此，我们可以使用集中化的日志管理，例如：开源的 syslog，将所有服务器上的日志收集汇总。</p><p>集中化管理日志后，日志的统计和检查又成为一件比较麻烦的事情，一般我们使用 grep、awk 和 wc 等 Linux 命令能实现检索和统计，但是对于更高要求的查询、排序和统计等，再加上庞大的机器数量，使用这样的方法依然难免有点力不从心。</p><p>开源实时日志分析 ELK 平台能够完美的解决我们上述的问题，ELK 由 ElasticSearch、Logstash 和 Kibana 这三个开源工具组成。</p><h1 id="ELK组成"><a href="#ELK组成" class="headerlink" title="ELK组成"></a>ELK组成</h1><p>Elasticsearch、Logstash 和 Kibana 三个开源工具配合使</p><ul><li>filebeat：部署在需要采集日志的各个服务器上，负责监听log文件，Filebeat会将日志数据收集并结构化后传输到Logstash上；</li><li>Logstash：负责将日志进行过滤、收集，再传输到Elasticsearch上；</li><li>Elasticsearch：负责把日志作为索引进行存储并且构造对应倒排索引；</li><li>Kibana：负责可视化呈现日志，需要查询时Kibana调用Elasticsearch进行日志数据的查询；</li></ul><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152053343.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="Quick-Start——监听nginx日志"><a href="#Quick-Start——监听nginx日志" class="headerlink" title="Quick Start——监听nginx日志"></a>Quick Start——监听nginx日志</h1><h2 id="安装filebeat"><a href="#安装filebeat" class="headerlink" title="安装filebeat"></a>安装filebeat</h2><p><code>tar -zxvf filebeat-7.7.0-linux-x86_64.tar.gz</code></p><h2 id="监听nginx的accss-log并输出到es"><a href="#监听nginx的accss-log并输出到es" class="headerlink" title="监听nginx的accss.log并输出到es"></a>监听nginx的accss.log并输出到es</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">filebeat.inputs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">log</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/usr/local/nginx/logs/*.log</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">["nginx"]</span></span><br><span class="line"><span class="attr">steup.template.settings:</span></span><br><span class="line">  <span class="attr">index.number_of_shards:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">output.elasticsearch:</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">["114.116.32.159:9200"]</span></span><br></pre></td></tr></tbody></table></figure></div><h1 id="kinaba展示日志并制作柱状图"><a href="#kinaba展示日志并制作柱状图" class="headerlink" title="kinaba展示日志并制作柱状图"></a>kinaba展示日志并制作柱状图</h1><h2 id="kibana安装"><a href="#kibana安装" class="headerlink" title="kibana安装"></a>kibana安装</h2><p>略</p><h2 id="柱状图"><a href="#柱状图" class="headerlink" title="柱状图"></a>柱状图</h2><p>Visualize选择柱状图并选择filebeat输出的nginx索引</p><p>Y轴位数量   X轴以时间为单位</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152056092.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="Metricbeat监听状态"><a href="#Metricbeat监听状态" class="headerlink" title="Metricbeat监听状态"></a>Metricbeat监听状态</h1><h2 id="nginx安装状态模块"><a href="#nginx安装状态模块" class="headerlink" title="nginx安装状态模块"></a>nginx安装状态模块</h2><h1 id="收集自定义服务的日志"><a href="#收集自定义服务的日志" class="headerlink" title="收集自定义服务的日志"></a>收集自定义服务的日志</h1><h2 id="Java服务"><a href="#Java服务" class="headerlink" title="Java服务"></a>Java服务</h2><h3 id="controller"><a href="#controller" class="headerlink" title="controller"></a>controller</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/hello"</span>,method = RequestMethod.GET)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>{</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;<span class="number">3</span>){</span><br><span class="line">        Date date = <span class="keyword">new</span> Date();</span><br><span class="line">        SimpleDateFormat slf = <span class="keyword">new</span> SimpleDateFormat();</span><br><span class="line">        String format = slf.format(date);</span><br><span class="line">        log.info(<span class="string">"hello info,{}"</span>,format);</span><br><span class="line">        log.debug(<span class="string">"hello debug,{}"</span>,format);</span><br><span class="line">        log.error(<span class="string">"hello error,{}"</span>,format);</span><br><span class="line">        Thread.sleep(<span class="number">200</span>);</span><br><span class="line">        i++;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"log hello"</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h3 id="logback-xml"><a href="#logback-xml" class="headerlink" title="logback.xml"></a>logback.xml</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">debug</span>=<span class="string">"false"</span> <span class="attr">xmlns</span>=<span class="string">"http://ch.qos.logback/xml/ns/logback"</span></span></span><br><span class="line"><span class="tag">               <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">               <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://ch.qos.logback/xml/ns/logback</span></span></span><br><span class="line"><span class="tag"><span class="string">               https://raw.githubusercontent.com/enricopulatzo/logback-XSD/master/src/main/xsd/logback.xsd"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志存放路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"log.path"</span> <span class="attr">value</span>=<span class="string">"/Users/bytedance/IdeaProjects/bytestudy/ELK/log"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"clr"</span> <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.ColorConverter"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"wex"</span></span></span><br><span class="line"><span class="tag">                    <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"wEx"</span></span></span><br><span class="line"><span class="tag">                    <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志输出格式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"log.pattern"</span></span></span><br><span class="line"><span class="tag">          <span class="attr">value</span>=<span class="string">"%d{yyyy-MM-dd HH:mm:ss.SSS} | [%thread] | %-5level | %logger{50} | [%method,%line] | %msg%n"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 控制台输出 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"console"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>${log.pattern}<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"infoAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--    文件路径    --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>${log.path}/info.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--        定义滚动策略。   基于时间的滚动策略--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志文件名格式  带有.gz 会自动压缩--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>${log.path}/info-%d{yyyy-MM-dd}.log.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志最大的历史 30天 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>${log.pattern}<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>INFO<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果是INFO级别，直接记录  匹配时的操作：接收（记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果不是，拒绝   不匹配时的操作：拒绝（不记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"errorAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--    文件路径    --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>${log.path}/error.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--        定义滚动策略。   基于时间的滚动策略--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志文件名格式  带有.gz 会自动压缩--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>${log.path}/error-%d{yyyy-MM-dd}.log.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志最大的历史 30天 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>${log.pattern}<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>ERROR<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果是ERROR级别，直接记录  匹配时的操作：接收（记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果不是，拒绝   不匹配时的操作：拒绝（不记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"sqlAppender"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--    文件路径    --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>${log.path}/infoSql.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--        定义滚动策略。   基于时间的滚动策略--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志文件名格式  带有.gz 会自动压缩--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>${log.path}/infoSql-%d{yyyy-MM-dd}.log.gz<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志最大的历史 30天 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">maxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">maxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>${log.pattern}<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>DEBUG<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果是ERROR级别，直接记录  匹配时的操作：接收（记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 如果不是，拒绝   不匹配时的操作：拒绝（不记录） --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--mybatis log configure--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.apache.ibatis"</span> <span class="attr">level</span>=<span class="string">"TRACE"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Connection"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.Statement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"java.sql.PreparedStatement"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--系统操作日志--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--    &lt;root level="INFO"&gt;--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--        &lt;appender-ref ref="console"/&gt;--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--    &lt;/root&gt;--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置自己写的代码的日志记录器    对应包里面的日志才会被记录  additivity表示我们自定义的日志输出 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.raptor"</span> <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"infoAppender"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"errorAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.raptor.system.mapper"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"sqlAppender"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure></div><h2 id="filebeat"><a href="#filebeat" class="headerlink" title="filebeat"></a>filebeat</h2><h3 id="监听Java服务的日志并输出到logstach"><a href="#监听Java服务的日志并输出到logstach" class="headerlink" title="监听Java服务的日志并输出到logstach"></a>监听Java服务的日志并输出到logstach</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">filebeat.inputs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">log</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/Users/bytedance/IdeaProjects/bytestudy/ELK/log/error.log</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">["elkdemo"]</span></span><br><span class="line"><span class="attr">steup.template.settings:</span></span><br><span class="line">  <span class="attr">index.number_of_shards:</span> <span class="number">3</span></span><br><span class="line"><span class="comment">#output.elasticsearch:</span></span><br><span class="line"><span class="comment">#  hosts: ["114.116.32.159:9200"]</span></span><br><span class="line"></span><br><span class="line"><span class="attr">output.logstash:</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">["127.0.0.1:5044"]</span></span><br></pre></td></tr></tbody></table></figure></div><h2 id="Logstach"><a href="#Logstach" class="headerlink" title="Logstach"></a>Logstach</h2><h3 id="简单测试控制台输出"><a href="#简单测试控制台输出" class="headerlink" title="简单测试控制台输出"></a>简单测试控制台输出</h3><p><code>./logstash -e "input {stdin {}} output {stdout{}}"</code></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152058000.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>监听5044 接收filebeat的输入 并输出 到控制台</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152058020.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">input {</span><br><span class="line">  beats {</span><br><span class="line">    port =&gt; "5044"</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">output{</span><br><span class="line">        stdout{codec =&gt; rubydebug}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">#output {</span><br><span class="line">#  elasticsearch {</span><br><span class="line">#    hosts =&gt; ["http://192.168.42.111:9200"]</span><br><span class="line">#    index =&gt; "mylogstash1"</span><br><span class="line">#    #user =&gt; "elastic"</span><br><span class="line">#    #password =&gt; "changeme"</span><br><span class="line">#  }</span><br><span class="line">#}</span><br></pre></td></tr></tbody></table></figure></div><h2 id="输出到es"><a href="#输出到es" class="headerlink" title="输出到es"></a>输出到es</h2><h3 id="添加split效果"><a href="#添加split效果" class="headerlink" title="添加split效果"></a>添加split效果</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang"></div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">         "input" =&gt; {</span><br><span class="line">        "type" =&gt; "log"</span><br><span class="line">    },</span><br><span class="line">           "ecs" =&gt; {</span><br><span class="line">        "version" =&gt; "1.10.0"</span><br><span class="line">    },</span><br><span class="line">          "tags" =&gt; [</span><br><span class="line">        [0] "elkdemo",</span><br><span class="line">        [<span class="number">1</span>] <span class="string">"beats_input_codec_plain_applied"</span></span><br><span class="line">    ],</span><br><span class="line">       "message" =&gt; [</span><br><span class="line">        [0] "2022-07-27 22:45:20.653 ",</span><br><span class="line">        [1] " [http-nio-8080-exec-1] ",</span><br><span class="line">        [2] " ERROR ",</span><br><span class="line">        [3] " com.raptor.elk.controller.LogController ",</span><br><span class="line">        [4] " [hello,28] ",</span><br><span class="line">        [<span class="number">5</span>] <span class="string">" hello error,22-7-27 下午10:45"</span></span><br><span class="line">    ],</span><br><span class="line">          "host" =&gt; {</span><br><span class="line">        "name" =&gt; "C02G94S8ML7H"</span><br><span class="line">    },</span><br><span class="line">      "@version" =&gt; "1",</span><br><span class="line">    "@timestamp" =&gt; 2022-07-27T14:45:24.480Z,</span><br><span class="line">         "agent" =&gt; {</span><br><span class="line">                "name" =&gt; "C02G94S8ML7H",</span><br><span class="line">                  "id" =&gt; "94db4c0d-006c-4e8a-999c-35e57c97099f",</span><br><span class="line">                "type" =&gt; "filebeat",</span><br><span class="line">             "version" =&gt; "7.14.0",</span><br><span class="line">        "ephemeral_id" =&gt; "bc8ce9a9-62c1-43f4-9826-e2f17a51cbe4",</span><br><span class="line">            "hostname" =&gt; "C02G94S8ML7H"</span><br><span class="line">    },</span><br><span class="line">           "log" =&gt; {</span><br><span class="line">          "file" =&gt; {</span><br><span class="line">            "path" =&gt; "/Users/bytedance/IdeaProjects/bytestudy/ELK/log/error.log"</span><br><span class="line">        },</span><br><span class="line">        "offset" =&gt; 1543</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h3 id="conf"><a href="#conf" class="headerlink" title=".conf"></a>.conf</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">input {</span><br><span class="line">  beats {</span><br><span class="line">    port =&gt; "5044"</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">filter {</span><br><span class="line">    mutate{</span><br><span class="line">        split =&gt; {"message"=&gt;"|"}</span><br><span class="line">        }</span><br><span class="line">    mutate{</span><br><span class="line">        add_field =&gt; {</span><br><span class="line">                "controllerName" =&gt; "%{[message][3]}"</span><br><span class="line">                "errorMessage" =&gt; "%{[message][5]}"</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    mutate{</span><br><span class="line">        convert =&gt; {</span><br><span class="line">                "controllerName" =&gt; "string"</span><br><span class="line">                "errorMessage" =&gt; "string"</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">output{</span></span><br><span class="line"><span class="meta">#</span><span class="bash">        stdout{codec =&gt; rubydebug}</span></span><br><span class="line"><span class="meta">#</span><span class="bash">}</span></span><br><span class="line"></span><br><span class="line">output {</span><br><span class="line">  elasticsearch {</span><br><span class="line">    hosts =&gt; ["http://114.116.32.159:9200"]</span><br><span class="line">    index =&gt; "elkdemo"</span><br><span class="line"><span class="meta">#</span><span class="bash">    <span class="comment">#user =&gt; "elastic"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">    <span class="comment">#password =&gt; "changeme"</span></span></span><br><span class="line">         }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h2 id="kibana制作表盘"><a href="#kibana制作表盘" class="headerlink" title="kibana制作表盘"></a>kibana制作表盘</h2><h3 id="访问量柱形图"><a href="#访问量柱形图" class="headerlink" title="访问量柱形图"></a>访问量柱形图</h3><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152100032.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h3 id="简单的饼图"><a href="#简单的饼图" class="headerlink" title="简单的饼图"></a>简单的饼图</h3><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152100071.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h3 id="表格展示"><a href="#表格展示" class="headerlink" title="表格展示"></a>表格展示</h3><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152100090.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h3 id="制作一个简单的表盘"><a href="#制作一个简单的表盘" class="headerlink" title="制作一个简单的表盘"></a>制作一个简单的表盘</h3><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152104124.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><ul><li>同时监控多套环境、多个项目的日志：由于我们的测试环境和开发环境内网在同一个网段下，因此我基于多个（dev+test）环境创建了多个项目的索引，以dev、test开头作为索引的名称，以此区分环境类型，在索引列表中可手动切换索引查看对应项目的日志，无需像往常一样登录多台服务器、打开多个窗口；</li><li>不占用服务器资源：Elasticsearch、Logstash、Kibana分别部署在多台服务器上，Filebeat仅部署在需要采集日志的服务器上，它们彼此通过内外相互联通，因此并不会集中占用内存、CPU等资源；</li><li>外网访问，通过浏览器即可随时随地访问，无需任何工具：另由于Kibana所在的服务器可以通过外网IP访问，因此，即使回到家中，也能通过浏览器实时访问到各个环境下各个项目的日志信息；<h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h2></li><li>搭建过程较为繁琐：Elasticsearch、Logstash、Kibana、Filebeat等多个服务需要分别部署，在此过程中可能遇到各种问题；</li><li>日志访问有延时：由于日志的收集、过滤、解析需要一定的时间，因此，当发起请求后，并不能像命令行或浏览器的F12工具一样，在ELK实时看到响应日志信息，会带有5-10s左右的延时；</li></ul></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy canal原理</title>
    <link href="http://raptor1998.top/2022/07/20/ByteStudy%20canal%E5%8E%9F%E7%90%86/"/>
    <id>http://raptor1998.top/2022/07/20/ByteStudy%20canal%E5%8E%9F%E7%90%86/</id>
    <published>2022-07-19T16:00:00.000Z</published>
    <updated>2022-08-15T13:14:42.913Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="Canal工作原理"><a href="#Canal工作原理" class="headerlink" title="Canal工作原理"></a>Canal工作原理</h1><p>Canal是模拟Mysql主从复制原理。将自己伪装成Slave。向主库发起dump协议，拿到bin_log日志，解析之后对数据做相关操作</p><h1 id="mysql主从复制原理"><a href="#mysql主从复制原理" class="headerlink" title="mysql主从复制原理"></a>mysql主从复制原理</h1><h2 id="为什么要主从"><a href="#为什么要主从" class="headerlink" title="为什么要主从"></a>为什么要主从</h2><ol><li>在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。</li><li>做数据的热备，主库宕机后能够及时替换主库，保证业务可用性。</li><li>架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。</li></ol><h2 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h2><ul><li>数据分布 (Data distribution )</li><li>负载平衡(load balancing)</li><li>数据备份(Backups) ，保证数据安全</li><li>高可用性和容错性(High availability and failover)</li><li>实现读写分离，缓解数据库压力</li></ul><p>注意：由于 mysql 实现的异步复制，所以主库和从库数据之间存在一定的差异，在从库执行查询操作需要考虑这些数据的差异，一般只有更新不频繁和对实时性要求不高的数据可以通过从库查询，实行要求高的仍要从主库查询。</p><h2 id="主要用途"><a href="#主要用途" class="headerlink" title="主要用途"></a>主要用途</h2><ol><li>读写分离<br>在开发工作中，有时候会遇见某个sql 语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。</li><li>数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换(主从切换)<br>提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据；</li><li>高可用（HA）<br>1）因为数据库服务器中的数据都是相同的，当Master挂掉后，可以指定一台Slave充当Master继续保证服务的运行，因为数据是一致性的（如果当插入时Master就挂掉，可能不一致，因为同步也需要时间）当然这种配置不是简单的把一台Slave充当Master，毕竟还要考虑后续的Slave的数据同步到Master<br>2）在主服务器上执行写入和更新，在从服务器上向外提供读功能，达到读写分离的效果，也可以动态地调整从服务器的数量，从而调整整个数据库的性能。<br>3）在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能。</li><li>架构扩展<br>随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。</li></ol><h2 id="复制的基本过程"><a href="#复制的基本过程" class="headerlink" title="复制的基本过程"></a>复制的基本过程</h2><ol><li>在从节点上执行sart slave命令开启主从复制开关，开始进行主从复制。从节点上的I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；</li><li>主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程（log dump 线程）根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position（bin-log中的下一个指定更新位置）；</li><li>从节点的I/O进程接收到主节点发送过来的日志内容、日志文件及位置点后，将接收到的日志内容更新到本机的relay-log（中继日志）的文件（Mysql-relay-bin.xxx）的最末端，并将读取到的binary log（bin-log）文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；</li><li>Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过SQL语句，然后在本数据库中按照解析出来的顺序执行，并在relay-log.info中记录当前应用中继日志的文件名和位置点。</li></ol><h2 id="Canal会不会丢失数据"><a href="#Canal会不会丢失数据" class="headerlink" title="Canal会不会丢失数据"></a>Canal会不会丢失数据</h2><ol><li>ZK的数据可靠性或者安全性被破坏，比如ZK数据丢失，ZK的数据被人为串改，特别是有关Position的值。</li><li>MySQL binlog非正常运维，比如binglog迁移、重命名、丢失等。</li><li>切换MySQL源，比如原来基于M1实例，后来M1因为某种原因失效，那么Canal将数据源切换为M2，而且M1和M2可能binlog数据存在不一致（非常有可能）。</li><li>Consumer端ACK的时机不佳，比如调用get()方法，而不是getWithoutAck()，那么消息有可能尚未完全消费，就已经ACK，那么此时由异常或者Consumer实例失效，则可能导致消息丢失。我们需要在ACK时机上保障“at lease once”。</li></ol><h2 id="Canal会导致消息重复吗"><a href="#Canal会导致消息重复吗" class="headerlink" title="Canal会导致消息重复吗"></a>Canal会导致消息重复吗</h2><ol><li>Canal 实例初始化时，根据“消费者的Cursor”来确定binlog的起始位置，但是Cursor在ZK中的保存是滞后的（间歇性刷新），所以Canal 实例获得的起始位置一定不会大于消费者真实已见的位置。</li><li>客户端，因为某种原因的rollback，也可能导致一个batch内的所有消息重发，此时可能导致重复消费。</li></ol><p>我们建议，Consumer端需要保持幂等，对于重复数据可以进行校验或者replace。对于非幂等操作，比如累加、计费，需要慎重。</p><h2 id="Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？"><a href="#Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？" class="headerlink" title="Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？"></a>Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？</h2><p>比如有两个客户端集群，C1/C2，你希望C1和C2中的消费者都能够订阅到相同的消息，就像Kafka或者JMS Topic一样…但是非常遗憾，似乎Canal无法做到，这取决于Canal内部的存储模式，Canal内部是一个“即发即失”的内存队列，无法权衡、追溯不同客户端之间的消息，所以无法支持。</p><p>如果希望达到这种结果，有2个办法：第一，消费者收到消息以后转发到kafka或者MQ中，后继的其他客户端只与kafka或者MQ接入；第二：一个Canal中使用多个目的地，但是它们对应相同的MySQL源。</p><h2 id="Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？-1"><a href="#Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？-1" class="headerlink" title="Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？"></a>Canal数据的集散问题，一个目的地的消息能否被多个客户端集群并行消费？</h2><p>比如有两个客户端集群，C1/C2，你希望C1和C2中的消费者都能够订阅到相同的消息，就像Kafka或者JMS Topic一样…但是非常遗憾，似乎Canal无法做到，这取决于Canal内部的存储模式，Canal内部是一个“即发即失”的内存队列，无法权衡、追溯不同客户端之间的消息，所以无法支持。</p><p>如果希望达到这种结果，有2个办法：第一，消费者收到消息以后转发到kafka或者MQ中，后继的其他客户端只与kafka或者MQ接入；第二：一个Canal中使用多个目的地，但是它们对应相同的MySQL源。</p><h2 id="Canal性能如何？"><a href="#Canal性能如何？" class="headerlink" title="Canal性能如何？"></a>Canal性能如何？</h2><p>Canal本身非常轻量级，主要性能开支就是在binlog解析，其转发、存储、提供消费者服务等都很简单。它本身不负责数据存储。原则上，canal解析效率几乎没有负载，canal的本身的延迟，取决于其与slave之间的网络IO。<br>如果Canal更换上游的主库或者从库，该怎么办？（比如迁库、迁表等）<br>背景要求，我们建议“新的数据库最好是旧的数据库的slave”或者“新、旧数据库为同源master”，平滑迁移；</p><pre><code>1）创建一个新的实例，使用新的目的地，并与新的Slave创建连接。2）在此期间，Consumer仍然与旧的目的地消费。3）通过“timestamp”确认，新的slave的最近binlog至少已经超过此值。4）Consumer切换，使用新的目的地消费，可能会消费到重复数据，但是不会导致数据丢失。</code></pre><p>当然，更简单的办法就是直接将原目的地中的数据库地址跟新即可，前提是新、旧两个数据库同源master，新库最好已经同步执行了一段时间。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://blog.csdn.net/K_520_W/article/details/117135287" target="_blank" rel="noopener">mysql主从复制原理_爱上口袋的天空的博客-CSDN博客_mysql主从复制的原理</a><br><a href="https://blog.csdn.net/qq_36971119/article/details/122856561" target="_blank" rel="noopener">Canal原理及其使用_②⑦丶的博客-CSDN博客_canal</a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy canal adaptor同步es</title>
    <link href="http://raptor1998.top/2022/07/18/ByteStudy-canal%E5%90%8C%E6%AD%A5es/"/>
    <id>http://raptor1998.top/2022/07/18/ByteStudy-canal%E5%90%8C%E6%AD%A5es/</id>
    <published>2022-07-17T16:00:00.000Z</published>
    <updated>2022-08-15T12:31:28.377Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="canal-工作原理"><a href="#canal-工作原理" class="headerlink" title="canal 工作原理"></a>canal 工作原理</h1><ul><li>canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议</li><li>MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )</li><li>canal 解析 binary log 对象(原始为 byte 流)</li></ul><h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><p>90%的问题都能在issues找到</p><p><a href="https://github.com/alibaba/canal/issues" target="_blank" rel="noopener">https://github.com/alibaba/canal/issues</a></p><h1 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">srcDataSources:</span></span><br><span class="line">    <span class="attr">defaultDS:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/canal?useUnicode=true&amp;useSSL=false</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span> <span class="number">123456</span></span><br><span class="line">  <span class="attr">canalAdapters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">instance:</span> <span class="string">example</span> <span class="comment"># canal instance Name or mq topic name</span></span><br><span class="line">    <span class="attr">groups:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">groupId:</span> <span class="string">g1</span></span><br><span class="line">      <span class="attr">outerAdapters:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">es7</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">exampleKey</span></span><br><span class="line">        <span class="attr">hosts:</span> <span class="number">114.116</span><span class="number">.32</span><span class="number">.159</span><span class="string">:9200</span></span><br><span class="line">        <span class="attr">properties:</span></span><br><span class="line">          <span class="attr">mode:</span> <span class="string">rest</span> <span class="comment"># or rest</span></span><br><span class="line">          <span class="comment"># security.auth: test:123456 #  only used for rest mode</span></span><br><span class="line">          <span class="attr">cluster.name:</span> <span class="string">elasticssearch</span></span><br></pre></td></tr></tbody></table></figure></div><h1 id="配置conf-es7-xxx-yml"><a href="#配置conf-es7-xxx-yml" class="headerlink" title="配置conf/es7/xxx.yml"></a>配置conf/es7/xxx.yml</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataSourceKey:</span> <span class="string">defaultDS</span> <span class="comment">#和上面canal.conf.srcDataSources.defaultDS要一样</span></span><br><span class="line"><span class="attr">outerAdapterKey:</span> <span class="string">exampleKey</span> <span class="comment">#和上面canal.conf.canalAdapters.instance.groups.outerAdapters.key要一样</span></span><br><span class="line"><span class="attr">destination:</span> <span class="string">example</span> <span class="comment">#和上面canal.conf.canalAdapters.instance要一样</span></span><br><span class="line"><span class="attr">groupId:</span> <span class="string">g1</span> <span class="comment">#和上面canal.conf.canalAdapters.instance.groups.groupId要一样</span></span><br><span class="line"><span class="attr">esMapping:</span></span><br><span class="line">  <span class="attr">_index:</span> <span class="string">test</span> <span class="comment">#索引名称</span></span><br><span class="line">  <span class="attr">_id:</span> <span class="string">_id</span> <span class="comment">#documentid</span></span><br><span class="line">  <span class="attr">_type:</span> <span class="string">_doc</span> <span class="comment"># type</span></span><br><span class="line"><span class="comment">#  upsert: true</span></span><br><span class="line"><span class="comment">#  pk: id</span></span><br><span class="line">  <span class="attr">sql:</span> <span class="string">"select a.id as _id, a.name_cn, a.name_en, a.email</span></span><br><span class="line"><span class="string">        from user a"</span>  <span class="comment"># 查询的sql返回的结构要使用as别名和es的filed对应</span></span><br><span class="line"><span class="comment">#  objFields:</span></span><br><span class="line"><span class="comment">#    _labels: array:;</span></span><br><span class="line">  <span class="attr">commitBatch:</span> <span class="number">3000</span> <span class="comment">#批量提交数量</span></span><br></pre></td></tr></tbody></table></figure></div><h1 id="es创建索引"><a href="#es创建索引" class="headerlink" title="es创建索引"></a>es创建索引</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">json</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PUT http://114.116.32.159:9200/test</span><br><span class="line">{</span><br><span class="line">    <span class="attr">"settings"</span>: {</span><br><span class="line">        <span class="attr">"number_of_shards"</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"number_of_replicas"</span>: <span class="number">2</span></span><br><span class="line">    },</span><br><span class="line">    <span class="attr">"mappings"</span>: {</span><br><span class="line">        <span class="attr">"properties"</span>: {</span><br><span class="line">            <span class="attr">"name_cn"</span>: {</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">            },</span><br><span class="line">            <span class="attr">"name_en"</span>: {</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">            },</span><br><span class="line">            <span class="attr">"email"</span>: {</span><br><span class="line">                <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h1 id="全量更新"><a href="#全量更新" class="headerlink" title="全量更新"></a>全量更新</h1><p><code>curl http://localhost:8081/etl/es7/exampleKey/mytest_user.yml -X POST</code></p><p>params即 p.id&gt;{}的参数<br><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152029118.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h1 id="究极踩坑指南"><a href="#究极踩坑指南" class="headerlink" title="究极踩坑指南"></a>究极踩坑指南</h1><blockquote><p>mysql链接异常：Host is blocked because of many connection errors</p></blockquote><p><a href="https://blog.csdn.net/weixin_50180533/article/details/125254466" target="_blank" rel="noopener">MySQL 报错ERROR 1129 Host is blocked because of many connection errors。_皱皱小菜鸡的博客-CSDN博客</a></p><blockquote><p>Es failed driuid异常</p></blockquote><p><a href="https://github.com/alibaba/canal/issues/3466#issuecomment-825494336" target="_blank" rel="noopener">github.com</a></p><p>大多数并不适用，更换alpha2的es7依赖是亲测有效</p><blockquote><p>全量更新Task not found </p></blockquote><p>url格式为<a href="http://localhost:8081/etl/es7/exampleKey/mytest_user.yml" target="_blank" rel="noopener">http://localhost:8081/etl/es7/exampleKey/mytest_user.yml</a></p><p>application.yml 的 key: exampleKey   和   xxxyml的 key对应</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://blog.csdn.net/Day_Day_No_Bug/article/details/116748553?spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2-116748553-blog-120271777.pc_relevant_sortByStrongTime&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2-116748553-blog-120271777.pc_relevant_sortByStrongTime&amp;utm_relevant_index=5" target="_blank" rel="noopener">CanalAdapter同步ES7(全量&amp; 增量)_如果悲伤有颜色，那么一定是黄昏的博客-CSDN博客_canal 首次全量同步</a></p><p><a href="https://blog.csdn.net/qq_32419139/article/details/125232695" target="_blank" rel="noopener">2022-06-10 通过canal将mysql数据同步到es中_寂寞旅行的博客-CSDN博客</a></p><p><a href="https://github.com/alibaba/canal/issues/3714" target="_blank" rel="noopener">全量同步任务提示找不到任务 · Issue #3714 · alibaba/canal</a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy canal监听</title>
    <link href="http://raptor1998.top/2022/07/16/ByteStudy-canal%E7%9B%91%E5%90%AC/"/>
    <id>http://raptor1998.top/2022/07/16/ByteStudy-canal%E7%9B%91%E5%90%AC/</id>
    <published>2022-07-15T16:00:00.000Z</published>
    <updated>2022-08-15T12:31:34.976Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p> Canal 是用 Java 开发的基于数据库增量日志解析，提供增量数据订阅&amp;消费的中间件。目前。Canal 主要支持了 MySQL 的 Binlog 解析，解析完成后才利用 Canal Client 来处理获得的相关数据。</p><h1 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h1><p>它记录了所有的 DDL 和 DML(除了数据查询语句)语句，以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。<br>见末尾</p><h1 id="canal安装配置"><a href="#canal安装配置" class="headerlink" title="canal安装配置"></a>canal安装配置</h1><h2 id="canal-properties"><a href="#canal-properties" class="headerlink" title="canal.properties"></a>canal.properties</h2><p>canal.destinations = example</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152014912.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>example/instance.properties</p><p>伪装从节点</p><p><strong>canal.instance.mysql.slaveId=20</strong></p><p>mysql服务地址</p><p><strong>canal.instance.master.address=127.0.0.1:3306</strong></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152014888.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>伪装成 Slave</p><h3 id="mysql的主从复制"><a href="#mysql的主从复制" class="headerlink" title="mysql的主从复制"></a>mysql的主从复制</h3><ol><li>Master 主库将改变记录，写到二进制日志(BinLog)中;</li><li>Slave 从库向 MySQL Master 发送 dump 协议，将 Master 主库的 binary log events 拷贝<br>到它的中继日志(relay log);</li><li>Slave 从库读取并重做中继日志中的事件，将改变的数据同步到自己的数据库。</li></ol><h3 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">开启binlog，并设置为ROW格式</span><br><span class="line">server-id=1</span><br><span class="line"><span class="meta">#</span><span class="bash">开启binlog日志</span></span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">binlog-format=Row</span><br></pre></td></tr></tbody></table></figure></div><p>查看模式<code>show variables like 'binlog_format'</code></p><p>给canal添加一个读角色</p><p><code>GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%' IDENTIFIED BY 'canal' ;</code></p><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InvalidProtocolBufferException </span>{</span><br><span class="line">    <span class="comment">//1.获取 canal 连接对象</span></span><br><span class="line">    CanalConnector canalConnector = CanalConnectors.newSingleConnector(<span class="keyword">new</span> InetSocketAddress(<span class="string">"114.116.32.159"</span>, <span class="number">11111</span>), <span class="string">"example"</span>, <span class="string">"canal"</span>, <span class="string">"canal"</span>);</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) {</span><br><span class="line">        <span class="comment">//2.获取连接</span></span><br><span class="line">        canalConnector.connect();</span><br><span class="line">        <span class="comment">// 3.指定要监控的数据库</span></span><br><span class="line">        <span class="comment">// 配指定数据库只监听到了事务结束开始，所以直接配置全部</span></span><br><span class="line">        canalConnector.subscribe(<span class="string">".*\\..*"</span>);</span><br><span class="line">        <span class="comment">//4.获取 Message</span></span><br><span class="line">        Message message = canalConnector.get(<span class="number">100</span>);</span><br><span class="line">        List&lt;CanalEntry.Entry&gt; entries = message.getEntries();</span><br><span class="line">        <span class="keyword">if</span> (entries.size() &lt;= <span class="number">0</span>) {</span><br><span class="line">            System.out.println(<span class="string">"没有数据"</span>);</span><br><span class="line">            <span class="keyword">try</span> {</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            } <span class="keyword">catch</span> (InterruptedException e) {</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            }</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">for</span> (CanalEntry.Entry entry : entries) {</span><br><span class="line">                <span class="comment">//获取表名</span></span><br><span class="line">                String tableName = entry.getHeader().getTableName();</span><br><span class="line">                <span class="comment">//Entry 类型</span></span><br><span class="line">                CanalEntry.EntryType entryType = entry.getEntryType();</span><br><span class="line">                <span class="comment">//判断 entryType 是否为 ROWDATA</span></span><br><span class="line">                <span class="keyword">if</span> (CanalEntry.EntryType.ROWDATA.equals(entryType)) {</span><br><span class="line">                    <span class="comment">//序列化数据</span></span><br><span class="line">                    ByteString storeValue = entry.getStoreValue();</span><br><span class="line">                    <span class="comment">//反序列化</span></span><br><span class="line">                    CanalEntry.RowChange rowChange = CanalEntry.RowChange.parseFrom(storeValue);</span><br><span class="line">                    <span class="comment">//获取事件类型</span></span><br><span class="line">                    CanalEntry.EventType eventType = rowChange.getEventType();</span><br><span class="line">                    <span class="comment">//获取具体的数据</span></span><br><span class="line">                    List&lt;CanalEntry.RowData&gt; rowDatasList = rowChange.getRowDatasList();</span><br><span class="line">                    <span class="comment">//遍历并打印数据</span></span><br><span class="line">                    <span class="keyword">for</span> (CanalEntry.RowData rowData : rowDatasList) {</span><br><span class="line">                        JSONObject beforeData = <span class="keyword">new</span> JSONObject();</span><br><span class="line">                        List&lt;CanalEntry.Column&gt; beforeColumnsList = rowData.getBeforeColumnsList();</span><br><span class="line">                        <span class="keyword">for</span> (CanalEntry.Column column : beforeColumnsList) {</span><br><span class="line">                            beforeData.put(column.getName(), column.getValue());</span><br><span class="line">                        }</span><br><span class="line">                        JSONObject afterData = <span class="keyword">new</span> JSONObject();</span><br><span class="line">                        List&lt;CanalEntry.Column&gt; afterColumnsList = rowData.getAfterColumnsList();</span><br><span class="line">                        <span class="keyword">for</span> (CanalEntry.Column column : afterColumnsList) {</span><br><span class="line">                            afterData.put(column.getName(), column.getValue());</span><br><span class="line">                        }</span><br><span class="line">                        System.out.println(<span class="string">"TableName:"</span> + tableName + <span class="string">"\n"</span> +</span><br><span class="line">                                <span class="string">"EventType:"</span> + eventType + <span class="string">"\n"</span> +</span><br><span class="line">                                <span class="string">"before:"</span> + beforeData + <span class="string">"\n"</span> +</span><br><span class="line">                                <span class="string">"After:"</span> + afterData);</span><br><span class="line">                    }</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    System.out.println(<span class="string">"操作类型为："</span> + entryType);</span><br><span class="line">                }</span><br><span class="line"></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="更新数据库"><a href="#更新数据库" class="headerlink" title="更新数据库"></a>更新数据库</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sql</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> course <span class="keyword">SET</span> course_name = <span class="string">"增量多个更新"</span>,chapter_num=<span class="number">3</span> <span class="keyword">WHERE</span> <span class="keyword">id</span>=<span class="number">6</span></span><br></pre></td></tr></tbody></table></figure></div><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208152014928.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h2 id="监测不到ROWDATA类型"><a href="#监测不到ROWDATA类型" class="headerlink" title="监测不到ROWDATA类型"></a>监测不到ROWDATA类型</h2><p>修改instance.properties的正则</p><p><code>canal.instance.filter.black.regex=.*\\..*</code></p><p>客户端设置</p><p><code>CanalConnector.subscribe(".*\\..*")</code></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.kancloud.cn/wenshunbiao/wenshunbiao/1403850" target="_blank" rel="noopener">mysql查看binlog日志 · 小温笔记 · 看云</a></p><p><a href="https://javaguide.cn/database/mysql/mysql-logs.html#%E5%89%8D%E8%A8%80" target="_blank" rel="noopener">MySQL三大日志(binlog、redo log和undo log)详解</a></p><p><a href="https://www.csdn.net/tags/NtzacgysMDkyMjctYmxvZwO0O0OO0O0O.html" target="_blank" rel="noopener">canal.instance.filter.black.regex - CSDN</a></p><p><a href="https://blog.csdn.net/Watermelon1986/article/details/121536631" target="_blank" rel="noopener">Canal部署运行问题记录_Watermel0n丶的博客-CSDN博客_canal启动很慢</a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance Month 1</title>
    <link href="http://raptor1998.top/2022/07/10/ByteDance4/"/>
    <id>http://raptor1998.top/2022/07/10/ByteDance4/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2022-08-15T12:38:55.729Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="业务"><a href="#业务" class="headerlink" title="业务"></a>业务</h1><h2 id="需求测试"><a href="#需求测试" class="headerlink" title="需求测试"></a>需求测试</h2><hr><p>呜呜呜，哒哒哒。。。呜呜呜，哒哒哒。。。</p><hr><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142218372.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a><br>我的状态完全和樱木刚开始接触篮球一样，啥也不会，自己还挺有想法</p><blockquote><p>如何评价“樱木花道”这个人物？</p></blockquote><blockquote><p>樱木花道从一个自负、无知、单纯而且有点爱惹祸的小年轻，后来因为他心目中的女生晴子小姐而彻底改变了自己，成为一个刻苦上进，最终当上篮球手而且努力使自己做到了“灌篮高手”的境界。</p></blockquote><p>实习到目前已经一个月出头，前面两周都在看文档，熟悉业务，参与回归测试，其实对于自身技术上的成长可以说是几乎没有，只能靠自己探索内部基础工具的实现原理学习技术，毕竟业务这东西，对于目前的工作意义非凡，但对于个人成长来说，更多的还是业务背后的技术沉淀</p><p>第一次独立处理需求，PM是新加坡人，万幸的是她讲中文，还不算难理解，对于测试用例的编写还算有点新的理解，第一次写，更多的还是站在开发的角度去考虑事情，去扣一些极端操作，反而忽略了用户操作，对于功能测试来讲，更多的还是偏重于用户角度，这时其实就在思考测试岗位存在的意义了，毕竟之前在校内开发，写完代码，自测没问题就直接上了，并没有专门的同学把关</p><p>目前收获最大的的是学习需求上线流程，敏捷迭代的各时间点工作</p><h2 id="换线"><a href="#换线" class="headerlink" title="换线"></a>换线</h2><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142211306.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>本来高高兴兴，ld拉了一个群，群里只有ld、我、mentor和未来的新mentor，就说了一句话，长期支持一下非中机器人的方向，当我看到这个消息和上图表情一模一样，难顶。。。</p><p>SMB的业务还没完全理解，刚处理了两个需求，还都没有完全上线，一个外部依赖，另一个历史逻辑太多，理解的有点慢，现在又要去接触一个新的业务，我这短短几个月的实习里，若是按照目前的强度来看，我这实习期间可能并不会接触多过多的东西</p><h2 id="新业务线"><a href="#新业务线" class="headerlink" title="新业务线"></a>新业务线</h2><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142216915.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>SMB一共处理了两个需求，还有一个因为外部依赖没能上线，现在新业务线是基础服务，业务好理解，就是智能问答，多轮对话，提供工具，为客增赋能，让销售们更好的、更快的解决问题，类似于辅助型对话机器人</p><h3 id="业务理解"><a href="#业务理解" class="headerlink" title="业务理解"></a>业务理解</h3><p>问答：通过机器人发起提问，权限以及其他的一些校验通过后，将信息打包给KE，KE进行意图分析（KE可以理解为卧龙为KE提供了训练模型的数据，读书期间研究方向有部分nlp相关，目前在做的主要是自动构建领域KG），KE将分析的数据返回飞书卡片，测试根据会话人的部分、角色等判定是否返回某些FAQ的答案，然后根据用户的交互行为卧龙返回对应数据</p><p>人工：会话服务将从KE获取的用户意图以及用户部门等信息，发送给卧龙后台，卧龙后台查找符合条件的值班客服信息并返回给会话服务</p><p> 多轮对话：目前还没涉及，应该很有意思，根据之前的理解，对于NLP相关的，随着trans(E\H……)系列问世，再加上各类变形，bert等，有简单了解过基于知识图谱的KBQA</p><h3 id="新小组"><a href="#新小组" class="headerlink" title="新小组"></a>新小组</h3><p>随着业务线的更换，mentor也换了，看来是不用回去了，同时过来的还有之前租的rd同学，但是他支持一个月还要回去的。。。</p><p>换座位，周五开完最后一个smb的迭代总结会议，晚上就换座位了，都不认识，基本有问题就问新mentor和之前组的xiayan，最难受的是啥，就是我刚换完座位，立刻就有人坐在了我原来的位置，其实本来应该他过来这边，但是好像因为需求紧急，我来了有一点时间，已经熟悉的差不多了，换组的成本不大，就让我来了，那我只能一遍呜呜呜，哒哒哒。。。呜呜呜，哒哒哒。。。</p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance Week 4</title>
    <link href="http://raptor1998.top/2022/06/28/ByteDance2/"/>
    <id>http://raptor1998.top/2022/06/28/ByteDance2/</id>
    <published>2022-06-27T16:00:00.000Z</published>
    <updated>2022-08-15T12:38:44.861Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="入职第四周"><a href="#入职第四周" class="headerlink" title="入职第四周"></a>入职第四周</h1><h2 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h2><p> <a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142146986.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142128353.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>怎么说呢，除了有点卷，没什么个人时间，工作内容不符合我的预期，餐厅吃够了，天天当混子之外，其他的都还可以</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142148721.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142149703.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h2 id="业务线"><a href="#业务线" class="headerlink" title="业务线"></a>业务线</h2><p>万万没想到，目前最大的阻碍竟然是英语，面试的时候可没提过这个事，所在的团队是 Non-China 线，小组是 SMB，小微企业的跟进，PM 多是外国人，每日站会他们参与就要用英文，包括新的需求 PRD 以及迭代会议的总结，看我 mentor 之前说的英文不是事，再看看她在站会和迭代上讲的熟练程度，说她英语专业毕业我都信……</p><p>每天九点半左右去吃早餐，准备一下开始新一天的工作，十点半开每日站会，前面几天，每天都用同样的句式，</p><ul><li>Today I will continue to learn basic components and understand general business operations</li><li>Today I will continue to learn basic components and learn agile software development</li><li>learn develop and test process specification</li><li>Today I will write test case for pitch planner and understand interface logic</li><li>learn how to test</li><li>Contact other needs and sort out relevant businesses</li><li>“Living to death” related documents, and alarm learning</li></ul><p>“熟悉文档，学习说啥啥啥”，下迭代我要参与到站会的主持中去，难顶，这个迭代要记录 todo，后续还要参与到火车轮班，虽然现在还知道是啥，盲猜就是服务发布相关的东西</p><p>刚上没几天班，我旁边带我熟悉的军哥晋升奶爸，直接休假都七月多，（写到这赶紧停下来，去买个小礼物，过几天回来恭喜一下）此时就又换了一位组内成员夏嫣带我熟悉业务，前面一周多是以熟悉文档为主，包括几种平台的使用，非常枯燥，实际上的使用还得是在实践中了解，纸上谈兵的看意义不大，甚至没有真正理解；第二三周开始接触业务，跟着夏嫣、凤琳做一些回归测试，熟悉业务为主，目前针对业务的理解，实际上简单概括可以分为几个大角色，广告主、销售，因为是变现中台，按业务模块，简单概括用户管理，线索发现，商机管理，业务跟进，数据分析。目前在接触最多的业务属于定时任务的一块，将一些某些条件的广告主筛选出来，推进某些流程中，由业务进行跟进，可能没有 C 端产品好理解，但都是基于 C 端产品的，Tik Tok 等<br>截止到目前，处理了两个需求，都是和新加坡的 winter 对接的，pitch planner 相关的（这块原本是要我接受的，但是军哥陪产假，没人带着熟悉，所以后续嗯可能接手夏嫣 program 那块），后端改动不大的那种，多是一些前端的改造，通过 Charles 做一些断点即可</p><p>团队内的自动化测试工具，ate，基于 pytest 写的， 在 win 下安装出现了很多独占问题，为了避免后续我本地 win 可以运行，其他人或容器无法运行，又要重新 debug，非常低效，这周申请更换了 mac pro，其实入职申请的就是 mac，只不过不给我</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142135241.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>当然了，虽然工作内容不符合预期，吃的还是不错的，疯狂炫零食饮料，包括其他也可以看很多其他东西的，内部的一些文章，架构都是可以学习的，QA 工作一部分也是要看 RD 代码，所以还是可惜学习一下如何设计的，比如在 shopify program 这块业务线，针对 cronjob 实际上，按照我预想的设计，就只是简单的在容器中设置一个定时任务，但是在实际此处的实现，还是与我想的有差别的，通过自定义注解，将所有将要执行的任务注册进容器中，然后在启动类中实现 CommandLineRunner，每次对定时任务的调度通过任务名实现，可以避免我们单个服务一直占用资源，而且可以随时对任务进行调度，说到这，我再次期间还犯了个错，在第一次进行定时任务测试的时候，将定时任务跑到了线上环境，造成当天的定时任务跑了两次，第二天策略同学火速赶来，应为数据对不上，还好没造成太大影响，不然直接因 P0 事故被开除。此次之后，我就小心了，每次操作前都反复跟组内的人确认，讲真，当时完全是认为工作枯燥，干完收工的一个心态</p><p>在实习期间，还要处理之前学校的项目，进入二期，讲给师弟，完全手把手交，人都麻了，又赶上服务器前移，溜了几个查询语句号让他们上手，将近一个月，毫无进展，当然，维护过程中，还是有收获，比如在 nginx 配置 https，但是此时服务不开放 443 如何解决等问题，说实话，对于此类项目，不该找连几行点吗都没写过的来维护，毕竟真实在用的业务，不断的新需求与更改，可能给后面接手的人造成更大的麻烦</p><h2 id="发钱了"><a href="#发钱了" class="headerlink" title="发钱了"></a>发钱了</h2><p>不说了，按天结算，算不错账<br>字节不打卡，考勤完全自己报，leader 审批通过了就行，问题很大，狗头……可能是怕打卡的话员工搞事，十点上班起点正常下班，but 实际大家上到九点十点，无脑卷，资本家的糖衣炮弹让人疯狂，我直接 反卷先锋 贴在飞书</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142135561.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><h2 id="春游"><a href="#春游" class="headerlink" title="春游"></a>春游</h2><p>竟然是死去的春游，实验室竟然还没忘记春游，现在夏天都快过完了<br>啥峡谷漂流来着，机智如我，有四个小机灵鬼没去，听说有人失温了，那天感觉是最近俩月最冷的一天，十几度吧，加上下雨，收集 n 张票，开了 n 次越野，攀岩 n 次，射击 n 次，</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142145894.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142136693.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance week 3</title>
    <link href="http://raptor1998.top/2022/06/25/ByteDance5/"/>
    <id>http://raptor1998.top/2022/06/25/ByteDance5/</id>
    <published>2022-06-24T16:00:00.000Z</published>
    <updated>2022-08-15T12:39:01.340Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="业务理解"><a href="#业务理解" class="headerlink" title="业务理解"></a>业务理解</h1><p>从高空看program这块业务，实际上通过cronjob的手段将符合预定条件的广告主添加进某个流程中（Handraiser、payment ready……），并赋予一些相关的状态标签，切换拥有者，为owner添加其目前的分配数量，判断条件来源于tcc</p><p>目前理解的tcc是类似spring cloud config </p><hr><p>从代码层面看，通过定时任务，检索配置，推进流程：实现ApplicationListener&lt; ContextRefreshedEvent&gt;一般被用于在项目初始化动作完成后执行的自己业务拓展动作，作为应用初始化完毕后执行的动作（先InitializingBean）获取加Schedule注解的类，将任务注册进taskRegMap中，实现CommandLineRunner接口，容器启动之后，加载实现类的逻辑资源，已达到完成资源初始化的任务，然后准备执行任务，调用TaskInvoker 的 invoke 方法，从taskRegisterListener中获取任务实例执行：获取TCC配置，不等步长获取需要检测的adv，对获取到的实体进行条件检测，符合条件进行下一步推进</p><h1 id="小组氛围"><a href="#小组氛围" class="headerlink" title="小组氛围"></a>小组氛围</h1><p>组内一共五个人，三位女生，另一位男生休陪产假目前接触还不是很多，前面一周都是跟着junge去吃的，现在恰饭都是我一个人，妈耶，孤单。。。mentor她们喜欢吃盒饭，我觉得有点难顶，所以都是自己去食堂，偶尔她们吃餐厅才会一起。</p><p>感觉mentor怀孕有点不喜欢说话，每次碰到我也不知道说啥玩意好，可能是因为是小组长，不能跟你嬉皮笑脸的吧（狗头保命）</p><p>业务都是我旁边的xiayan在带，人美心善就是她了，感觉还没我年龄大。<br>业务上关键是我啥也不会，问的我都不好意思再问了。。。这里要吐槽一下，字节这内部平台也太多了，而且感觉全是在市面上的工具的改版，功能上可能差不多，但是用法上可能会有很大差距</p><p>这边一般九点下班（2022.8.3半夜前来更新，还没下班。。。麻了），太难了，抛出房租、生活费，希望我的实习期间能剩下个学费的钱。。。</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142254091.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>希望能在实习过程中，接触更多技术相关的东西，像樱木一样，从初学者到”灌篮高手“在短短几个月完成蜕变</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142253172.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance Culture</title>
    <link href="http://raptor1998.top/2022/06/20/ByteDance3/"/>
    <id>http://raptor1998.top/2022/06/20/ByteDance3/</id>
    <published>2022-06-19T16:00:00.000Z</published>
    <updated>2022-08-15T12:38:50.362Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="始终创业"><a href="#始终创业" class="headerlink" title="始终创业"></a>始终创业</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142151560.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><ul><li><p>保持创业心态，始终开创而不守成，创新而非依赖资源</p></li><li><p>敏捷有效，最简化流程，避免简单事情复杂化</p></li><li><p>对外敏锐谦逊，避免自满或优越感</p><h1 id="多元兼容"><a href="#多元兼容" class="headerlink" title="多元兼容"></a>多元兼容</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142200521.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p></li><li><p>欣赏个体多样性，聚焦人的核心特质</p></li><li><p>全球视角，理解不同文化、观点和实践</p></li><li><p>善意假设，默认开放信任，有效合作</p></li></ul><h1 id="坦诚清晰"><a href="#坦诚清晰" class="headerlink" title="坦诚清晰"></a>坦诚清晰</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142200247.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><ul><li>表达真实想法，不怕暴露问题，反对”向上管理”</li><li>准确、简洁、直接，少用抽象、模糊、空泛的词</li><li>就事论事，理性沟通，避免主观臆测和情绪化表达</li></ul><h1 id="求真务实"><a href="#求真务实" class="headerlink" title="求真务实"></a>求真务实</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142201517.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><ul><li>独立思考，刨根问底，找到本质</li><li>直接体验，深入事实，拿一手数据或信息</li><li>不自嗨，注重实际效果</li></ul><h1 id="敢为极致"><a href="#敢为极致" class="headerlink" title="敢为极致"></a>敢为极致</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142201235.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><ul><li>敢于为了更好的结果明智地冒险，注重整体ROI</li><li>尝试多种可能性，在更大范围里找最优解</li><li>追求卓越，高标准，不仅做了，更要做好</li></ul><h1 id="共同成长"><a href="#共同成长" class="headerlink" title="共同成长"></a>共同成长</h1><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208142201471.jpeg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><ul><li>相信并认可使命和愿景，基于使命愿景自驱</li><li>面对短期波动有耐心、有韧性，共同解决问题</li><li>持续学习，不设边界，与组织一起成长</li></ul></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy 消息队列</title>
    <link href="http://raptor1998.top/2022/06/10/ByteStudy%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://raptor1998.top/2022/06/10/ByteStudy%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2022-06-09T16:00:00.000Z</published>
    <updated>2022-08-15T12:21:42.276Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="为什么使用"><a href="#为什么使用" class="headerlink" title="为什么使用"></a>为什么使用</h1><p>解耦：通过Pub/Sub发布订阅消息这么一个模型，上游关注通知，而不关注校友处理。<br>缓冲：应对突发流量，假设一个每秒处理2k请求的服务，突然涌入很多流量，为防止为打宕机，可以使用mq，服务每秒从mq拉取2K个请求，保证不超过每秒能处理的最大请求数量即可，保证服务不会挂掉。高峰可能会堆积消息，短暂的积压是可以接受的，高峰过后每秒50个请求，但是服务依然以每秒2K的速度消费<br>广播：一条消息，可以被多个下游分别处理<br>持久化：消息可以被回溯</p><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h1 id="消息队列常见的一些问题处理思路"><a href="#消息队列常见的一些问题处理思路" class="headerlink" title="消息队列常见的一些问题处理思路"></a>消息队列常见的一些问题处理思路</h1><h2 id="队列的高可用"><a href="#队列的高可用" class="headerlink" title="队列的高可用"></a>队列的高可用</h2><p>rabbitmq的普通集群模式下，元数据存放在一个实例上，如果连接了其他实例，name那个实例会从queue所在的实例来取数据过来。这会导致消费者每次要么随机连接一个实例，或者固定那个queeu所在的实例消费，前者有数据拉取的开销，后者单实例瓶颈。</p><p>镜像集群：</p><p>在镜像集群下，创建的queue和元数据都存在于多个实例上，就是说每个mq的节点都有这个queue的完整镜像，每次些消息到queue时，会自动同步到多实例上<br>好处在于，任何一个机器宕机，其他节点都还有queue的完整数据<br>坏事处在于，性能开销大，消息同步到所有机器上，导致网络带宽压力和消耗都很大；没有拓展性可言，如果某个queue的负载很重，增加机器，新增的机器也是包含全部的数据，没办法线性拓展queue</p><h2 id="消息幂等性问题"><a href="#消息幂等性问题" class="headerlink" title="消息幂等性问题"></a>消息幂等性问题</h2><p>其实还是得结合实际业务场景来看，比如：<br>数据落库，可以先根据主键查一下，存在走update<br>写redis，天然幂等<br>或者生产者发送消息时，每条数据都加一个全局唯一id，消费的时候去redis查一下，之前是否消费过<br>或者基于数据库的唯一约束</p><h2 id="可靠性传输问题"><a href="#可靠性传输问题" class="headerlink" title="可靠性传输问题"></a>可靠性传输问题</h2><h2 id="顺序性问题"><a href="#顺序性问题" class="headerlink" title="顺序性问题"></a>顺序性问题</h2><p>rabbitmq的错乱场景，一个queue，多个consumer消费；一个queue，一个consumer，但是消费者多线程消费</p><ol><li>拆分queue，每个queue对应一个consumer，生产者发送的时候根据关键值哈希等操作，投放到同一个queue</li><li>一个queue对应一个consumer，consumer内部做内存队列做排队，然后分发给底层的worker处理<br>消费者获取消息后，不直接去消费消息，而是将消息根据关键值哈希放入内存队列，消费者线程去内存队列消费信息</li></ol><h2 id="堆积问题"><a href="#堆积问题" class="headerlink" title="堆积问题"></a>堆积问题</h2><p>一个简单的思路</p><p>先修复consumer的问题，确保其恢复消费速度，然后停掉现有的consumer<br>新建topic，partition是原来的十倍，临时建立好原来十倍的queue数量<br>写一个临时分发数据的consumer服务，去消费积压的数据，消费之后不做任何处理，直接轮询写入临时建立的queue中<br>接着征用十倍的机器来部署consumer，每一批consumer消费一个临时queue数据。这种做法相当于是将临时queeu资源和consumer资源扩大十倍，以十倍速度来消费数据<br>等加压数据消费完之后，再恢复原来的架构<br>如何设计一个消息队列</p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteStudy 为什么需要一把分布式锁？</title>
    <link href="http://raptor1998.top/2022/06/08/ByteStudy%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E4%B8%80%E6%8A%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F/"/>
    <id>http://raptor1998.top/2022/06/08/ByteStudy%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E4%B8%80%E6%8A%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F/</id>
    <published>2022-06-07T16:00:00.000Z</published>
    <updated>2022-08-15T12:42:22.935Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="为什么我们需要一把分布式锁？"><a href="#为什么我们需要一把分布式锁？" class="headerlink" title="为什么我们需要一把分布式锁？"></a>为什么我们需要一把分布式锁？</h1><p>为了效率(efficiency)，协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。比如重复发送了一封同样的email（当然这取决于业务应用的容忍度）。</p><p>为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，订单重复，超卖或者其它严重的问题。</p><h1 id="分布式锁的三个属性"><a href="#分布式锁的三个属性" class="headerlink" title="分布式锁的三个属性"></a>分布式锁的三个属性</h1><h2 id="互斥（Mutual-Exclusion）"><a href="#互斥（Mutual-Exclusion）" class="headerlink" title="互斥（Mutual Exclusion）"></a>互斥（Mutual Exclusion）</h2><p>这是锁最基本的功能，同一时刻只能有一个客户端持有锁；</p><h2 id="避免死锁（Dead-lock-free）"><a href="#避免死锁（Dead-lock-free）" class="headerlink" title="避免死锁（Dead lock free）"></a>避免死锁（Dead lock free）</h2><p>如果某个客户端获得锁之后花了太长时间处理，或者客户端发生了故障，锁无法释放会导致整个处理流程无法进行下去，所以要避免死锁。最常见的是通过设置一个 TTL(Time To Live，存活时间) 来避免死锁。</p><h2 id="容错（Fault-tolerance）"><a href="#容错（Fault-tolerance）" class="headerlink" title="容错（Fault tolerance）"></a>容错（Fault tolerance）</h2><p>为避免单点故障，锁服务需要具有一定容错性。大体有两种容错方式，一种是锁服务本身是一个集群，能够自动故障切换(ZooKeeper、etcd)；另一种是客户端向多个独立的锁服务发起请求，其中某个锁服务故障时仍然可以从其他锁服务读取到锁信息(Redlock)，代价是一个客户端要获取多把锁，并且要求每台机器的时钟都是一样的，否则 TTL 会不一致，可能有的机器会提前释放锁，有的机器会太晚释放锁，导致出现问题。</p><h1 id="常见的分布式锁实现方案"><a href="#常见的分布式锁实现方案" class="headerlink" title="常见的分布式锁实现方案"></a>常见的分布式锁实现方案</h1><ul><li>redis</li><li>mysql</li><li>zookeeper</li><li>。。。<h1 id="基于redis的分布式锁"><a href="#基于redis的分布式锁" class="headerlink" title="基于redis的分布式锁"></a>基于redis的分布式锁</h1><h2 id="错误的加锁：非原子操作"><a href="#错误的加锁：非原子操作" class="headerlink" title="错误的加锁：非原子操作"></a>错误的加锁：非原子操作</h2>使用redis的分布式锁，我们首先想到的是setnx命令，</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SET if Not Exists：</span><br><span class="line">   SETNX lockKey value</span><br><span class="line">   EXPIRE lockKey 30</span><br></pre></td></tr></tbody></table></figure></div><p>使用jedis的客户端代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (jedis.setnx(lockKey, val) == 1) {</span><br><span class="line">    jedis.expire(lockKey, timeout);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><p>虽然这两个命令和前面算法描述中的一个SET命令执行效果相同，但却不是原子的。如果客户端在执行完SETNX后崩溃了，那么就没有机会执行EXPIRE了，导致它一直持有这个锁。<br>加锁和设置超时两个操作是分开的，并非原子操作。假设加锁成功，但是设置锁超时失败，那么该lockKey永不失效。</p><blockquote><p>问题1：为什么这个锁必须要设置一个过期时间？</p></blockquote><p>当一个客户端获取锁成功之后，假如它崩溃了，或者它忘记释放锁，或者由于发生了网络分割（network partition）导致它再也无法和Redis节点通信了，那么它就会一直持有这个锁，而其它客户端永远无法获得锁了</p><blockquote><p>问题2：这个锁的有效时间设置多长比较合适？</p></blockquote><p>前面这个算法中出现的锁的有效时间(lock validity time)，设置成多少合适呢？如果设置太短的话，锁就有可能在客户端完成对于共享资源的访问之前过期，从而失去保护；如果设置太长的话，一旦某个持有锁的客户端释放锁失败，那么就会导致所有其它客户端都无法获取锁，从而长时间内无法正常工作。看来真是个两难的问题。</p><h2 id="正确的加锁姿势"><a href="#正确的加锁姿势" class="headerlink" title="正确的加锁姿势"></a>正确的加锁姿势</h2><p>Redis客户端为了获取锁，向Redis节点发送如下命令：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lockKey requestId NX PX 30000</span><br></pre></td></tr></tbody></table></figure></div><p>lockKey 是加锁的锁名；<br>requestId 是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的；（下面会分析它的作用）<br>NX 表示只有当lockKey对应的key值不存在的时候才能SET成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁；<br>PX 30000 设置过期时间，表示这个锁有一个30秒的自动过期时间。当然，这里30秒只是一个例子，客户端可以选择合适的过期时间。</p><p>在java中使用jedis包的调用方法是：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime)</span><br></pre></td></tr></tbody></table></figure></div><p><strong>问题：为什么要设置一个随机字符串requestId？如果没有会出现什么问题？</strong></p><p>下面释放锁的时候给出答案。</p><h2 id="依赖redis超时自动释放锁的问题"><a href="#依赖redis超时自动释放锁的问题" class="headerlink" title="依赖redis超时自动释放锁的问题"></a>依赖redis超时自动释放锁的问题</h2><p>如果按照如下方式加锁：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);</span><br><span class="line">if ("OK".equals(result)) {</span><br><span class="line">    return true;</span><br><span class="line">}</span><br><span class="line">return false;</span><br></pre></td></tr></tbody></table></figure></div><p>加锁之后，每次都会到expireTime之后才会释放锁，哪怕业务使用完这把锁了。所以更合理的做法是：</p><p>1、加锁；</p><p>2、业务操作；</p><p>3、主动释放锁；</p><p>4、如果主动释放锁失败了，则达到超时时间，redis自动释放锁。</p><p>暂时无法在飞书文档外展示此内容</p><p>如何释放锁呢？java代码里在finally中释放锁，即无论代码执行成功或者失败，都要释放锁。</p><p>try{<br>    String result = jedis.set(lockKey, requestId, “NX”, “PX”, expireTime);<br>    if (“OK”.equals(result)) {<br>        return true;<br>    }<br>    return false;<br>} finally {<br>    unlock(lockKey);<br>}</p><h2 id="释放了别人的锁"><a href="#释放了别人的锁" class="headerlink" title="释放了别人的锁"></a>释放了别人的锁</h2><p>上面那个unlock(lockKey)代码释放锁有什么问题？可能会出现释放别人的锁的问题。</p><p>有的同学可能会反驳：线程A获取了锁之后，它要是没有释放锁，这个时候别的线程假如线程B、C……根本不可能获取到锁，何来释放别人锁之说？</p><p>暂时无法在飞书文档外展示此内容</p><p>【1】客户端1获取锁成功。</p><p>【2】客户端1在某个操作上阻塞了很长时间。</p><p>【3】过期时间到了，锁自动释放了。</p><p>【4】客户端2获取到了对应同一个资源的锁。</p><p>【5】客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。</p><p>【6】另外线程客户端3此时可以成功请求到锁</p><p>如何解决这个问题：自己只能释放自己加的锁，不允许释放别人加的锁！</p><p>前面使用set命令加锁的时候，除了使用lockKey锁标识之外，还使用了一个requestId，这个requestId的作用是什么呢？</p><p>requestId是在释放锁的时候用的！！！</p><p>伪代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (jedis.get(lockKey).equals(requestId)) {</span><br><span class="line">    jedis.del(lockKey);</span><br><span class="line">    return true;</span><br><span class="line">}</span><br><span class="line">return false;</span><br></pre></td></tr></tbody></table></figure></div><p>所以在释放锁的时候，先要获取到该锁的值（就是每个加锁线程自己设置的requestId），然后判断跟之前自己设置的值是否相同，如果相同才允许删除锁，返回成功，如果不同，直接返回失败。</p><p><strong>问题：为什么要设置一个随机字符串requestId？如果没有会出现什么问题？</strong></p><p>设置一个随机字符串requestId是必要的，它保证了一个客户端释放的锁必须是自己持有的那个锁。假如获取锁时SET的不是一个随机字符串，而是一个固定值，那么可能导致释放别人的锁。所以要保证requestId全局唯一。</p><h2 id="释放锁的问题：非原子操作"><a href="#释放锁的问题：非原子操作" class="headerlink" title="释放锁的问题：非原子操作"></a>释放锁的问题：非原子操作</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (jedis.get(lockKey).equals(requestId)) {</span><br><span class="line">    jedis.del(lockKey);</span><br><span class="line">    return true;</span><br><span class="line">}</span><br><span class="line">return false;</span><br></pre></td></tr></tbody></table></figure></div><p>显然，jedis.get(lockKey).equals(requestId) 这行代码包含了【获取该锁的值】，【判断是否是自己加的锁】，【删除锁】这三个操作，万一这三个操作中间的某个时刻出现阻塞</p><p>暂时无法在飞书文档外展示此内容<br>【1】客户端1获取锁成功；<br>【2】客户端1进行业务操作；<br>【3】客户端1为了释放锁，先执行’GET’操作获取随机字符串的值。<br>【4】客户端1判断随机字符串的值，与预期的值相等。<br>【5】客户端1由于某个原因阻塞住了很长时间。<br>【6】过期时间到了，锁自动释放了。<br>【7】客户端2获取到了对应同一个资源的锁。<br>【8】客户端1从阻塞中恢复过来，执行DEL操纵，释放掉了客户端2持有的锁。</p><p>实际上，如果不是客户端1阻塞住了，而是出现了大的网络延迟，也有可能导致类似的执行序列发生。</p><p>问题的根源：锁的判断在客户端，但是锁的删除却在服务端！</p><h2 id="正确的释放锁姿势"><a href="#正确的释放锁姿势" class="headerlink" title="正确的释放锁姿势"></a>正确的释放锁姿势</h2><p>正确的释放锁姿势——锁的判断和删除都在服务端（redis），使用lua脚本保证原子性：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if redis.call("get",KEYS[1]) == ARGV[1] then</span><br><span class="line">    return redis.call("del",KEYS[1])</span><br><span class="line">else</span><br><span class="line">    return 0</span><br><span class="line">end</span><br></pre></td></tr></tbody></table></figure></div><p>这段Lua脚本在执行的时候要把前面的requestId作为ARGV[1]的值传进去，把lockKey作为KEYS[1]的值传进去。</p><p>释放锁的操作为什么要使用lua脚本？<br>释放锁其实包含三步操作：’GET’、判断和’DEL’，用Lua脚本来实现能保证这三步的原子性。</p><h2 id="锁超时问题"><a href="#锁超时问题" class="headerlink" title="锁超时问题"></a>锁超时问题</h2><p>如果客户端1请求锁成功了，但是由于业务处理、GC、操作系统等原因导致它处理时间过长，超过了锁的时间，这时候redis会自动释放锁，这种情况可能导致问题：</p><p>如何解决这种问题？</p><p>—- 续期，java里我们可以使用TimerTask类来实现自动续期的功能，伪代码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Timer timer = new Timer();</span><br><span class="line">timer.schedule(new TimerTask() {</span><br><span class="line">    @Override</span><br><span class="line">    public void run(Timeout timeout) throws Exception {</span><br><span class="line">        //自动续期逻辑􁛔􀛖􁖅􀹗􁭦􁬋</span><br><span class="line">    }</span><br><span class="line">}, 10000, TimeUnit.MILLISECONDS);</span><br></pre></td></tr></tbody></table></figure></div><p>这个机制在redisson框架中已经实现，而且还有一个比较霸气的名字watchdog（看门狗）：加锁时没有指定加锁时间时会启用watchdog机制，默认加锁30秒，每10秒钟检查一次，如果存在就重新设置 过期时间为30秒（即30秒之后它就不再续期了）</p><p>lockWatchdogTimeout（监控锁的看门狗超时，单位：毫秒）</p><p>默认值：30000</p><p>监控锁的看门狗超时时间单位为毫秒。该参数只适用于分布式锁的加锁请求中未明确使用leaseTimeout参数的情况。如果该看门狗未使用lockWatchdogTimeout去重新调整一个分布式锁的</p><p>lockWatchdogTimeout超时，那么这个锁将变为失效状态。这个参数可以用来避免由Redisson客户端节点宕机或其他原因造成死锁的情况。</p><h1 id="Redis主从架构数据同步复制问题"><a href="#Redis主从架构数据同步复制问题" class="headerlink" title="Redis主从架构数据同步复制问题"></a>Redis主从架构数据同步复制问题</h1><p>我们通常使用「Redis Cluster」或者「哨兵模式」这两种方式实现redis的高可用，而这两种方式都是基于「主从架构数据同步复制」实现的，而redis默认的主从复制是异步的。</p><p>前面铺垫的redis锁在单点实例中是没有问题的，因为并没有涉及redis的高可用部署架构细节。但是如果多实例的情况下会出现什么问题呢？比如：主从、或者使用了哨兵模式、或者redis cluster。redis的主从架构如下所示：</p><p>Redis所有的写操作都是先在Master上操作，然后同步更新到Slave上，Slave只能读不能写。<br>丢失数据场景：当网络发生脑裂（split-brain）或者partitioned cluster集群分裂为多数派与少数派，如果数据继续写入少数派的Master，则当Cluster感知，并停止少数派Master，或者重新选主时，则面临丢失刚才已写入少数派的数据</p><p>主从发生重新选导致分布式锁出现问题的场景：<br>暂时无法在飞书文档外展示此内容</p><h1 id="WAIT命令能够为Redis实现强一致吗？"><a href="#WAIT命令能够为Redis实现强一致吗？" class="headerlink" title="WAIT命令能够为Redis实现强一致吗？"></a>WAIT命令能够为Redis实现强一致吗？</h1><p>WAIT numreplicas timeout </p><p>numreplicas：指定副本（slave）的数量。</p><p>timeout：超时时间，时间单位为毫秒；当设置为0 时，表示无限等待，即用不超时。</p><p>WAIT命令作用：WAIT 命令阻塞当前客户端，直到所有先前的写入命令成功传输，并且由至少指定数量的副本（slave）确认。在主从、sentinel和Redis群集故障转移中， WAIT能够增强（仅仅是增强，但不是保证）数据的安全性。</p><p>官方文档：<a href="https://redis.io/commands/wait" target="_blank" rel="noopener">https://redis.io/commands/wait</a></p><p>结论： WAIT 不能保证 Redis 的强一致性</p><h1 id="Redlock算法"><a href="#Redlock算法" class="headerlink" title="Redlock算法"></a>Redlock算法</h1><p>针对上面的问题，redis之父antirez设计了Redlock算法，Redlock的算法描述就放在Redis的官网上：<br><a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">https://redis.io/topics/distlock</a></p><p>在Redlock之前，很多人对于分布式锁的实现都是基于单个Redis节点的。而Redlock是基于多个Redis节点（都是Master）的一种实现。前面基于单Redis节点的算法是Redlock的基础。<br>加锁<br>Redlock算法基于N个完全独立的Redis节点，客户端依次执行下面各个步骤，来完成获取锁的操作：</p><p>【1】获取当前时间T1（毫秒数）。</p><p>【2】使用相同的key、value按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。</p><p>【3】获取当前时间T2减去步骤1中的T1，计算获取锁消耗了多长时间（T3= T2-T1），计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（大于等于 N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</p><p>【4】如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</p><p>【5】如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</p><p>注意！！！：redLock会直接连接多个redis主节点，不是通过集群机制连接的。<br>RedLock的写与主从集群无关，直接操作的是所有主节点，所以才能避开主从故障切换时锁丢失的问题。</p><h2 id="失败重试（脑裂问题）"><a href="#失败重试（脑裂问题）" class="headerlink" title="失败重试（脑裂问题）"></a>失败重试（脑裂问题）</h2><p>高并发场景下，当多个加锁线程并发抢锁时，可能导致脑裂，最终造成任何一个线程都无法抢到锁的情况。<br>暂时无法在飞书文档外展示此内容所以当一个加锁线程无法获得锁的时候，应该在一个随机延时后再一次尝试获得锁。加锁线程从多数redis实例中获得锁越快，出现脑裂的窗口越小（重试的次数也越少）。所以理想情况下，加锁线程应该多路复用地同时向N个实例发送加锁命令。</p><p>值得强调的是，如果获取大部分锁失败，加锁线程应该尽可能快的释放（部分）已经获得了的锁。所以为了让锁能够再次被获得就没有必要等待key过期（然而如果发生了网络分区导致客户端无法再与redis实例交互，那么就必须等待key过期才能重新抢到锁）。</p><h2 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h2><p>Redlock算法释放锁的过程比较简单：客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。</p><blockquote><p>问题1：为什么要在多个实例上加锁？<br>本质上为了容错，部分实例异常宕机，剩余实例只要超过N/2+1依旧可用。多个实例节点，实际上构建了一个分布式锁系统。分布式系统中，总会有异常节点，所以需要考虑异常节点达到多少个，也不会影响整个系统的正确性。（可以参考一下拜占庭将军问题的分析）</p></blockquote><blockquote><p>问题2：为什么步骤3加锁成功之后，还要计算加锁的累计耗时？<br>因为加锁操作的针对的是分布式中的多个节点，所以耗时肯定是比单个实例耗时更久，至少需要N/2+1个网络来回，还要考虑网络延迟、丢包、超时等情况发生，网络请求次数越多，异常的概率越大。<br>所以即使N/2+1个节点加锁成功，但如果加锁的累计耗时已经超过了锁的过期时间，那么此时的锁已经没有意义了。</p></blockquote><blockquote><p>问题3：为什么释放锁，要操作所有节点，对所有节点都释放锁？<br>因为当对某一个redis节点加锁时，可能因为网络原因导致加锁“失败”。注意这个“失败”，指的是redis节点实际已经加锁成功了，但是返回的结果因为网络延迟并没有传到加锁的线程，被加锁线程丢弃了，加锁线程误以为没有成功，于是加锁线程去尝试下一个节点了。</p></blockquote><p>所以释放锁的时候，不管以前有没有加锁成功，都要释放所有节点的锁，以保证清除节点上述图中发生的情况导致残留的锁。</p><p>崩## 溃恢复（AOF持久化）对Redlock算法影响</p><p>假设Rodlock算法中的redis发生了崩溃-恢复，那么锁的安全性将无法保证。假设加锁线程在5个实例中对其中3个加锁成功，获得了这把分布式锁，这个时候3个实例中有一个实例被重启了。重启后的实例将丢失其中的锁信息，这个时候另一个加锁线程可以对这个实例加锁成功，此时两个线程同时持有分布式锁。锁的安全性被破坏。</p><p>暂时无法在飞书文档外展示此内容如果我们配置了AOF持久化，只能减少它发生的概率而无法保证锁的绝对安全。断电的场景下，如果redis被配置了默认每秒同步数据到硬盘，重启之后lockKey可能会丢失，理论上，如果我们想要保证任何实例重启的情况下锁都是安全的，需要在持久化配置中设置<br>fsync=always，但此时redis的性能将大大打折扣。</p><p>为了保证这一点，我们只需要让一个崩溃时间、不可用时间（实例崩溃后存在的锁的所有key所需的时间）比最大TTL还要长的实例变成非法和自动释放的。<br>如果不配置redis持久化，那么只能使用延迟重启保证锁的安全性。</p><p>结论：为了保证Redlock算法的安全性，有如下两种手段</p><h2 id="持久化配置中设置"><a href="#持久化配置中设置" class="headerlink" title="持久化配置中设置"></a>持久化配置中设置</h2><p>fsync=always，性能大大降低<br>恰当的运维，把崩溃节点进行延迟重启，超过崩溃前所有锁的</p><p>TTL时间之后才加入Redlock节点组<br>redis分布式锁官方文档翻译</p><h2 id="Redlock算法存在的问题"><a href="#Redlock算法存在的问题" class="headerlink" title="Redlock算法存在的问题"></a>Redlock算法存在的问题</h2><p>Redlock论战：Martin Kleppmann vs. Antirez<br>Martin Kleppmann是剑桥大学的分布式系统专家，《数据密集型应用系统设计》一书的作者。<br>Antirez 是redis的作者，redlock算法的作者。<br>Redis之父Antirez实现Redlock算法之后。有一天，Martin Kleppmann写了一篇blog，分析了Redlock在安全性上存在的一些问题。然后Redis的作者立即写了一篇blog来反驳Martin的分析。但Martin表示仍然坚持原来的观点。随后，这个问题在Twitter和Hacker News上引发了激烈的讨论，很多分布式系统的专家都参与其中。</p><p><a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">https://redis.io/topics/distlock</a><br><a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html" target="_blank" rel="noopener">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a><br><a href="http://antirez.com/news/101" target="_blank" rel="noopener">http://antirez.com/news/101</a></p><p>Martin Kleppmann在2016-02-08这一天发表了一篇blog，名字叫“How to do distributed locking”，地址如下：<br><a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html" target="_blank" rel="noopener">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></p><p>Martin在这篇文章中谈及了分布式系统的很多基础性的问题（特别是分布式计算的异步模型），对分布式系统的从业者来说非常值得一读。这篇文章大体可以分为两大部分：<br>前半部分，与Redlock无关。Martin指出，即使我们拥有一个完美实现的分布式锁（带自动过期功能），在没有共享资源参与进来提供某种fencing机制的前提下，我们仍然不可能获得足够的安全性。<br>后半部分，是对Redlock本身的批评。Martin指出，由于Redlock本质上是建立在一个同步模型之上，对系统的记时假设(timing assumption)有很强的要求，因此本身的安全性是不够的。<br>客户端长期阻塞导致锁过期<br>首先我们讨论一下前半部分的关键点。Martin给出了下面这样一份时序图：</p><p>在上面的时序图中，假设锁服务本身是没有问题的，它总是能保证任一时刻最多只有一个客户端获得锁。上图中出现的lease这个词可以暂且认为就等同于一个带有自动过期功能的锁。客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。</p><p>初看上去，有人可能会说，既然客户端1从GC pause中恢复过来以后不知道自己持有的锁已经过期了，那么它可以在访问共享资源之前先判断一下锁是否过期。但仔细想想，这丝毫也没有帮助。因为GC pause可能发生在任意时刻，也许恰好在判断完之后。<br>也有人会说，如果客户端使用没有GC的语言来实现，是不是就没有这个问题呢？Martin指出，系统环境太复杂，仍然有很多原因导致进程的pause，比如虚存造成的缺页故障(page fault)，再比如CPU资源的竞争。即使不考虑进程pause的情况，网络延迟也仍然会造成类似的结果。<br>总结起来就是说，即使锁服务本身是没有问题的，而仅仅是客户端有长时间的pause或网络延迟，仍然会造成两个客户端同时访问共享资源的冲突情况发生。而这种情况其实就是我们在前面已经提出来的“客户端长期阻塞导致锁过期”的那个疑问。<br>解决方案——fencing token<br>那怎么解决这个问题呢？Martin给出了一种方法，称为fencing token。fencing token是一个单调递增的数字，当客户端成功获取锁的时候它随同锁一起返回给客户端。而客户端访问共享资源的时候带着这个fencing token，这样提供共享资源的服务就能根据它进行检查，拒绝掉延迟到来的访问请求（避免了冲突）。如下图：</p><p>在上图中，客户端1先获取到的锁，因此有一个较小的fencing token，等于33，而客户端2后获取到的锁，有一个较大的fencing token，等于34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次33的请求。这样就避免了冲突。<br>（问题：考虑网络延迟导致33号token比34号先到的情景）<br>时间跳跃<br>Martin在文中构造了一些事件序列，能够让Redlock失效（两个客户端同时持有锁）。为了说明Redlock对系统记时(timing)的过分依赖，他首先给出了下面的一个例子（还是假设有5个Redis节点A, B, C, D, E）：<br>客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。<br>节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。<br>客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。<br>客户端1和客户端2现在都认为自己持有了锁。<br>上面这种情况之所以有可能发生，本质上是因为Redlock的安全性(safety property)对系统的时钟有比较强的依赖，一旦系统的时钟变得不准确，算法的安全性也就保证不了了。Martin在这里其实是要指出分布式算法研究中的一些基础性问题，或者说一些常识问题，即好的分布式算法应该基于异步模型(asynchronous model)，算法的安全性不应该依赖于任何记时假设(timing assumption)。在异步模型中：进程可能pause任意长的时间，消息可能在网络中延迟任意长的时间，甚至丢失，系统时钟也可能以任意方式出错。一个好的分布式算法，这些因素不应该影响它的安全性(safety property)，只可能影响到它的活性(liveness property)，也就是说，即使在非常极端的情况下（比如系统时钟严重错误），算法顶多是不能在有限的时间内给出结果而已，而不应该给出错误的结果。这样的算法在现实中是存在的，像比较著名的Paxos，或Raft。但显然按这个标准的话，Redlock的安全性级别是达不到的。</p><p>在Martin的这篇文章中，还有一个很有见地的观点，就是对锁的用途的区分。他把锁的用途分为两种：<br>为了效率(efficiency)，协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。比如重复发送了一封同样的email。<br>为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，或者其它严重的问题。<br>最后，Martin得出了如下的结论：<br>如果是为了效率(efficiency)而使用分布式锁，允许锁的偶尔失效，那么使用单Redis节点的锁方案就足够了，简单而且效率高。Redlock则是个过重的实现(heavyweight)。<br>如果是为了正确性(correctness)在很严肃的场合使用分布式锁，那么不要使用Redlock。它不是建立在异步模型上的一个足够强的算法，它对于系统模型的假设中包含很多危险的成分(对于timing)。而且，它没有一个机制能够提供fencing token。那应该使用什么技术呢？Martin认为，应该考虑类似Zookeeper的方案，或者支持事务的数据库。<br>Martin对Redlock算法的形容是：<br>neither fish nor fowl （不伦不类）</p><p>【其它疑问】<br>Martin提出的fencing token的方案，需要对提供共享资源的服务进行修改，这在现实中可行吗？<br>根据Martin的说法，看起来，如果资源服务器实现了fencing token，它在分布式锁失效的情况下也仍然能保持资源的互斥访问。这是不是意味着分布式锁根本没有存在的意义了？<br>资源服务器需要检查fencing token的大小，如果提供资源访问的服务也是包含多个节点的（分布式的），那么这里怎么检查才能保证fencing token在多个节点上是递增的呢？<br>Martin对于fencing token的举例中，两个fencing token到达资源服务器的顺序颠倒了（小的fencing token后到了），这时资源服务器检查出了这一问题。如果客户端1和客户端2都发生了GC pause，两个fencing token都延迟了，它们几乎同时到达了资源服务器，但保持了顺序，那么资源服务器是不是就检查不出问题了？这时对于资源的访问是不是就发生冲突了？</p><p>1、问题一：节点重启<br>N个Redis节点中如果有节点发生崩溃重启，会对锁的安全性有影响的。具体的影响程度跟Redis对数据的持久化程度有关。参考上面的“崩溃恢复（AOF持久化）对Redlock算法影响”分析。<br>【备注】在默认情况下，Redis的AOF持久化方式是每秒写一次磁盘（即执行fsync），因此最坏情况下可能丢失1秒的数据。为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据（这取决于系统而不是Redis的实现）。所以，上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。</p><p>如何解决这个问题？<br>redis之父antirez提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。</p><p>2、问题二：时钟变迁<br>Redlock的安全性(safety property)对系统的时钟有比较强的依赖，一旦系统的时钟变得不准确，算法的安全性也就保证不了了。<br>结论：redis的过期时间是依赖系统时钟的，如果时钟漂移过大时会影响到过期时间的计算。<br>为什么系统时钟会存在漂移呢？先简单说下系统时间，linux提供了两个系统时间：clock realtime和clock monotonic<br>clock realtime</p><p>也就是xtime/wall time，这个时间是可以被用户改变的，被NTP改变。redis的判断超时使用的gettimeofday函数取的就是这个时间，redis的过期计算用的也是这个时间。参考<a href="https://blog.habets.se/2010/09/gettimeofday-should-never-be-used-to-measure-time.html" target="_blank" rel="noopener">https://blog.habets.se/2010/09/gettimeofday-should-never-be-used-to-measure-time.html</a><br>clock monotonic</p><p>，直译过来是单调时间，不会被用户改变，但是会被NTP改变。<br>最理想的情况是：所有系统的时钟都时时刻刻和NTP服务器保持同步，但这显然是不可能的。<br>clock realtime可以被人为修改，在实现分布式锁时，不应该使用clock realtime。不过很可惜，redis使用的就是这个时间，Redis 5.0使用的还是clock realtime。Antirez说过后面会改成clock monotonic的。也就是说，人为修改redis服务器的时间，就能让redis出问题了。<br>暂时无法在飞书文档外展示此内容<br>【1】加锁线程1从节点Redis1, Redis2, Redis3成功获取了锁（多数节点）。由于网络问题，与Redis4、Redis5通信失败。<br>【2】节点Redis3上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。<br>【3】加锁线程2从Redis3, Redis4, Redis5成功获取了同一个资源的锁（多数节点）。<br>【4】加锁线程1和加锁线程2现在都认为自己持有了锁。</p><p>什么情况下会发生时钟变迁？<br>人为修改了时钟<br>从NTP服务收到了一个大的时钟更新事件导致时钟漂移<br>闰秒（是指为保持协调世界时接近于世界时时刻，由国际计量局统一规定在年底或年中或者季末对协调世界时增加或减少1秒的调整，此时一分钟为59秒或者61秒，闰秒曾使许多大型系统崩溃）<br>……</p><p>如何解决这个问题？<br>（1）redis之父antirez在redlock论战中的解释：实际系统中是可以避免大的时钟跳跃的。当然，这取决于基础设施和运维方式。（实际上这种理想情况是很难达到的，不同的redis节点，毫秒级别的时间误差几乎是必然存在的。）<br>（2）Fencing token机制：类似raft算法、zab协议中的全局递增数字，对这个token的校验需要后端资源进行校验，如此一来，相当于后端资源具备了互斥机制，这种情况下为什么还要一把分布式锁呢？而且涉及到后端资源的改造。</p><p>总结<br>RedLock算法数建立在了 Time 是可信的模型上的一种分布式锁，所以时间被破坏的情况下它无法实现锁的绝对安全；<br>RedLock算法实现比较复杂，并且性能比较差；<br>RedLock需要恰当的运维保障它的正确性，故障-崩溃之后需要一套延迟重启的机制</p><p>RedLock的核心价值，在于多数派思想。相比于基于单点Redis的锁服务，RedLock解决了锁数据写入时多份的问题，从而可以克服单点故障下的数据一致性问题。在继承自基于单点的Redis锁服务缺陷（解锁不具备原子性；锁服务、调用方、资源方缺乏确认机制）的基础上，其核心的问题为：缺乏锁数据丢失的识别和感知机制。<br>RedLock中的每台Redis，充当的仍旧只是存储锁数据的功能，每台Redis之间各自独立，单台Redis缺乏全局的信息，自然也不知道自己的锁数据是否是完整的。在单台Redis数据的不完整的前提下，没有分布式共识机制，使得在各种分布式环境的典型场景下（结点故障、网络丢包、网络乱序），没有完整数据但参与决策，从而破坏数据一致性。</p><p>基于Mysql的分布式锁（ShedLock）<br>使用ShedLock需要在Mysql数据库创建一张加锁用的表：<br>CREATE TABLE shedlock<br>(<br>    name VARCHAR(64),<br>    lock_until TIMESTAMP(3) NULL,<br>    locked_at TIMESTAMP(3) NULL,<br>    locked_by VARCHAR(255),<br>    PRIMARY KEY (name)<br>)</p><p>加锁<br>通过插入同一个name(primary key)，或者更新同一个name来抢，对应的intsert、update的SQL为：</p><p>INSERT INTO shedlock<br>(name, lock_until, locked_at, locked_by)<br>VALUES<br>(锁名字,  当前时间+最多锁多久,  当前时间, 主机名)<br>UPDATE shedlock<br>SET lock_until = 当前时间+最多锁多久,<br>locked_at = 当前时间,<br>locked_by = 主机名 WHERE name = 锁名字 AND lock_until &lt;= 当前时间 </p><p>释放锁：<br>通过设置lock_until来实现释放，再次抢锁的时候需要通过lock_util来判断锁失效了没。对应的SQL为：<br>UPDATE shedlock<br>SET lock_until = lockTime WHERE name = 锁名字<br>问题分析<br>1、单点问题；<br>2、主从同步问题。假如使用全同步模式，分布式锁将会有性能上的问题。</p><p>基于zookeeper的分布式锁<br>zookeeper的节点类型<br>Zookeeper的数据存储结构就像一棵树，这棵树由节点组成，这种节点叫做Znode。Znode分为四种类型：<br>持久节点 （PERSISTENT）</p><p>默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。<br>持久节点顺序节点（PERSISTENT_SEQUENTIAL）</p><p>所谓顺序节点，就是在创建节点时，Zookeeper根据创建的顺序给该节点名称进行编号：<br>临时节点（EPHEMERAL）</p><p>和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除：<br>临时顺序节点（EPHEMERAL_SEQUENTIAL）</p><p>【使用该类型节点实现分布式锁】<br>顾名思义，临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。<br>zookeeper的watch机制<br>zookeeper集群和客户端通过长连接维护一个session，当客户端试图创建/lock节点的时候，发现它已经存在了，这时候创建失败，但客户端不一定就此返回获取锁失败。客户端可以进入一种等待状态，等待当/lock节点被删除的时候，ZooKeeper通过watch机制通知它，这样它就可以继续完成创建操作（获取锁）。这可以让分布式锁在客户端用起来就像一个本地的锁一样：加锁失败就阻塞住，直到获取到锁为止。这样的特性redis的Redlock就无法实现。<br>暂时无法在飞书文档外展示此内容</p><p>加锁&amp;释放锁<br>客户端尝试创建一个znode节点，比如/lock。那么第一个客户端就创建成功了，相当于拿到了锁；而其它的客户端会创建失败（znode已存在），获取锁失败。<br>持有锁的客户端访问共享资源完成后，将znode删掉，这样其它客户端接下来就能来获取锁了。（<br>客户端删除锁）<br>znode应该被创建成<br>EPHEMERAL_SEQUENTIAL的。这是znode的一个特性，它保证如果创建znode的那个客户端崩溃了，那么相应的znode会被自动删除，。这保证了锁一定会被释放（zookeeper服务器自己删除锁）。另外保证了公平性，后面创建的节点会加在节点链最后的位置，等待锁的客户端会按照先来先得的顺序获取到锁。</p><p>暂时无法在飞书文档外展示此内容<br>惊群效应：错误的实现——如果实现zookeeper分布式锁的时候，所有后加入的节点都监听最小的节点。那么删除节点的时候，所有客户端都会被唤醒，这个时候由于通知的客户端很多，通知操作会造成zookeeper性能突然下降，这样会影响zookeeper的使用。<br>时钟变迁问题Zookeeper不依赖全局时间，它使用zab协议实现分布式共识算法，不存在该问题。<br>超时导致锁失效问题Zookeeper不依赖有效时间，它依靠心跳维持锁的占用状态，不存在该问题。</p><p>看起来这个锁相当完美，没有Redlock过期时间的问题，而且能在需要的时候让锁自动释放。但仔细考察的话，并不尽然。客户端可以删除锁，zookeeper服务器也可以删除锁，会引发什么问题。<br>zookeeper是怎么检测出某个客户端已经崩溃了呢？<br>实际上，每个客户端都与ZooKeeper的某台服务器维护着一个Session，这个Session依赖定期的心跳(heartbeat)来维持。如果ZooKeeper长时间收不到客户端的心跳（这个时间称为Sesion的过期时间），那么它就认为Session过期了，通过这个Session所创建的所有的ephemeral类型的znode节点都会被自动删除。</p><p>基于zookeeper的分布式锁存在的问题：<br>【1】客户端1创建了znode节点/lock，获得了锁。<br>【2】客户端1进入了长时间的GC pause。（或者网络出现问题、或者zk服务检测心跳线程出现问题等等）<br>【3】客户端1连接到ZooKeeper的Session过期了。znode节点/lock被自动删除。<br>【4】客户端2创建了znode节点/lock，从而获得了锁。<br>【5】客户端1从GC pause中恢复过来，它仍然认为自己持有锁。<br>这个场景下，客户端1和客户端2在一段窗口时间内同时获取到锁。</p><p>结论：使用zookeeper的临时节点实现的分布式锁，它的锁安全期是在客户端取得锁之后到zk服务器会话超时的阈值（跨机房部署很容易出现）的时间之间。它无法设置占用分布式锁的时间，何时zk服务器会删除锁是不可预知的，所以这种方式它比较适合一些客户端获取到锁之后能够快速处理完毕的场景。</p><p>另一种方案<br>另外一种使用zk作分布式锁的实现方式：不使用临时节点，而是使用持久节点加锁，把zk集群当做一个mysql、或者一个单机版的redis，加锁的时候存储锁的到期时间，这种方案把锁的删除、判断过期这两个职责交给客户端处理。（当做一个可以容错的mysql，性能问题！）</p><p>ZooKeeper分布式锁的优点和缺点<br>总结一下ZooKeeper分布式锁：<br>优点：<br>（1）ZooKeeper分布式锁基于分布式一致性算法实现，能有效的解决分布式问题，不受时钟变迁影响，不可重入问题，使用起来也较为简单；<br>（2）当锁持有方发生异常的时候，它和Zookeeper之间的session无法维护。Zookeeper会在Session租约到期后，自动删除该Client持有的锁，以避免锁长时间无法释放而导致死锁。<br>缺点：<br>ZooKeeper实现的分布式锁，性能并不太高。为啥呢？因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。大家知道，ZK中创建和删除节点只能通过Leader服务器来执行，然后Leader服务器还需要将数据同步不到所有的Follower机器上，这样频繁的网络通信，性能的短板是非常突出的。<br>总之，在高性能，高并发的场景下，不建议使用ZooKeeper的分布式锁。而由于ZooKeeper的高可用特性，所以在并发量不是太高的场景，推荐使用ZooKeeper的分布式锁。</p><p>小结一下，基于ZooKeeper的锁和基于Redis的锁相比在实现特性上有两个不同：<br>在正常情况下，客户端可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于Redis的锁对于有效时间(lock validity time)到底设置多长的两难问题。实际上，基于ZooKeeper的锁是依靠Session（心跳）来维持锁的持有状态的，而Redis不支持Sesion。<br>基于ZooKeeper的锁支持在获取锁失败之后等待锁重新释放的事件。这让客户端对锁的使用更加灵活。</p><p>Chubby<br>提到分布式锁，就不能不提Google的Chubby。<br>Chubby是Google内部使用的分布式锁服务，有点类似于ZooKeeper，但也存在很多差异。Chubby对外公开的资料，主要是一篇论文，叫做“The Chubby lock service for loosely-coupled distributed systems”，下载地址如下：<br><a href="https://research.google.com/archive/chubby.html" target="_blank" rel="noopener">https://research.google.com/archive/chubby.html</a></p><p>另外，YouTube上有一个的讲Chubby的talk，也很不错，播放地址：<br><a href="https://www.youtube.com/watch?v=PqItueBaiRg&amp;feature=youtu.be&amp;t=487" target="_blank" rel="noopener">https://www.youtube.com/watch?v=PqItueBaiRg&amp;feature=youtu.be&amp;t=487</a></p><p>Chubby自然也考虑到了延迟造成的锁失效的问题。论文里有一段描述如下：<br>a process holding a lock L may issue a request R, but then fail. Another process may ac- quire L and perform some action before R arrives at its destination. If R later arrives, it may be acted on without the protection of L, and potentially on inconsistent data.<br>（译文： 一个进程持有锁L，发起了请求R，但是请求失败了。另一个进程获得了锁L并在请求R到达目的方之前执行了一些动作。如果后来请求R到达了，它就有可能在没有锁L保护的情况下进行操作，带来数据不一致的潜在风险。）<br>这跟前面Martin的分析大同小异。</p><p>Chubby给出的用于解决（缓解）这一问题的机制称为sequencer，类似于fencing token机制。锁的持有者可以随时请求一个sequencer，这是一个字节串，它由三部分组成：<br>锁的名字。</p><p>锁的获取模式（排他锁还是共享锁）。</p><p>lock generation number（一个64bit的单调递增数字）。作用相当于fencing token或epoch number。</p><p>sequencer：客户端拿到sequencer之后，在操作资源的时候把它传给资源服务器。然后，资源服务器负责对sequencer的有效性进行检查。检查可以有两种方式：<br>调用Chubby提供的API，<br>CheckSequencer()，将整个sequencer传进去进行检查。这个检查是为了保证客户端持有的锁在进行资源访问的时候仍然有效。<br>将客户端传来的sequencer与资源服务器当前观察到的<br>最新的sequencer进行对比检查。可以理解为与Martin描述的对于fencing token的检查类似。<br>锁延期机制：当然，如果由于兼容的原因，资源服务本身不容易修改，那么Chubby还提供了一种机制：<br>lock-delay</p><p>。Chubby允许客户端为持有的锁指定一个lock-delay的时间值（默认是1分钟）。当Chubby发现客户端被动失去联系的时候，并不会立即释放锁，而是会在lock-delay指定的时间内阻止其它客户端获得这个锁。这是为了在把锁分配给新的客户端之前，让之前持有锁的客户端有充分的时间把请求队列排空(draining the queue)，尽量防止出现延迟到达的未处理请求。</p><p>可见，为了应对锁失效问题，Chubby提供的两种处理方式：CheckSequencer()检查与上次最新的sequencer对比、lock-delay，它们对于安全性的保证是从强到弱的。而且，这些处理方式本身都没有保证提供绝对的正确性(correctness)。但是，Chubby确实提供了单调递增的lock generation number，这就允许资源服务器在需要的时候，利用它提供更强的安全性保障。</p><p>总结起来，Chubby引入了资源方和锁服务的验证，来避免了锁服务本身孤立地做预防死锁机制而导致的破坏锁安全性的风险。同时依靠Session来维持锁的持有状态，在正常情况下，客户端可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于Redis的锁对于有效时间(lock validity time)到底设置多长的两难问题。</p><p>总结<br>（1）基于ZooKeeper的分布式锁，适用于高可靠（高可用）而并发量不是太大的场景；<br>（2）基于Redis的分布式锁，适用于并发量很大、性能要求很高的、而可靠性问题可以通过其他方案去弥补的场景。<br>（3）基于mysql的分布式锁一般均有单点问题，高并发场景下对数据库的压力比较大；</p><p>需要考虑的问题：我们的业务对极端情况的容忍度，为了一把绝对安全的分布式锁导致过度设计，引入的复杂性和得到的收益是否值得。</p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/categories/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
    
      <category term="实习技术帖" scheme="http://raptor1998.top/tags/%E5%AE%9E%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>ByteDance Day1</title>
    <link href="http://raptor1998.top/2022/06/07/ByteDance1/"/>
    <id>http://raptor1998.top/2022/06/07/ByteDance1/</id>
    <published>2022-06-06T16:00:00.000Z</published>
    <updated>2022-08-15T12:38:40.244Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h1><h2 id="一面5-16"><a href="#一面5-16" class="headerlink" title="一面5.16"></a>一面5.16</h2><p>具体细节内容忘了，只有几个深刻的，spring中的循环依赖问题，随便背了一下，然后简单分析一二三级的实现方式，算法是最长公共子串，对于这俩问题，我只能说测开何苦为难测开啊，还好我简单看过spring这块</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="kabuxiaqu" class="fancybox"><img alt="kabuxiaqu" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141843526.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title="kabuxiaqu"></a></p><p>redis的big key有什么影响，项目中的最后上线的架构，mq消息堆积问题，最后问了个测试用例设计，反问了工作内容，不是点点点吧，回答我说：要是只是测试，你觉得我会问你这么多内容吗</p><h2 id="二三四面5-19"><a href="#二三四面5-19" class="headerlink" title="二三四面5.19"></a>二三四面5.19</h2><p>效率直接起飞，二面结束直接问我有时间吗，进行三面，三面结束hr直接电话问有时间吗，聊聊……，从两点到五点半，中间还穿插了一个其他厂的hr面，累够呛</p><p>二面leader面，没啥有印象的题目，只记得写了好多sql，无非就是group by，left join……算法忘了……最后同样反问工作内容，又随便聊了点别的，leader还亮了亮纹身</p><p>三面交叉，首先震惊，竟然是个女的，问我怎么封装一个http工具，说了半天没说明白，差点怼起来……说平时看我用mybatis，问都用来干什么，直接开始XX，内心狂喜，</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/202208141921214.gif" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>刚写过一个简单的mybatis，没讲干啥，讲了下怎么实现mybatis<br>最后算法感觉走过场吧，给你一个数组，统计次数出现最多的那个数……讲了个hashmap的实现以及空间换时间的实现，我想手写第二种思路，她让我写hashmap的吧<br>不得不说，得书的在线coding做的还是不错的，比牛客、力扣好用一万倍<br>hr面反正就问一下经历以及实习时间，啥时候入职，希望能快点入职，最后就说去和业务确认一下，然后就审批offer了</p><h1 id="入职"><a href="#入职" class="headerlink" title="入职"></a>入职</h1><h2 id="6-1"><a href="#6-1" class="headerlink" title="6.1"></a>6.1</h2><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="华夏之心" class="fancybox"><img alt="华夏之心" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141943550.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title="华夏之心"></a></p><p>der der的就去了八方城，入职填的mac，领到手的确实thinkpad，然后前往华夏之心</p><p> <a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141843477.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>头两天没租房子，准备随时跑路，毕竟测开，手里还有几份开发的offer，这个时候华为要是给了我offer，我就去华子了，可惜他晚了几天，这里必须得点名一下体面厂，4月我都躺平了，准备就体面厂混个实习了，然后五一过完，跟我说实习发不了offer，毁约，我就又去投了一份暑期超新星，两轮面完，我又通过了（滑稽），我直接接了offer，准备鸽他</p><p> <a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141843535.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>入职第一天，啥也没干，mentor oneone画饼，mentor画完leader oneone画，说后续参与到什么什么的开发中，至少到写这个的时候我还没参与进去……不知道后续<br>就觉得 饭还可以，下午茶也不错</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141944577.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>入职赶上6.1儿童节，领了个儿童节大礼包，瑜伽、跳绳二选一，下午茶小手表，棒棒糖等一系列小朋友礼物……<br>入职第二天，赶上端午节假期，端午大礼包……赶上字节十周年，day1大礼包+T恤纪念<br>截止到此时，资本家的糖衣炮弹邦邦砸在身上，直接跑路还来的及，薅资本家羊毛</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141945647.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p>端午期间租了个房子，环境还凑合，能直接看到工作的地方，房补有要求，不行30分钟以内，地铁20分钟，除去房补每月还要支出1000多块</p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141945004.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="" class="fancybox"><img alt="" data-src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/byte/202208141945662.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title=""></a></p></body></html>]]></content>
    
    <summary type="html">
    
      我无法忍受沉默，而与你交谈恰是良药。
    
    </summary>
    
    
      <category term="随笔" scheme="http://raptor1998.top/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://raptor1998.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Redis常见面试题</title>
    <link href="http://raptor1998.top/2022/05/27/redis%E5%B8%B8%E8%A7%81%E9%A2%98%E7%9B%AE/"/>
    <id>http://raptor1998.top/2022/05/27/redis%E5%B8%B8%E8%A7%81%E9%A2%98%E7%9B%AE/</id>
    <published>2022-05-26T16:00:00.000Z</published>
    <updated>2022-08-15T12:43:32.309Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h2 id="1-什么是Redis？它主要用来什么的？"><a href="#1-什么是Redis？它主要用来什么的？" class="headerlink" title="1. 什么是Redis？它主要用来什么的？"></a>1. 什么是Redis？它主要用来什么的？</h2><p>Redis，英文全称是<strong>Remote Dictionary Server</strong>（远程字典服务），是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。</p><p>与MySQL数据库不同的是，Redis的数据是存在内存中的。它的读写速度非常快，每秒可以处理超过10万次读写操作。因此redis被<strong>广泛应用于缓存</strong>，另外，Redis也经常用来做分布式锁。除此之外，Redis支持事务、持久化、LUA 脚本、LRU 驱动事件、多种集群方案。</p><h2 id="2-说说Redis的基本数据结构类型"><a href="#2-说说Redis的基本数据结构类型" class="headerlink" title="2.说说Redis的基本数据结构类型"></a>2.说说Redis的基本数据结构类型</h2><p>大多数小伙伴都知道，Redis有以下这五种基本类型：</p><ul><li>String（字符串）</li><li>Hash（哈希）</li><li>List（列表）</li><li>Set（集合）</li><li>zset（有序集合）</li></ul><p>它还有三种特殊的数据结构类型</p><ul><li>Geospatial</li><li>Hyperloglog</li><li>Bitmap</li></ul><h3 id="2-1-Redis-的五种基本数据类型"><a href="#2-1-Redis-的五种基本数据类型" class="headerlink" title="2.1 Redis 的五种基本数据类型"></a>2.1 Redis 的五种基本数据类型</h3><p><a href="https://pic1.zhimg.com/80/v2-42ecf99d863aadb00f914a23be91e564_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-42ecf99d863aadb00f914a23be91e564_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h4 id="String（字符串）"><a href="#String（字符串）" class="headerlink" title="String（字符串）"></a>String（字符串）</h4><ul><li>简介:String是Redis最基础的数据结构类型，它是二进制安全的，可以存储图片或者序列化的对象，值最大存储为512M</li><li>简单使用举例: <code>set key value</code>、<code>get key</code>等</li><li>应用场景：共享session、分布式锁，计数器、限流。</li><li>内部编码有3种，<code>int（8字节长整型）/embstr（小于等于39字节字符串）/raw（大于39个字节字符串）</code></li></ul><p>C语言的字符串是<code>char[]</code>实现的，而Redis使用<strong>SDS（simple dynamic string）</strong> 封装，sds源码如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">struct sdshdr{ unsigned int len; // 标记buf的长度 unsigned int free; //标记buf中未使用的元素个数 char buf[]; // 存放元素的坑 }</span><br></pre></td></tr></tbody></table></figure></div><p>SDS 结构图如下：</p><p><a href="https://pic2.zhimg.com/80/v2-3423339183d978aed32dca64447d728d_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-3423339183d978aed32dca64447d728d_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>Redis为什么选择<strong>SDS</strong>结构，而C语言原生的<code>char[]</code>不香吗？</p><blockquote><p>举例其中一点，SDS中，O(1)时间复杂度，就可以获取字符串长度；而C 字符串，需要遍历整个字符串，时间复杂度为O(n)</p></blockquote><h4 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h4><ul><li>简介：在Redis中，哈希类型是指v（值）本身又是一个键值对（k-v）结构</li><li>简单使用举例：<code>hset key field value</code> 、<code>hget key field</code></li><li>内部编码：<code>ziplist（压缩列表）</code> 、<code>hashtable（哈希表）</code></li><li>应用场景：缓存用户信息等。</li><li><strong>注意点</strong>：如果开发使用hgetall，哈希元素比较多的话，可能导致Redis阻塞，可以使用hscan。而如果只是获取部分field，建议使用hmget。</li></ul><p>字符串和哈希类型对比如下图：</p><p><a href="https://pic1.zhimg.com/80/v2-35a03c770a54bf4efb6c66292983d428_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-35a03c770a54bf4efb6c66292983d428_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h4 id="List（列表）"><a href="#List（列表）" class="headerlink" title="List（列表）"></a>List（列表）</h4><ul><li>简介：列表（list）类型是用来存储多个有序的字符串，一个列表最多可以存储2^32-1个元素。</li><li>简单实用举例：<code>lpush key value [value ...]</code> 、<code>lrange key start end</code></li><li>内部编码：ziplist（压缩列表）、linkedlist（链表）</li><li>应用场景：消息队列，文章列表,</li></ul><p>一图看懂list类型的插入与弹出：</p><p><a href="https://pic1.zhimg.com/80/v2-a3eb7e75fa982bb3c94ac8f0bc08e594_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-a3eb7e75fa982bb3c94ac8f0bc08e594_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>list应用场景参考以下：</p><blockquote><ul><li>lpush+lpop=Stack（栈）</li><li>lpush+rpop=Queue（队列）</li><li>lpsh+ltrim=Capped Collection（有限集合）</li><li>lpush+brpop=Message Queue（消息队列）</li></ul></blockquote><h4 id="Set（集合）"><a href="#Set（集合）" class="headerlink" title="Set（集合）"></a>Set（集合）</h4><p><a href="https://pic1.zhimg.com/80/v2-bf0ba39f8ed2b1e0c52063dd4c6bf1e8_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-bf0ba39f8ed2b1e0c52063dd4c6bf1e8_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><ul><li>简介：集合（set）类型也是用来保存多个的字符串元素，但是不允许重复元素</li><li>简单使用举例：<code>sadd key element [element ...]</code>、<code>smembers key</code></li><li>内部编码：<code>intset（整数集合）</code>、<code>hashtable（哈希表）</code></li><li><strong>注意点</strong>：smembers和lrange、hgetall都属于比较重的命令，如果元素过多存在阻塞Redis的可能性，可以使用sscan来完成。</li><li>应用场景：用户标签,生成随机数抽奖、社交需求。</li></ul><h4 id="有序集合（zset）"><a href="#有序集合（zset）" class="headerlink" title="有序集合（zset）"></a>有序集合（zset）</h4><ul><li>简介：已排序的字符串集合，同时元素不能重复</li><li>简单格式举例：<code>zadd key score member [score member ...]</code>，<code>zrank key member</code></li><li>底层内部编码：<code>ziplist（压缩列表）</code>、<code>skiplist（跳跃表）</code></li><li>应用场景：排行榜，社交需求（如用户点赞）。</li></ul><h3 id="2-2-Redis-的三种特殊数据类型"><a href="#2-2-Redis-的三种特殊数据类型" class="headerlink" title="2.2 Redis 的三种特殊数据类型"></a>2.2 Redis 的三种特殊数据类型</h3><ul><li>Geo：Redis3.2推出的，地理位置定位，用于存储地理位置信息，并对存储的信息进行操作。</li><li>HyperLogLog：用来做基数统计算法的数据结构，如统计网站的UV。</li><li>Bitmaps ：用一个比特位来映射某个元素的状态，在Redis中，它的底层是基于字符串类型实现的，可以把bitmaps成作一个以比特位为单位的数组</li></ul><h2 id="3-Redis为什么这么快？"><a href="#3-Redis为什么这么快？" class="headerlink" title="3. Redis为什么这么快？"></a>3. Redis为什么这么快？</h2><p><a href="https://pic3.zhimg.com/80/v2-f762d3d75e2d730863db187fdfaffbe2_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-f762d3d75e2d730863db187fdfaffbe2_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>Redis为什么这么快</p><h3 id="3-1-基于内存存储实现"><a href="#3-1-基于内存存储实现" class="headerlink" title="3.1 基于内存存储实现"></a>3.1 基于内存存储实现</h3><p>我们都知道内存读写是比在磁盘快很多的，Redis基于内存存储实现的数据库，相对于数据存在磁盘的MySQL数据库，省去磁盘I/O的消耗。</p><h3 id="3-2-高效的数据结构"><a href="#3-2-高效的数据结构" class="headerlink" title="3.2 高效的数据结构"></a>3.2 高效的数据结构</h3><p>我们知道，Mysql索引为了提高效率，选择了B+树的数据结构。其实合理的数据结构，就是可以让你的应用/程序更快。先看下Redis的数据结构&amp;内部编码图：</p><p><a href="https://pic3.zhimg.com/80/v2-ae8d85c70cc68763fbec60928ba4cda6_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-ae8d85c70cc68763fbec60928ba4cda6_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h4 id="SDS简单动态字符串"><a href="#SDS简单动态字符串" class="headerlink" title="SDS简单动态字符串"></a>SDS简单动态字符串</h4><p><a href="https://pic4.zhimg.com/80/v2-916d224d51854e36272897813c112d03_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-916d224d51854e36272897813c112d03_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><blockquote><ul><li>字符串长度处理：Redis获取字符串长度，时间复杂度为O(1)，而C语言中，需要从头开始遍历，复杂度为O（n）;</li><li>空间预分配：字符串修改越频繁的话，内存分配越频繁，就会消耗性能，而SDS修改和空间扩充，会额外分配未使用的空间，减少性能损耗。</li><li>惰性空间释放：SDS 缩短时，不是回收多余的内存空间，而是free记录下多余的空间，后续有变更，直接使用free中记录的空间，减少分配。</li><li>二进制安全：Redis可以存储一些二进制数据，在C语言中字符串遇到’\0’会结束，而 SDS中标志字符串结束的是len属性。</li></ul></blockquote><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>Redis 作为 K-V 型内存数据库，所有的键值就是用字典来存储。字典就是哈希表，比如HashMap，通过key就可以直接获取到对应的value。而哈希表的特性，在O（1）时间复杂度就可以获得对应的值。</p><h4 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h4><p><a href="https://pic4.zhimg.com/80/v2-62461a985478cdcccee509f1cf41c1d7_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-62461a985478cdcccee509f1cf41c1d7_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><blockquote><ul><li>跳跃表是Redis特有的数据结构，就是在链表的基础上，增加多级索引提升查找效率。</li><li>跳跃表支持平均 O（logN）,最坏 O（N）复杂度的节点查找，还可以通过顺序性操作批量处理节点。</li></ul></blockquote><h3 id="3-3-合理的数据编码"><a href="#3-3-合理的数据编码" class="headerlink" title="3.3 合理的数据编码"></a>3.3 合理的数据编码</h3><p>Redis 支持多种数据数据类型，每种基本类型，可能对多种数据结构。什么时候,使用什么样数据结构，使用什么样编码，是redis设计者总结优化的结果。</p><blockquote><ul><li>String：如果存储数字的话，是用int类型的编码;如果存储非数字，小于等于39字节的字符串，是embstr；大于39个字节，则是raw编码。</li><li>List：如果列表的元素个数小于512个，列表每个元素的值都小于64字节（默认），使用ziplist编码，否则使用linkedlist编码</li><li>Hash：哈希类型元素个数小于512个，所有值小于64字节的话，使用ziplist编码,否则使用hashtable编码。</li><li>Set：如果集合中的元素都是整数且元素个数小于512个，使用intset编码，否则使用hashtable编码。</li><li>Zset：当有序集合的元素个数小于128个，每个元素的值小于64字节时，使用ziplist编码，否则使用skiplist（跳跃表）编码</li></ul></blockquote><h3 id="3-4-合理的线程模型"><a href="#3-4-合理的线程模型" class="headerlink" title="3.4 合理的线程模型"></a>3.4 合理的线程模型</h3><p><strong>I/O 多路复用</strong></p><p><a href="https://pic3.zhimg.com/80/v2-66b6b4f7a3d3e59dd6e077560d7a6262_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-66b6b4f7a3d3e59dd6e077560d7a6262_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>I/O 多路复用</p><blockquote><p>多路I/O复用技术可以让单个线程高效的处理多个连接请求，而Redis使用用epoll作为I/O多路复用技术的实现。并且，Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。</p></blockquote><p>什么是I/O多路复用？</p><blockquote><ul><li>I/O ：网络 I/O</li><li>多路 ：多个网络连接</li><li>复用：复用同一个线程。</li><li>IO多路复用其实就是一种同步IO模型，它实现了一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；而没有文件句柄就绪时,就会阻塞应用程序，交出cpu。</li></ul></blockquote><p><strong>单线程模型</strong></p><ul><li>Redis是单线程模型的，而单线程避免了CPU不必要的上下文切换和竞争锁的消耗。也正因为是单线程，如果某个命令执行过长（如hgetall命令），会造成阻塞。Redis是面向快速执行场景的数据库。，所以要慎用如smembers和lrange、hgetall等命令。</li><li>Redis 6.0 引入了多线程提速，它的执行命令操作内存的仍然是个单线程。</li></ul><h3 id="3-5-虚拟内存机制"><a href="#3-5-虚拟内存机制" class="headerlink" title="3.5 虚拟内存机制"></a>3.5 虚拟内存机制</h3><p>Redis直接自己构建了VM机制 ，不会像一般的系统会调用系统函数处理，会浪费一定的时间去移动和请求。</p><p><strong>Redis的虚拟内存机制是啥呢？</strong></p><blockquote><p>虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。</p></blockquote><h2 id="4-什么是缓存击穿、缓存穿透、缓存雪崩？"><a href="#4-什么是缓存击穿、缓存穿透、缓存雪崩？" class="headerlink" title="4. 什么是缓存击穿、缓存穿透、缓存雪崩？"></a>4. 什么是缓存击穿、缓存穿透、缓存雪崩？</h2><h3 id="4-1-缓存穿透问题"><a href="#4-1-缓存穿透问题" class="headerlink" title="4.1 缓存穿透问题"></a>4.1 缓存穿透问题</h3><p>先来看一个常见的缓存使用方式：读请求来了，先查下缓存，缓存有值命中，就直接返回；缓存没命中，就去查数据库，然后把数据库的值更新到缓存，再返回。</p><p><a href="https://pic2.zhimg.com/80/v2-27528bb903aa1db97a7d2ea202ddc259_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-27528bb903aa1db97a7d2ea202ddc259_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>读取缓存</p><p><strong>缓存穿透</strong>：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。</p><blockquote><p>通俗点说，读请求访问时，缓存和数据库都没有某个值，这样就会导致每次对这个值的查询请求都会穿透到数据库，这就是缓存穿透。</p></blockquote><p>缓存穿透一般都是这几种情况产生的：</p><ul><li><strong>业务不合理的设计</strong>，比如大多数用户都没开守护，但是你的每个请求都去缓存，查询某个userid查询有没有守护。</li><li><strong>业务/运维/开发失误的操作</strong>，比如缓存和数据库的数据都被误删除了。</li><li><strong>黑客非法请求攻击</strong>，比如黑客故意捏造大量非法请求，以读取不存在的业务数据。</li></ul><p><strong>如何避免缓存穿透呢？</strong> 一般有三种方法。</p><ul><li>1.如果是非法请求，我们在API入口，对参数进行校验，过滤非法值。</li><li>2.如果查询数据库为空，我们可以给缓存设置个空值，或者默认值。但是如有有写请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。（业务上比较常用，简单有效）</li><li>3.使用布隆过滤器快速判断数据是否存在。即一个查询请求过来时，先通过布隆过滤器判断值是否存在，存在才继续往下查。</li></ul><blockquote><p>布隆过滤器原理：它由初始值为0的位图数组和N个哈希函数组成。一个对一个key进行N个hash算法获取N个值，在比特数组中将这N个值散列后设定为1，然后查的时候如果特定的这几个位置都为1，那么布隆过滤器判断该key存在。</p></blockquote><h3 id="4-2-缓存雪崩问题"><a href="#4-2-缓存雪崩问题" class="headerlink" title="4.2 缓存雪崩问题"></a>4.2 缓存雪崩问题</h3><p><strong>缓存雪奔：</strong> 指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至down机。</p><ul><li>缓存雪奔一般是由于大量数据同时过期造成的，对于这个原因，可通过均匀设置过期时间解决，即让过期时间相对离散一点。如采用一个较大固定值+一个较小的随机值，5小时+0到1800秒酱紫。</li><li>Redis 故障宕机也可能引起缓存雪奔。这就需要构造Redis高可用集群啦。</li></ul><h3 id="4-3-缓存击穿问题"><a href="#4-3-缓存击穿问题" class="headerlink" title="4.3 缓存击穿问题"></a>4.3 缓存击穿问题</h3><p><strong>缓存击穿：</strong> 指热点key在某个时间点过期的时候，而恰好在这个时间点对这个Key有大量的并发请求过来，从而大量的请求打到db。</p><p>缓存击穿看着有点像，其实它两区别是，缓存雪奔是指数据库压力过大甚至down机，缓存击穿只是大量并发请求到了DB数据库层面。可以认为击穿是缓存雪奔的一个子集吧。有些文章认为它俩区别，是区别在于击穿针对某一热点key缓存，雪奔则是很多key。</p><p>解决方案就有两种：</p><ul><li><strong>1.使用互斥锁方案</strong>。缓存失效时，不是立即去加载db数据，而是先使用某些带成功返回的原子操作命令，如(Redis的setnx）去操作，成功的时候，再去加载db数据库数据和设置缓存。否则就去重试获取缓存。</li><li><strong>2. “永不过期”</strong>，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。</li></ul><h2 id="5-什么是热Key问题，如何解决热key问题"><a href="#5-什么是热Key问题，如何解决热key问题" class="headerlink" title="5. 什么是热Key问题，如何解决热key问题"></a>5. 什么是热Key问题，如何解决热key问题</h2><p><strong>什么是热Key呢</strong>？在Redis中，我们把访问频率高的key，称为热点key。</p><p>如果某一热点key的请求到服务器主机时，由于请求量特别大，可能会导致主机资源不足，甚至宕机，从而影响正常的服务。</p><p><a href="https://pic2.zhimg.com/80/v2-caba55257b9de9ff85867d40daa8eb31_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-caba55257b9de9ff85867d40daa8eb31_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>而热点Key是怎么产生的呢？主要原因有两个：</p><blockquote><ul><li>用户消费的数据远大于生产的数据，如秒杀、热点新闻等读多写少的场景。</li><li>请求分片集中，超过单Redi服务器的性能，比如固定名称key，Hash落入同一台服务器，瞬间访问量极大，超过机器瓶颈，产生热点Key问题。</li></ul></blockquote><p>那么在日常开发中，如何识别到热点key呢？</p><blockquote><ul><li>凭经验判断哪些是热Key；</li><li>客户端统计上报；</li><li>服务代理层上报</li></ul></blockquote><p>如何解决热key问题？</p><blockquote><ul><li>Redis集群扩容：增加分片副本，均衡读流量；</li><li>将热key分散到不同的服务器中；</li><li>使用二级缓存，即JVM本地缓存,减少Redis的读请求。</li></ul></blockquote><h2 id="6-Redis-过期策略和内存淘汰策略"><a href="#6-Redis-过期策略和内存淘汰策略" class="headerlink" title="6. Redis 过期策略和内存淘汰策略"></a>6. Redis 过期策略和内存淘汰策略</h2><p><a href="https://pic3.zhimg.com/80/v2-e6220bf60f2760694f3a26dbc8fc64c2_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-e6220bf60f2760694f3a26dbc8fc64c2_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="6-1-Redis的过期策略"><a href="#6-1-Redis的过期策略" class="headerlink" title="6.1 Redis的过期策略"></a>6.1 Redis的过期策略</h3><p>我们在<code>set key</code>的时候，可以给它设置一个过期时间，比如<code>expire key 60</code>。指定这key60s后过期，60s后，redis是如何处理的嘛？我们先来介绍几种过期策略：</p><h4 id="定时过期"><a href="#定时过期" class="headerlink" title="定时过期"></a>定时过期</h4><blockquote><p>每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即对key进行清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</p></blockquote><h4 id="惰性过期"><a href="#惰性过期" class="headerlink" title="惰性过期"></a>惰性过期</h4><blockquote><p>只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</p></blockquote><h4 id="定期过期"><a href="#定期过期" class="headerlink" title="定期过期"></a>定期过期</h4><blockquote><p>每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。</p><p>expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。</p></blockquote><p>Redis中同时使用了<strong>惰性过期和定期过期</strong>两种过期策略。</p><ul><li>假设Redis当前存放30万个key，并且都设置了过期时间，如果你每隔100ms就去检查这全部的key，CPU负载会特别高，最后可能会挂掉。</li><li>因此，redis采取的是定期过期，每隔100ms就随机抽取一定数量的key来检查和删除的。</li><li>但是呢，最后可能会有很多已经过期的key没被删除。这时候，redis采用惰性删除。在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除。</li></ul><p>但是呀，如果定期删除漏掉了很多过期的key，然后也没走惰性删除。就会有很多过期key积在内存内存，直接会导致内存爆的。或者有些时候，业务量大起来了，redis的key被大量使用，内存直接不够了，运维小哥哥也忘记加大内存了。难道redis直接这样挂掉？不会的！Redis用8种内存淘汰策略保护自己~</p><h3 id="6-2-Redis-内存淘汰策略"><a href="#6-2-Redis-内存淘汰策略" class="headerlink" title="6.2 Redis 内存淘汰策略"></a>6.2 Redis 内存淘汰策略</h3><blockquote><ul><li>volatile-lru：当内存不足以容纳新写入数据时，从设置了过期时间的key中使用LRU（最近最少使用）算法进行淘汰；</li><li>allkeys-lru：当内存不足以容纳新写入数据时，从所有key中使用LRU（最近最少使用）算法进行淘汰。</li><li>volatile-lfu：4.0版本新增，当内存不足以容纳新写入数据时，在过期的key中，使用LFU算法进行删除key。</li><li>allkeys-lfu：4.0版本新增，当内存不足以容纳新写入数据时，从所有key中使用LFU算法进行淘汰；</li><li>volatile-random：当内存不足以容纳新写入数据时，从设置了过期时间的key中，随机淘汰数据；。</li><li>allkeys-random：当内存不足以容纳新写入数据时，从所有key中随机淘汰数据。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，根据过期时间进行淘汰，越早过期的优先被淘汰；</li><li>noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。</li></ul></blockquote><h2 id="7-说说Redis的常用应用场景"><a href="#7-说说Redis的常用应用场景" class="headerlink" title="7.说说Redis的常用应用场景"></a>7.说说Redis的常用应用场景</h2><ul><li>缓存</li><li>排行榜</li><li>计数器应用</li><li>共享Session</li><li>分布式锁</li><li>社交网络</li><li>消息队列</li><li>位操作</li></ul><h3 id="7-1-缓存"><a href="#7-1-缓存" class="headerlink" title="7.1 缓存"></a>7.1 缓存</h3><p>我们一提到redis，自然而然就想到缓存，国内外中大型的网站都离不开缓存。合理的利用缓存，比如缓存热点数据，不仅可以提升网站的访问速度，还可以降低数据库DB的压力。并且，Redis相比于memcached，还提供了丰富的数据结构，并且提供RDB和AOF等持久化机制，强的一批。</p><h3 id="7-2-排行榜"><a href="#7-2-排行榜" class="headerlink" title="7.2 排行榜"></a>7.2 排行榜</h3><p>当今互联网应用，有各种各样的排行榜，如电商网站的月度销量排行榜、社交APP的礼物排行榜、小程序的投票排行榜等等。Redis提供的<code>zset</code>数据类型能够实现这些复杂的排行榜。</p><p>比如，用户每天上传视频，获得点赞的排行榜可以这样设计：</p><ul><li>1.用户Jay上传一个视频，获得6个赞，可以酱紫：</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zadd user:ranking:2021-03-03 Jay 3</span><br></pre></td></tr></tbody></table></figure></div><ul><li>2.过了一段时间，再获得一个赞，可以这样：</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zincrby user:ranking:2021-03-03 Jay 1</span><br></pre></td></tr></tbody></table></figure></div><ul><li>3.如果某个用户John作弊，需要删除该用户：</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrem user:ranking:2021-03-03 John</span><br></pre></td></tr></tbody></table></figure></div><ul><li>4.展示获取赞数最多的3个用户</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrevrangebyrank user:ranking:2021-03-03 0 2</span><br></pre></td></tr></tbody></table></figure></div><h3 id="7-3-计数器应用"><a href="#7-3-计数器应用" class="headerlink" title="7.3 计数器应用"></a>7.3 计数器应用</h3><p>各大网站、APP应用经常需要计数器的功能，如短视频的播放数、电商网站的浏览数。这些播放数、浏览数一般要求实时的，每一次播放和浏览都要做加1的操作，如果并发量很大对于传统关系型数据的性能是一种挑战。Redis天然支持计数功能而且计数的性能也非常好，可以说是计数器系统的重要选择。</p><h3 id="7-4-共享Session"><a href="#7-4-共享Session" class="headerlink" title="7.4 共享Session"></a>7.4 共享Session</h3><p>如果一个分布式Web服务将用户的Session信息保存在各自服务器，用户刷新一次可能就需要重新登录了，这样显然有问题。实际上，可以使用Redis将用户的Session进行集中管理，每次用户更新或者查询登录信息都直接从Redis中集中获取。</p><h3 id="7-5-分布式锁"><a href="#7-5-分布式锁" class="headerlink" title="7.5 分布式锁"></a>7.5 分布式锁</h3><p>几乎每个互联网公司中都使用了分布式部署，分布式服务下，就会遇到对同一个资源的并发访问的技术难题，如秒杀、下单减库存等场景。</p><ul><li>用synchronize或者reentrantlock本地锁肯定是不行的。</li><li>如果是并发量不大话，使用数据库的悲观锁、乐观锁来实现没啥问题。</li><li>但是在并发量高的场合中，利用数据库锁来控制资源的并发访问，会影响数据库的性能。</li><li>实际上，可以用Redis的setnx来实现分布式的锁。</li></ul><h3 id="7-6-社交网络"><a href="#7-6-社交网络" class="headerlink" title="7.6 社交网络"></a>7.6 社交网络</h3><p>赞/踩、粉丝、共同好友/喜好、推送、下拉刷新等是社交网站的必备功能，由于社交网站访问量通常比较大，而且传统的关系型数据不太适保存 这种类型的数据，Redis提供的数据结构可以相对比较容易地实现这些功能。</p><h3 id="7-7-消息队列"><a href="#7-7-消息队列" class="headerlink" title="7.7 消息队列"></a>7.7 消息队列</h3><p>消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。</p><h3 id="7-8-位操作"><a href="#7-8-位操作" class="headerlink" title="7.8 位操作"></a>7.8 位操作</h3><p>用于数据量上亿的场景下，例如几亿用户系统的签到，去重登录次数统计，某用户是否在线状态等等。腾讯10亿用户，要几个毫秒内查询到某个用户是否在线，能怎么做？千万别说给每个用户建立一个key，然后挨个记（你可以算一下需要的内存会很恐怖，而且这种类似的需求很多。这里要用到位操作——使用setbit、getbit、bitcount命令。原理是：redis内构建一个足够长的数组，每个数组元素只能是0和1两个值，然后这个数组的下标index用来表示用户id（必须是数字哈），那么很显然，这个几亿长的大数组就能通过下标和元素值（0和1）来构建一个记忆系统。</p><h2 id="8-Redis-的持久化机制有哪些？优缺点说说"><a href="#8-Redis-的持久化机制有哪些？优缺点说说" class="headerlink" title="8. Redis 的持久化机制有哪些？优缺点说说"></a>8. Redis 的持久化机制有哪些？优缺点说说</h2><p>Redis是基于内存的非关系型K-V数据库，既然它是基于内存的，如果Redis服务器挂了，数据就会丢失。为了避免数据丢失了，Redis提供了<strong>持久化</strong>，即把数据保存到磁盘。</p><p>Redis提供了<strong>RDB和AOF</strong>两种持久化机制，它持久化文件加载流程如下：</p><p><a href="https://pic2.zhimg.com/80/v2-9865e430cee7ef0672e0094ef8e1b919_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-9865e430cee7ef0672e0094ef8e1b919_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="8-1-RDB"><a href="#8-1-RDB" class="headerlink" title="8.1 RDB"></a>8.1 RDB</h3><p><strong>RDB</strong>，就是把内存数据以快照的形式保存到磁盘上。</p><blockquote><p>什么是快照?可以这样理解，给当前时刻的数据，拍一张照片，然后保存下来。</p></blockquote><p>RDB持久化，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个<code>dump.rdb</code>文件，Redis 重启的时候，通过加载<code>dump.rdb</code>文件来恢复数据。RDB触发机制主要有以下几种：</p><p><a href="https://pic4.zhimg.com/80/v2-3ee8c672621dbf34a168ec8aa8448d9f_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-3ee8c672621dbf34a168ec8aa8448d9f_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><strong>RDB 的优点</strong></p><ul><li>适合大规模的数据恢复场景，如备份，全量复制等</li></ul><p><strong>RDB缺点</strong></p><ul><li>没办法做到实时持久化/秒级持久化。</li><li>新老版本存在RDB格式兼容问题</li></ul><h3 id="8-2-AOF"><a href="#8-2-AOF" class="headerlink" title="8.2 AOF"></a>8.2 AOF</h3><p><strong>AOF（append only file）</strong> 持久化，采用日志的形式来记录每个写操作，追加到文件中，重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题。默认是不开启的。</p><p>AOF的工作流程如下：</p><p><a href="https://pic4.zhimg.com/80/v2-4a0cca2f525e8dfc7b8ddd7c106c518f_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-4a0cca2f525e8dfc7b8ddd7c106c518f_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><strong>AOF的优点</strong></p><ul><li>数据的一致性和完整性更高</li></ul><p><strong>AOF的缺点</strong></p><ul><li>AOF记录的内容越多，文件越大，数据恢复变慢。</li></ul><h2 id="9-怎么实现Redis的高可用？"><a href="#9-怎么实现Redis的高可用？" class="headerlink" title="9.怎么实现Redis的高可用？"></a>9.怎么实现Redis的高可用？</h2><p>我们在项目中使用Redis，肯定不会是单点部署Redis服务的。因为，单点部署一旦宕机，就不可用了。为了实现高可用，通常的做法是，将数据库复制多个副本以部署在不同的服务器上，其中一台挂了也可以继续提供服务。Redis 实现高可用有三种部署模式：<strong>主从模式，哨兵模式，集群模式</strong>。</p><h3 id="9-1-主从模式"><a href="#9-1-主从模式" class="headerlink" title="9.1 主从模式"></a>9.1 主从模式</h3><p>主从模式中，Redis部署了多台机器，有主节点，负责读写操作，有从节点，只负责读操作。从节点的数据来自主节点，实现原理就是<strong>主从复制机制</strong></p><p>主从复制包括全量复制，增量复制两种。一般当slave第一次启动连接master，或者认为是第一次连接，就采用<strong>全量复制</strong>，全量复制流程如下：</p><p><a href="https://pic4.zhimg.com/80/v2-f3d737878e92e5fdd3ce5217359b3127_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-f3d737878e92e5fdd3ce5217359b3127_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><ul><li>1.slave发送sync命令到master。</li><li>2.master接收到SYNC命令后，执行bgsave命令，生成RDB全量文件。</li><li>3.master使用缓冲区，记录RDB快照生成期间的所有写命令。</li><li>4.master执行完bgsave后，向所有slave发送RDB快照文件。</li><li>5.slave收到RDB快照文件后，载入、解析收到的快照。</li><li>6.master使用缓冲区，记录RDB同步期间生成的所有写的命令。</li><li>7.master快照发送完毕后，开始向slave发送缓冲区中的写命令;</li><li>8.salve接受命令请求，并执行来自master缓冲区的写命令</li></ul><p>redis2.8版本之后，已经使用<strong>psync来替代sync</strong>，因为sync命令非常消耗系统资源，psync的效率更高。</p><p>slave与master全量同步之后，master上的数据，如果再次发生更新，就会触发<strong>增量复制</strong>。</p><p>当master节点发生数据增减时，就会触发<code>replicationFeedSalves()</code>函数，接下来在 Master节点上调用的每一个命令会使用<code>replicationFeedSlaves()</code>来同步到Slave节点。执行此函数之前呢，master节点会判断用户执行的命令是否有数据更新，如果有数据更新的话，并且slave节点不为空，就会执行此函数。这个函数作用就是：<strong>把用户执行的命令发送到所有的slave节点</strong>，让slave节点执行。流程如下：</p><p><a href="https://pic3.zhimg.com/80/v2-fd08a5ca02f3d2cd99dc9b9f880138f2_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-fd08a5ca02f3d2cd99dc9b9f880138f2_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="9-2-哨兵模式"><a href="#9-2-哨兵模式" class="headerlink" title="9.2 哨兵模式"></a>9.2 哨兵模式</h3><p>主从模式中，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址。显然，多数业务场景都不能接受这种故障处理方式。Redis从2.8开始正式提供了Redis Sentinel（哨兵）架构来解决这个问题。</p><p><strong>哨兵模式</strong>，由一个或多个Sentinel实例组成的Sentinel系统，它可以监视所有的Redis主节点和从节点，并在被监视的主节点进入下线状态时，<strong>自动将下线主服务器属下的某个从节点升级为新的主节点</strong>。但是呢，一个哨兵进程对Redis节点进行监控，就可能会出现问题（<strong>单点问题</strong>），因此，可以使用多个哨兵来进行监控Redis节点，并且各个哨兵之间还会进行监控。</p><p><a href="https://pic3.zhimg.com/80/v2-d67de384b1fddd2f08704a6df0afd856_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-d67de384b1fddd2f08704a6df0afd856_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>Sentinel哨兵模式</p><p>简单来说，哨兵模式就三个作用：</p><ul><li>发送命令，等待Redis服务器（包括主服务器和从服务器）返回监控其运行状态；</li><li>哨兵监测到主节点宕机，会自动将从节点切换成主节点，然后通过发布订阅模式通知其他的从节点，修改配置文件，让它们切换主机；</li><li>哨兵之间还会相互监控，从而达到高可用。</li></ul><p><strong>故障切换的过程是怎样的呢</strong></p><blockquote><p>假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。</p></blockquote><h4 id="哨兵的工作模式如下："><a href="#哨兵的工作模式如下：" class="headerlink" title="哨兵的工作模式如下："></a>哨兵的工作模式如下：</h4><ol><li>每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他Sentinel实例发送一个 PING命令。</li><li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel标记为主观下线。</li><li>如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。</li><li>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线。</li><li>在一般情况下， 每个 Sentinel 会以每10秒一次的频率向它已知的所有Master，Slave发送 INFO 命令。</li><li>当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次</li><li>若没有足够数量的 Sentinel同意Master已经下线， Master的客观下线状态就会被移除；若Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。</li></ol><h3 id="9-3-Cluster集群模式"><a href="#9-3-Cluster集群模式" class="headerlink" title="9.3 Cluster集群模式"></a>9.3 Cluster集群模式</h3><p>哨兵模式基于主从模式，实现读写分离，它还可以自动切换，系统可用性更高。但是它每个节点存储的数据是一样的，浪费内存，并且不好在线扩容。因此，Cluster集群应运而生，它在Redis3.0加入的，实现了Redis的<strong>分布式存储</strong>。对数据进行分片，也就是说<strong>每台Redis节点上存储不同的内容</strong>，来解决在线扩容的问题。并且，它也提供复制和故障转移的功能。</p><h4 id="Cluster集群节点的通讯"><a href="#Cluster集群节点的通讯" class="headerlink" title="Cluster集群节点的通讯"></a>Cluster集群节点的通讯</h4><p>一个Redis集群由多个节点组成，<strong>各个节点之间是怎么通信的呢</strong>？通过<strong>Gossip协议</strong>！</p><p>Redis Cluster集群通过Gossip协议进行通信，节点之前不断交换信息，交换的信息内容包括节点出现故障、新节点加入、主从节点变更信息、slot信息等等。常用的Gossip消息分为4种，分别是：ping、pong、meet、fail。</p><p><a href="https://pic3.zhimg.com/80/v2-7900d0c4d5607b63ea333ab65d821b3e_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-7900d0c4d5607b63ea333ab65d821b3e_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><blockquote><ul><li>meet消息：通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。</li><li>ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。</li><li>pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。</li><li>fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。</li></ul></blockquote><p>特别的，每个节点是通过<strong>集群总线(cluster bus)</strong> 与其他的节点进行通信的。通讯时，使用特殊的端口号，即对外服务端口号加10000。例如如果某个node的端口号是6379，那么它与其它nodes通信的端口号是 16379。nodes 之间的通信采用特殊的二进制协议。</p><h4 id="Hash-Slot插槽算法"><a href="#Hash-Slot插槽算法" class="headerlink" title="Hash Slot插槽算法"></a>Hash Slot插槽算法</h4><p>既然是分布式存储，Cluster集群使用的分布式算法是<strong>一致性Hash</strong>嘛？并不是，而是<strong>Hash Slot插槽算法</strong>。</p><p><strong>插槽算法</strong>把整个数据库被分为16384个slot（槽），每个进入Redis的键值对，根据key进行散列，分配到这16384插槽中的一个。使用的哈希映射也比较简单，用CRC16算法计算出一个16 位的值，再对16384取模。数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点都可以处理这16384个槽。</p><p>集群中的每个节点负责一部分的hash槽，比如当前集群有A、B、C个节点，每个节点上的哈希槽数 =16384/3，那么就有：</p><ul><li>节点A负责0~5460号哈希槽</li><li>节点B负责5461~10922号哈希槽</li><li>节点C负责10923~16383号哈希槽</li></ul><h4 id="Redis-Cluster集群"><a href="#Redis-Cluster集群" class="headerlink" title="Redis Cluster集群"></a>Redis Cluster集群</h4><p>Redis Cluster集群中，需要确保16384个槽对应的node都正常工作，如果某个node出现故障，它负责的slot也会失效，整个集群将不能工作。</p><p>因此为了保证高可用，Cluster集群引入了主从复制，一个主节点对应一个或者多个从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点宕机时，就会启用从节点。</p><p>在Redis的每一个节点上，都有两个玩意，一个是插槽（slot），它的取值范围是0<del>16383。另外一个是cluster，可以理解为一个集群管理的插件。当我们存取的key到达时，Redis 会根据CRC16算法得出一个16 bit的值，然后把结果对16384取模。酱紫每个key都会对应一个编号在 0</del>16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。</p><p>虽然数据是分开存储在不同节点上的，但是对客户端来说，整个集群Cluster，被看做一个整体。客户端端连接任意一个node，看起来跟操作单实例的Redis一样。当客户端操作的key没有被分配到正确的node节点时，Redis会返回转向指令，最后指向正确的node，这就有点像浏览器页面的302 重定向跳转。</p><p><a href="https://pic3.zhimg.com/80/v2-cd8b925e38ee6600803a92516b9a1e02_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-cd8b925e38ee6600803a92516b9a1e02_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>Redis集群实现了高可用，当集群内节点出现故障时，通过<strong>故障转移</strong>，以保证集群正常对外提供服务。</p><p>redis集群通过ping/pong消息，实现故障发现。这个环境包括<strong>主观下线和客观下线</strong>。</p><p><strong>主观下线：</strong> 某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。</p><p><a href="https://pic4.zhimg.com/80/v2-d6156c362d9a12f7c2b70cda3318cebf_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-d6156c362d9a12f7c2b70cda3318cebf_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>主观下线</p><p><strong>客观下线：</strong> 指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。</p><ul><li>假如节点A标记节点B为主观下线，一段时间后，节点A通过消息把节点B的状态发到其它节点，当节点C接受到消息并解析出消息体时，如果发现节点B的pfail状态时，会触发客观下线流程；</li><li>当下线为主节点时，此时Redis Cluster集群为统计持有槽的主节点投票，看投票数是否达到一半，当下线报告统计数大于一半时，被标记为<strong>客观下线</strong>状态。</li></ul><p>流程如下：</p><p><a href="https://pic4.zhimg.com/80/v2-984e36262f247982f87f425eb243db17_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-984e36262f247982f87f425eb243db17_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>客观下线</p><p><strong>故障恢复</strong>：故障发现后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，以保证集群的高可用。流程如下：</p><p><a href="https://pic1.zhimg.com/80/v2-71e6ae742b0e40de0eb1b32dff7d37e4_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-71e6ae742b0e40de0eb1b32dff7d37e4_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><ul><li>资格检查：检查从节点是否具备替换故障主节点的条件。</li><li>准备选举时间：资格检查通过后，更新触发故障选举时间。</li><li>发起选举：到了故障选举时间，进行选举。</li><li>选举投票：只有持有槽的<strong>主节点</strong>才有票，从节点收集到足够的选票（大于一半），触发<strong>替换主节点操作</strong></li></ul><h2 id="10-使用过Redis分布式锁嘛？有哪些注意点呢？"><a href="#10-使用过Redis分布式锁嘛？有哪些注意点呢？" class="headerlink" title="10. 使用过Redis分布式锁嘛？有哪些注意点呢？"></a>10. 使用过Redis分布式锁嘛？有哪些注意点呢？</h2><p><strong>分布式锁</strong>，是控制分布式系统不同进程共同访问共享资源的一种锁的实现。秒杀下单、抢红包等等业务场景，都需要用到分布式锁，我们项目中经常使用Redis作为分布式锁。</p><p>选了Redis分布式锁的几种实现方法，大家来讨论下，看有没有啥问题哈。</p><ul><li>命令setnx + expire分开写</li><li>setnx + value值是过期时间</li><li>set的扩展命令（set ex px nx）</li><li>set ex px nx + 校验唯一随机值,再删除</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">synchronized (this)</span></span><br><span class="line"><span class="comment">1. 在分布式环境下  多个jvm  进程级别锁</span></span><br><span class="line"><span class="comment">Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, "lalal");</span></span><br><span class="line"><span class="comment">stringRedisTemplate.expire(lockKey, 10, TimeUnit.SECONDS);</span></span><br><span class="line"><span class="comment">stringRedisTemplate.delete(lockKey);</span></span><br><span class="line"><span class="comment">1. 进程执行到  设置过期时间, 服务挂掉，则无法解锁</span></span><br><span class="line"><span class="comment">2. 若A需要执行 15s, 代码未执行完成，锁过期，则后续请求B进入，加B锁，5s后，A执行到删除锁，删掉B加的锁</span></span><br><span class="line"><span class="comment">    同理，C进来，上锁，B此时执行了5s，  套娃下去，总会出现，多个请求，同时在做库存相关操作</span></span><br><span class="line"><span class="comment">String clientId = UUID.randomUUID().toString();</span></span><br><span class="line"><span class="comment">if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) {</span></span><br><span class="line"><span class="comment">        stringRedisTemplate.delete(lockKey);</span></span><br><span class="line"><span class="comment">    }</span></span><br><span class="line"><span class="comment">1. 引入进程识别，只能删除我自己加的锁</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">在主线程处理业务逻辑时，开辟新的timer线程，强行为locakKey续命，最好设置为过期时间的1/3</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></tbody></table></figure></div><h3 id="10-1-命令setnx-expire分开写"><a href="#10-1-命令setnx-expire分开写" class="headerlink" title="10.1 命令setnx + expire分开写"></a>10.1 命令setnx + expire分开写</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.setnx(key,lock_value) == 1）{ //加锁 expire（key，100）; //设置过期时间 try { do something //业务请求 }catch(){ } finally { jedis.del(key); //释放锁 } }</span><br></pre></td></tr></tbody></table></figure></div><p>如果执行完<code>setnx</code>加锁，正要执行expire设置过期时间时，进程crash掉或者要重启维护了，那这个锁就“长生不老”了，<strong>别的线程永远获取不到锁</strong>啦，所以分布式锁<strong>不能</strong>这么实现。</p><h3 id="10-2-setnx-value值是过期时间"><a href="#10-2-setnx-value值是过期时间" class="headerlink" title="10.2 setnx + value值是过期时间"></a>10.2 setnx + value值是过期时间</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">long expires = System.currentTimeMillis() + expireTime; //系统时间+设置的过期时间 String expiresStr = String.valueOf(expires); // 如果当前锁不存在，返回加锁成功 if (jedis.setnx(key, expiresStr) == 1) { return true; } // 如果锁已经存在，获取锁的过期时间 String currentValueStr = jedis.get(key); // 如果获取到的过期时间，小于系统当前时间，表示已经过期 if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) { // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间（不了解redis的getSet命令的小伙伴，可以去官网看下哈） String oldValueStr = jedis.getSet(key_resource_id, expiresStr); if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) { // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁 return true; } } //其他情况，均返回加锁失败 return false; }</span><br></pre></td></tr></tbody></table></figure></div><p>笔者看过有开发小伙伴是这么实现分布式锁的，但是这种方案也有这些<strong>缺点</strong>：</p><ul><li>过期时间是客户端自己生成的，分布式环境下，每个客户端的时间必须同步。</li><li>没有保存持有者的唯一标识，可能被别的客户端释放/解锁。</li><li>锁过期的时候，并发多个客户端同时请求过来，都执行了<code>jedis.getSet()</code>，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖。</li></ul><h4 id="10-3：set的扩展命令（set-ex-px-nx）（注意可能存在的问题）"><a href="#10-3：set的扩展命令（set-ex-px-nx）（注意可能存在的问题）" class="headerlink" title="10.3：set的扩展命令（set ex px nx）（注意可能存在的问题）"></a>10.3：set的扩展命令（set ex px nx）（注意可能存在的问题）</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key, lock_value, "NX", "EX", 100s) == 1）{ //加锁 try { do something //业务处理 }catch(){ } finally { jedis.del(key); //释放锁 } }</span><br></pre></td></tr></tbody></table></figure></div><p>这个方案可能存在这样的问题：</p><ul><li>锁过期释放了，业务还没执行完。</li><li>锁被别的线程误删。</li></ul><h3 id="10-4-set-ex-px-nx-校验唯一随机值-再删除"><a href="#10-4-set-ex-px-nx-校验唯一随机值-再删除" class="headerlink" title="10.4 set ex px nx + 校验唯一随机值,再删除"></a>10.4 set ex px nx + 校验唯一随机值,再删除</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key, uni_request_id, "NX", "EX", 100s) == 1）{ //加锁 try { do something //业务处理 }catch(){ } finally { //判断是不是当前线程加的锁,是才释放 if (uni_request_id.equals(jedis.get(key))) { jedis.del(key); //释放锁 } } }</span><br></pre></td></tr></tbody></table></figure></div><p>在这里，判断当前线程加的锁和释放锁是不是一个原子操作。如果调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，<strong>会解除他人加的锁</strong>。</p><p><a href="https://pic2.zhimg.com/80/v2-4f173ebee69f1747d8f16f1b28872e29_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-4f173ebee69f1747d8f16f1b28872e29_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>一般也是用<strong>lua脚本</strong>代替。lua脚本如下：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end;</span><br></pre></td></tr></tbody></table></figure></div><p>这种方式比较不错了，一般情况下，已经可以使用这种实现方式。但是存在<strong>锁过期释放了，业务还没执行完的问题</strong>（实际上，估算个业务处理的时间，一般没啥问题了）。</p><h2 id="11-使用过Redisson嘛？说说它的原理"><a href="#11-使用过Redisson嘛？说说它的原理" class="headerlink" title="11. 使用过Redisson嘛？说说它的原理"></a>11. 使用过Redisson嘛？说说它的原理</h2><p><strong>分布式锁</strong>可能存在<strong>锁过期释放，业务没执行完的问题</strong>。有些小伙伴认为，稍微把锁过期时间设置长一些就可以啦。其实我们设想一下，是否可以给获得锁的线程，开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁的过期时间延长，防止锁过期提前释放。</p><p>当前<strong>开源框架Redisson</strong>就解决了这个分布式锁问题。我们一起来看下Redisson底层原理是怎样的吧：</p><p><a href="https://pic1.zhimg.com/80/v2-d710b0c1f995dcc8b1d00302b14c31ec_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-d710b0c1f995dcc8b1d00302b14c31ec_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>只要线程一加锁成功，就会启动一个<code>watch dog</code>看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了<strong>锁过期释放，业务没执行完</strong>问题。</p><h2 id="12-什么是Redlock算法"><a href="#12-什么是Redlock算法" class="headerlink" title="12. 什么是Redlock算法"></a>12. 什么是Redlock算法</h2><p>Redis一般都是集群部署的，假设数据在主从同步过程，主节点挂了，Redis分布式锁可能会有<strong>哪些问题</strong>呢？一起来看些这个流程图：</p><p><a href="https://pic1.zhimg.com/80/v2-a77bab394f24cbbf9df632bf77503c38_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-a77bab394f24cbbf9df632bf77503c38_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>如果线程一在Redis的master节点上拿到了锁，但是加锁的key还没同步到slave节点。恰好这时，master节点发生故障，一个slave节点就会升级为master节点。线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。</p><p>为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：<strong>Redlock</strong>。Redlock核心思想是这样的：</p><blockquote><p>搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。</p></blockquote><p>我们假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。</p><p><a href="https://pic1.zhimg.com/80/v2-964f4b9c4c2493bba58bce4a029ecdfc_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-964f4b9c4c2493bba58bce4a029ecdfc_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>RedLock的实现步骤:如下</p><blockquote><ul><li>1.获取当前时间，以毫秒为单位。</li><li>2.按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。</li><li>3.客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s&gt; 30ms+40ms+50ms+4m0s+50ms）</li><li>如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。</li><li>如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。</li></ul></blockquote><p>简化下步骤就是：</p><ul><li>按顺序向5个master节点请求加锁</li><li>根据设置的超时时间来判断，是不是要跳过该master节点。</li><li>如果大于等于三个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。</li><li>如果获取锁失败，解锁！</li></ul><h2 id="13-Redis的跳跃表"><a href="#13-Redis的跳跃表" class="headerlink" title="13. Redis的跳跃表"></a>13. Redis的跳跃表</h2><p><a href="https://pic4.zhimg.com/80/v2-62461a985478cdcccee509f1cf41c1d7_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-62461a985478cdcccee509f1cf41c1d7_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>跳跃表</p><ul><li>跳跃表是有序集合zset的底层实现之一</li><li>跳跃表支持平均<strong>O（logN）</strong>,最坏 O（N）复杂度的节点查找，还可以通过顺序性操作批量处理节点。</li><li>跳跃表实现由<strong>zskiplist和zskiplistNode</strong>两个结构组成，其中zskiplist用于保存跳跃表信息（如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。</li><li>跳跃表就是在链表的基础上，增加多级索引提升查找效率。</li></ul><h2 id="14-MySQL与Redis-如何保证双写一致性"><a href="#14-MySQL与Redis-如何保证双写一致性" class="headerlink" title="14. MySQL与Redis 如何保证双写一致性"></a>14. MySQL与Redis 如何保证双写一致性</h2><ul><li>缓存延时双删</li><li>删除缓存重试机制</li><li>读取biglog异步删除缓存</li></ul><h3 id="14-1-延时双删？"><a href="#14-1-延时双删？" class="headerlink" title="14.1 延时双删？"></a>14.1 延时双删？</h3><p>什么是延时双删呢？流程图如下：</p><p><a href="https://pic1.zhimg.com/80/v2-27057a64e8026ca2722fd7f35eb641f4_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-27057a64e8026ca2722fd7f35eb641f4_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>延时双删流程</p><ol><li>先删除缓存</li><li>再更新数据库</li><li>休眠一会（比如1秒），再次删除缓存。</li></ol><p>这个休眠一会，一般多久呢？都是1秒？</p><blockquote><p>这个休眠时间 = 读业务逻辑数据的耗时 + 几百毫秒。为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。</p></blockquote><p>这种方案还算可以，只有休眠那一会（比如就那1秒），可能有脏数据，一般业务也会接受的。但是如果<strong>第二次删除缓存失败</strong>呢？缓存和数据库的数据还是可能不一致，对吧？给Key设置一个自然的expire过期时间，让它自动过期怎样？那业务要接受过期时间内，数据的不一致咯？还是有其他更佳方案呢？</p><h3 id="14-2-删除缓存重试机制"><a href="#14-2-删除缓存重试机制" class="headerlink" title="14.2 删除缓存重试机制"></a>14.2 删除缓存重试机制</h3><p>因为延时双删可能会存在第二步的删除缓存失败，导致的数据不一致问题。可以使用这个方案优化：删除失败就多删除几次呀,保证删除缓存成功就可以了呀~ 所以可以引入删除缓存重试机制</p><p><a href="https://pic4.zhimg.com/80/v2-486ec77baa326fba2bc6e00379038403_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-486ec77baa326fba2bc6e00379038403_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>删除缓存重试流程</p><ol><li>写请求更新数据库</li><li>缓存因为某些原因，删除失败</li><li>把删除失败的key放到消息队列</li><li>消费消息队列的消息，获取要删除的key</li><li>重试删除缓存操作</li></ol><h3 id="14-3-读取biglog异步删除缓存"><a href="#14-3-读取biglog异步删除缓存" class="headerlink" title="14.3 读取biglog异步删除缓存"></a>14.3 读取biglog异步删除缓存</h3><p>重试删除缓存机制还可以吧，就是会造成好多<strong>业务代码入侵</strong>。其实，还可以这样优化：通过数据库的binlog来异步淘汰key。</p><p><a href="https://pic1.zhimg.com/80/v2-71471cee712caebd71981b7db2adc614_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-71471cee712caebd71981b7db2adc614_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>以mysql为例吧</p><ul><li>可以使用阿里的canal将binlog日志采集发送到MQ队列里面</li><li>然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性</li></ul><h2 id="15-为什么Redis-6-0-之后改多线程呢？"><a href="#15-为什么Redis-6-0-之后改多线程呢？" class="headerlink" title="15. 为什么Redis 6.0 之后改多线程呢？"></a>15. 为什么Redis 6.0 之后改多线程呢？</h2><ul><li>Redis6.0之前，Redis在处理客户端的请求时，包括读socket、解析、执行、写socket等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。</li><li>Redis6.0之前为什么一直不使用多线程？使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。</li></ul><p>redis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。</p><p>这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。</p><h2 id="16-聊聊Redis-事务机制"><a href="#16-聊聊Redis-事务机制" class="headerlink" title="16. 聊聊Redis 事务机制"></a>16. 聊聊Redis 事务机制</h2><p>Redis通过<strong>MULTI、EXEC、WATCH</strong>等一组命令集合，来实现事务机制。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p><p>简言之，Redis事务就是<strong>顺序性、一次性、排他性</strong>的执行一个队列中的一系列命令。</p><p>Redis执行事务的流程如下：</p><ul><li>开始事务（MULTI）</li><li>命令入队</li><li>执行事务（EXEC）、撤销事务（DISCARD ）</li></ul><h2 id="17-Redis的Hash-冲突怎么办"><a href="#17-Redis的Hash-冲突怎么办" class="headerlink" title="17. Redis的Hash 冲突怎么办"></a>17. Redis的Hash 冲突怎么办</h2><p>Redis 作为一个K-V的内存数据库，它使用用一张全局的哈希来保存所有的键值对。这张哈希表，有多个哈希桶组成，哈希桶中的entry元素保存了<em>key和</em>value指针，其中<em>key指向了实际的键，</em>value指向了实际的值。</p><p><a href="https://pic2.zhimg.com/80/v2-fcb3bf89f7938eeec3733c1b048206a5_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-fcb3bf89f7938eeec3733c1b048206a5_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>哈希表查找速率很快的，有点类似于Java中的HashMap，它让我们在O(1) 的时间复杂度快速找到键值对。首先通过key计算哈希值，找到对应的哈希桶位置，然后定位到entry，在entry找到对应的数据。</p><p><strong>什么是哈希冲突？</strong></p><blockquote><p>哈希冲突：通过不同的key，计算出一样的哈希值，导致落在同一个哈希桶中。</p></blockquote><p>Redis为了解决哈希冲突，采用了<strong>链式哈希</strong>。链式哈希是指同一个哈希桶中，多个元素用一个链表来保存，它们之间依次用指针连接。</p><p><a href="https://pic3.zhimg.com/80/v2-c402064212da8657a18de78741938d36_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-c402064212da8657a18de78741938d36_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>有些读者可能还会有疑问：哈希冲突链上的元素只能通过指针逐一查找再操作。当往哈希表插入数据很多，冲突也会越多，冲突链表就会越长，那查询效率就会降低了。</p><p>为了保持高效，Redis 会对<strong>哈希表做rehash</strong>操作，也就是增加哈希桶，减少冲突。为了rehash更高效，Redis还默认使用了两个全局哈希表，一个用于当前使用，称为主哈希表，<strong>一个用于扩容，称为备用哈希表</strong>。</p><h2 id="18-在生成-RDB期间，Redis-可以同时处理写请求么？"><a href="#18-在生成-RDB期间，Redis-可以同时处理写请求么？" class="headerlink" title="18. 在生成 RDB期间，Redis 可以同时处理写请求么？"></a>18. 在生成 RDB期间，Redis 可以同时处理写请求么？</h2><p><strong>可以的</strong>，Redis提供两个指令生成RDB，分别是<strong>save和bgsave</strong>。</p><ul><li>如果是save指令，会阻塞，因为是主线程执行的。</li><li>如果是bgsave指令，是fork一个子进程来写入RDB文件的，快照持久化完全交给子进程来处理，父进程则可以继续处理客户端的请求。</li></ul><h2 id="19-Redis底层，使用的什么协议"><a href="#19-Redis底层，使用的什么协议" class="headerlink" title="19. Redis底层，使用的什么协议?"></a>19. Redis底层，使用的什么协议?</h2><p>RESP，英文全称是Redis Serialization Protocol,它是专门为redis设计的一套序列化协议. 这个协议其实在redis的1.2版本时就已经出现了,但是到了redis2.0才最终成为redis通讯协议的标准。</p><p>RESP主要有<strong>实现简单、解析速度快、可读性好</strong>等优点。</p><h2 id="20-布隆过滤器"><a href="#20-布隆过滤器" class="headerlink" title="20. 布隆过滤器"></a>20. 布隆过滤器</h2><p>应对<strong>缓存穿透</strong>问题，我们可以使用<strong>布隆过滤器</strong>。布隆过滤器是什么呢？</p><p>布隆过滤器是一种占用空间很小的数据结构，它由一个很长的二进制向量和一组Hash映射函数组成，它用于检索一个元素是否在一个集合中，空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。</p><p><strong>布隆过滤器原理是？</strong>假设我们有个集合A，A中有n个元素。利用<strong>k个哈希散列</strong>函数，将A中的每个元素<strong>映射</strong>到一个长度为a位的数组B中的不同位置上，这些位置上的二进制数均设置为1。如果待检查的元素，经过这k个哈希散列函数的映射后，发现其k个位置上的二进制数<strong>全部为1</strong>，这个元素很可能属于集合A，反之，<strong>一定不属于集合A</strong>。</p><p>来看个简单例子吧，假设集合A有3个元素，分别为{<strong>d1,d2,d3</strong>}。有1个哈希函数，为<strong>Hash1</strong>。现在将A的每个元素映射到长度为16位数组B。</p><p><a href="https://pic1.zhimg.com/80/v2-27d1b156e14904a16dcee613cabf8258_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-27d1b156e14904a16dcee613cabf8258_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>我们现在把d1映射过来，假设Hash1（d1）= 2，我们就把数组B中，下标为2的格子改成1，如下：</p><p><a href="https://pic4.zhimg.com/80/v2-4c5a3761cd0ac5d3281f28088f966f0b_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-4c5a3761cd0ac5d3281f28088f966f0b_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>我们现在把<strong>d2</strong>也映射过来，假设Hash1（d2）= 5，我们把数组B中，下标为5的格子也改成1，如下：</p><p><a href="https://pic1.zhimg.com/80/v2-5da7bf2fc42359a9403f50609dd8cf64_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-5da7bf2fc42359a9403f50609dd8cf64_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>接着我们把<strong>d3</strong>也映射过来，假设Hash1（d3）也等于 2，它也是把下标为2的格子标1：</p><p><a href="https://pic3.zhimg.com/80/v2-8259602f8017b616bc3530e7081310f2_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-8259602f8017b616bc3530e7081310f2_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>因此，我们要确认一个元素dn是否在集合A里，我们只要算出Hash1（dn）得到的索引下标，只要是0，那就表示这个元素<strong>不在集合A</strong>，如果索引下标是1呢？那该元素<strong>可能</strong>是A中的某一个元素。因为你看，d1和d3得到的下标值，都可能是1，还可能是其他别的数映射的，布隆过滤器是存在这个<strong>缺点</strong>的：会存在<strong>hash碰撞</strong>导致的假阳性，判断存在误差。</p><p>如何<strong>减少这种误差</strong>呢？</p><ul><li>搞多几个哈希函数映射，降低哈希碰撞的概率</li><li>同时增加B数组的bit长度，可以增大hash函数生成的数据的范围，也可以降低哈希碰撞的概率</li></ul><p>我们又增加一个Hash2<strong>哈希映射</strong>函数，假设Hash2（d1）=6,Hash2（d3）=8,它俩不就不冲突了嘛，如下：</p><p><a href="https://pic1.zhimg.com/80/v2-75dd6aaaa9131456a51f09adf27f39f4_720w.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-75dd6aaaa9131456a51f09adf27f39f4_720w.jpg" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p>即使存在误差，我们可以发现，布隆过滤器并<strong>没有存放完整的数据</strong>，它只是运用一系列哈希映射函数计算出位置，然后填充二进制向量。如果<strong>数量很大的话</strong>，布隆过滤器通过极少的错误率，换取了存储空间的极大节省，还是挺划算的。</p><p>目前布隆过滤器已经有相应实现的开源类库啦，如<strong>Google的Guava类库</strong>，Twitter的 Algebird 类库，信手拈来即可，或者基于Redis自带的Bitmaps自行实现设计也是可以的。</p></body></html>]]></content>
    
    <summary type="html">
    
      redis常见面试题
    
    </summary>
    
    
      <category term="Redis" scheme="http://raptor1998.top/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://raptor1998.top/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>mybatis-simple</title>
    <link href="http://raptor1998.top/2022/05/10/mybatis-mini/"/>
    <id>http://raptor1998.top/2022/05/10/mybatis-mini/</id>
    <published>2022-05-09T16:00:00.000Z</published>
    <updated>2022-05-25T03:01:28.534Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="mybatis执行的流程"><a href="#mybatis执行的流程" class="headerlink" title="mybatis执行的流程"></a>mybatis执行的流程</h2><p><a href="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" data-fancybox="group" data-caption="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220525110009.png" class="fancybox"><img alt="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220525110009.png" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220525110009.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload" title="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220525110009.png"></a></p><h2 id="实现一个简单的mybatis思路"><a href="#实现一个简单的mybatis思路" class="headerlink" title="实现一个简单的mybatis思路"></a>实现一个简单的mybatis思路</h2><ol><li>读取xml配置文件的信息</li><li>创建一个SqlSessionFactory，并解析mybatis-config.xml和xxMapper.xml的信息（简化了步骤，直接在解析过程中赋值了）</li><li>将解析的结果封装到一个Configuration中，包括Environment，表示数据库的一些连接信息；<br>和一个Map&lt;String, MapperStatement&gt;，其中key的表示是namespace+id，MapperStatement存储相关的sql信息</li><li>调用openSession方法，其中SqlSession中包括前面解析的配置类和一个执行器Executor。</li><li>Executor可以通过DataSource进行数据库交互</li><li>获取mapper的代理类</li><li>调用查询方法，最终会调用Executor的方法，Executor的到参数，并获取响应的MapperStatement，执行完成之后，根据返回类型，使用反射将结果封装成响应的类型</li></ol><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p><a href="https://github.com/Raptor1998" target="_blank" rel="noopener">Raptor1998</a>/<strong><a href="https://github.com/Raptor1998/mybatis-mini" target="_blank" rel="noopener">mybatis-mini</a></strong></p></body></html>]]></content>
    
    <summary type="html">
    
      
      
        &lt;html&gt;&lt;head&gt;&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer
      
    
    </summary>
    
    
      <category term="mybatis" scheme="http://raptor1998.top/categories/mybatis/"/>
    
    
      <category term="mybatis" scheme="http://raptor1998.top/tags/mybatis/"/>
    
  </entry>
  
  <entry>
    <title>Spring Transaction</title>
    <link href="http://raptor1998.top/2022/05/03/spring%20transaction/"/>
    <id>http://raptor1998.top/2022/05/03/spring%20transaction/</id>
    <published>2022-05-02T16:00:00.000Z</published>
    <updated>2022-08-15T12:40:43.655Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script></head><body><h1 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h1><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220505094129.png" data-fancybox="group" data-caption="img.png" class="fancybox"><img alt="img.png" title="img.png" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220505094129.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h2 id="什么是事务"><a href="#什么是事务" class="headerlink" title="什么是事务"></a>什么是事务</h2><p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p><p>事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作就是：将小明的余额减少 1000 元，将小红的余额增加 1000 元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。</p><h2 id="事务的ACID"><a href="#事务的ACID" class="headerlink" title="事务的ACID"></a>事务的<code>ACID</code></h2><ol><li>原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li><li>一致性： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</li><li>隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li><li>持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li></ol><h2 id="JDBC中手动事务的实现"><a href="#JDBC中手动事务的实现" class="headerlink" title="JDBC中手动事务的实现"></a><code>JDBC</code>中手动事务的实现</h2><h3 id="基础版本"><a href="#基础版本" class="headerlink" title="基础版本"></a>基础版本</h3><p>手动获取数据源的连接，将提交方式设置为手动，出现异常手动回滚。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">JdbcTemplate jdbcTemplate;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">DataSource dataSource;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="comment">//@Transactional(rollbackFor = Exception.class)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line"></span><br><span class="line">    Connection connection = dataSource.getConnection();</span><br><span class="line">    connection.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line">    Statement statement = connection.createStatement();</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        String s = UUID.randomUUID().toString().substring(<span class="number">0</span>, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//配合spring事务</span></span><br><span class="line">        <span class="comment">//jdbcTemplate.execute("insert into user(nickname) values('" + s + "')");</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//手动控制</span></span><br><span class="line">        statement.execute(<span class="string">"insert into user(nickname) values('"</span> + s + <span class="string">"')"</span>);</span><br><span class="line">        <span class="comment">//int a = 12 / 0;</span></span><br><span class="line"></span><br><span class="line">        connection.commit();</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        System.out.println(<span class="string">"异常"</span>+e.getMessage());</span><br><span class="line">        connection.rollback();</span><br><span class="line">    }<span class="keyword">finally</span> {</span><br><span class="line">        <span class="comment">//关闭是放回连接池还是关闭java和mysql的连接</span></span><br><span class="line">        <span class="comment">//不一定，连接池不同，可能不同，一般是放回连接池</span></span><br><span class="line">        connection.close();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p>将<code>JDBCTemplate</code>抽离出来,将无用的操作封装到<code>MyJDBCTemplate</code>中，<code>serveice</code>中只关心业务逻辑</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line"></span><br><span class="line">    Connection connection = dataSource.getConnection();</span><br><span class="line">    connection.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line">    Statement statement = connection.createStatement();</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        statement.execute(sql);</span><br><span class="line">        connection.commit();</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        System.out.println(<span class="string">"异常"</span> + e.getMessage());</span><br><span class="line">        connection.rollback();</span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        <span class="comment">//关闭是放回连接池还是关闭java和mysql的连接</span></span><br><span class="line">        <span class="comment">//不一定，连接池不同，可能不同，一般是放回连接池</span></span><br><span class="line">        connection.close();</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line">        myJdbcTemplate.execute(<span class="string">"insert into user(nickname) values('"</span> + UUID.randomUUID().toString().substring(<span class="number">0</span>, <span class="number">5</span>) + <span class="string">"')"</span>);</span><br><span class="line">        myJdbcTemplate.execute(<span class="string">"insert into user(nickname) values('"</span> + UUID.randomUUID().toString().substring(<span class="number">0</span>, <span class="number">5</span>) + <span class="string">"')"</span>);</span><br><span class="line">        <span class="comment">//int a = 10 / 0;</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h3 id="QA——两条sql语句如何保证在一个连接内"><a href="#QA——两条sql语句如何保证在一个连接内" class="headerlink" title="QA——两条sql语句如何保证在一个连接内"></a>QA——两条<code>sql</code>语句如何保证在一个连接内</h3><h4 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a><code>ThreadLocal</code></h4><p><a href="面试官：小伙子，听说你看过ThreadLocal源码？（万字图文深度解析ThreadLocal）">面试官：小伙子，听说你看过ThreadLocal源码？（万字图文深度解析ThreadLocal）</a></p><h3 id="通过事务管理"><a href="#通过事务管理" class="headerlink" title="通过事务管理"></a>通过事务管理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">DataSource dataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">//保证在一个线程中拿到的连接时同一个连接</span></span><br><span class="line">ThreadLocal&lt;Connection&gt; connectionThreadLocal = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line">    <span class="keyword">if</span> (connectionThreadLocal.get() != <span class="keyword">null</span>) {</span><br><span class="line">        <span class="keyword">return</span> connectionThreadLocal.get();</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        connectionThreadLocal.set(dataSource.getConnection());</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> connectionThreadLocal.get();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">MyTransactionManager myTransactionManager;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line">    Connection connection = myTransactionManager.getConnection();</span><br><span class="line">    Statement statement = connection.createStatement();</span><br><span class="line">    statement.execute(sql);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h2 id="通过aop实现一个简单的事务回滚"><a href="#通过aop实现一个简单的事务回滚" class="headerlink" title="通过aop实现一个简单的事务回滚"></a>通过aop实现一个简单的事务回滚</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">MyTransactionManager transactionManager;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Around</span>(<span class="string">"@annotation(MyTransaction)"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">doTransaction</span><span class="params">(ProceedingJoinPoint proceedingJoinPoint)</span> <span class="keyword">throws</span> Throwable </span>{</span><br><span class="line">    Connection connection = transactionManager.getConnection();</span><br><span class="line">    connection.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line">    System.out.println(<span class="string">"事务开始"</span>);</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        Object proceed = proceedingJoinPoint.proceed();</span><br><span class="line">        connection.commit();</span><br><span class="line">        System.out.println(<span class="string">"事务提交"</span>);</span><br><span class="line">        <span class="keyword">return</span> proceed;</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        System.out.println(<span class="string">"事务回滚"</span>);</span><br><span class="line">        connection.rollback();</span><br><span class="line">    } <span class="keyword">finally</span> {</span><br><span class="line">        connection.close();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div><h2 id="事务传播行为"><a href="#事务传播行为" class="headerlink" title="事务传播行为"></a>事务传播行为</h2><h3 id="Propagation-REQUIRED（默认）"><a href="#Propagation-REQUIRED（默认）" class="headerlink" title="Propagation.REQUIRED（默认）"></a>Propagation.REQUIRED（默认）</h3><p><strong>如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。</strong></p><p>  1. 父方法和子方法都开启事务，异常发生让子事务回滚，父事务一定回滚(子事务没将父事务挂起的情况下)，不管是否被try-catch包裹。<br>  2. 只要try-catch在内层，@Transactional在外层，异常被try-catch住，事务就不会回滚。<br>          3. 但是如果@Transactional在内层，try-catch在外层，那try-catch还没来得及处理异常就在@Transactional注解作用下回滚了</p><h3 id="Propagation-SUPPORTS"><a href="#Propagation-SUPPORTS" class="headerlink" title="Propagation.SUPPORTS"></a>Propagation.SUPPORTS</h3><p><strong>如果当前有事务，则使用事务，如果当前没有事务，就以非事务方式执行</strong></p><h3 id="Propagation-MANDATORY"><a href="#Propagation-MANDATORY" class="headerlink" title="Propagation.MANDATORY"></a>Propagation.MANDATORY</h3><p><strong>支持当前的事务，如果当前没有事务，就抛出异常。</strong></p><h3 id="Propagation-REQUIRES-NEW"><a href="#Propagation-REQUIRES-NEW" class="headerlink" title="Propagation.REQUIRES_NEW"></a>Propagation.REQUIRES_NEW</h3><p><strong>新建事务，如果当前存在事务，把当前事务挂起。</strong></p><h3 id="Propagation-NOT-SUPPORTED"><a href="#Propagation-NOT-SUPPORTED" class="headerlink" title="Propagation.NOT_SUPPORTED"></a>Propagation.NOT_SUPPORTED</h3><p><strong>以非事务方式执行操作，如果当前存在事务，就把当前事务挂起</strong></p><h3 id="Propagation-NEVER"><a href="#Propagation-NEVER" class="headerlink" title="Propagation.NEVER"></a>Propagation.NEVER</h3><p><strong>以非事务方式执行，如果当前存在事务，则抛出异常。与<code>Propagation.MANDATORY</code>正好相反。</strong></p><h3 id="Propagation-NESTED"><a href="#Propagation-NESTED" class="headerlink" title="Propagation.NESTED"></a>Propagation.NESTED</h3><p><strong>如果当前有事务，则开启子事务（嵌套事务），嵌套事务是独立提交或者回滚，如果当前没有事务，就新建事务运行。</strong></p><p><strong>运行结果和原因与<code>Propagation.REQUIRED</code>一模一样。几乎没区别，这种情况用得少。</strong></p><h2 id="如何让下一个方法获取当前是否已经存在事务"><a href="#如何让下一个方法获取当前是否已经存在事务" class="headerlink" title="如何让下一个方法获取当前是否已经存在事务"></a>如何让下一个方法获取当前是否已经存在事务</h2><p>当事务开启之后，将值设置为true，此时便可以获取当前是否存在事务</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocal&lt;Boolean&gt; hasTransaction = <span class="keyword">new</span> ThreadLocal();</span><br></pre></td></tr></tbody></table></figure></div><h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p><a href="https://blog.csdn.net/qq_34115899/article/details/115602002" target="_blank" rel="noopener">事务的7种传播行为</a></p><h2 id="代码地址"><a href="#代码地址" class="headerlink" title="代码地址"></a>代码地址</h2><p><a href="https://github.com/Raptor1998" target="_blank" rel="noopener">Raptor1998</a>/<strong><a href="https://github.com/Raptor1998/spring-transaction" target="_blank" rel="noopener">spring-transaction</a></strong></p></body></html>]]></content>
    
    <summary type="html">
    
      
      
        &lt;html&gt;&lt;head&gt;&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer
      
    
    </summary>
    
    
      <category term="Spring" scheme="http://raptor1998.top/categories/Spring/"/>
    
    
      <category term="Spring" scheme="http://raptor1998.top/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Spring Bean</title>
    <link href="http://raptor1998.top/2022/04/26/spring%20bean/"/>
    <id>http://raptor1998.top/2022/04/26/spring%20bean/</id>
    <published>2022-04-25T16:00:00.000Z</published>
    <updated>2022-05-11T09:37:21.759Z</updated>
    
    <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="Spring-中-bean"><a href="#Spring-中-bean" class="headerlink" title="Spring 中 bean"></a>Spring 中 bean</h1><h2 id="Scope"><a href="#Scope" class="headerlink" title="Scope"></a>Scope</h2><p><strong>Spring 的 bean 作用域（scope）：</strong></p><ul><li>singleton:单例，默认作用域。</li><li>prototype:原型，每次创建一个新对象。</li><li>request:请求，每次Http请求创建一个新对象，适用于WebApplicationContext环境下。</li><li>session:会话，同一个会话共享一个实例，不同会话使用不用的实例。</li><li>global-session:全局会话，所有会话共享一个实例。</li></ul><h2 id="线程安全问题"><a href="#线程安全问题" class="headerlink" title="线程安全问题"></a>线程安全问题</h2><h3 id="单例Bean"><a href="#单例Bean" class="headerlink" title="单例Bean"></a><strong>单例Bean</strong></h3><p>对于单例Bean,所有线程都共享一个单例实例Bean，因此是存在资源的竞争。如果单例Bean是一个<strong>无状态Bean</strong>（<strong>有状态就是有数据存储功能，无状态就是不会保存数据</strong>），也就是线程中的操作不会对Bean的成员执行查询以外的操作，那么这个单例Bean是线程安全的。比如Spring mvc 的 Controller、Service、Dao等，这些Bean大多是无状态的，只关注于方法本身。</p><p><strong>spring单例，为什么controller、service和dao确能保证线程安全？</strong></p><p>Spring中的Bean默认是单例模式的，框架并没有对bean进行多线程的封装处理。<br>实际上大部分时间Bean是无状态的（比如Dao） 所以说在某种程度上来说Bean其实是安全的。</p><ol><li>在@Controller/@Service等容器中，默认情况下，scope值是单例-singleton的，也是线程不安全的。</li><li>尽量不要在@Controller/@Service等容器中定义静态变量，不论是单例(singleton)还是多实例(prototype)他都是线程不安全的。</li><li>默认注入的Bean对象，在不设置scope的时候他也是线程不安全的。</li><li>一定要定义变量的话，用ThreadLocal来封装，这个是线程安全的</li></ol><h3 id="原型Bean"><a href="#原型Bean" class="headerlink" title="原型Bean"></a><strong>原型Bean</strong></h3><p>对于原型Bean,每次创建一个新对象，也就是线程之间并不存在Bean共享，自然是不会有线程安全的问题。</p><h1 id="bean的循环依赖"><a href="#bean的循环依赖" class="headerlink" title="bean的循环依赖"></a>bean的循环依赖</h1><h2 id="三级缓存"><a href="#三级缓存" class="headerlink" title="三级缓存"></a>三级缓存</h2><h3 id="singletonObjects"><a href="#singletonObjects" class="headerlink" title="singletonObjects"></a>singletonObjects</h3><p>完成初始化的单例对象的 cache，这里的 bean 经历过 实例化-&gt;属性填充-&gt;初始化 以及各种后置处理（一级缓存）。</p><h3 id="earlySingletonObjects"><a href="#earlySingletonObjects" class="headerlink" title="earlySingletonObjects"></a>earlySingletonObjects</h3><p>存放原始的 bean 对象（完成实例化但是尚未填充属性和初始化），仅仅能作为指针提前曝光，被其他 bean 所引用，用于解决循环依赖的 （二级缓存）。</p><h3 id="singletonFactories"><a href="#singletonFactories" class="headerlink" title="singletonFactories"></a>singletonFactories</h3><p>在 bean 实例化完之后，属性填充以及初始化之前，如果允许提前曝光，Spring 会将实例化后的 bean 提前曝光，也就是把该 bean 转换成 beanFactory 并加入到 singletonFactories（三级缓存）。</p><h2 id="创建bean"><a href="#创建bean" class="headerlink" title="创建bean"></a>创建bean</h2><ol><li>实例化Bean：通过反射调用构造方法实例化对象。</li><li>依赖注入：装配Bean的属性</li><li>实现了Aware接口的Bean，执行接口方法：如顺序执行BeanNameAware、BeanFactoryAware、 ApplicationContextAware的接口方法。</li><li>Bean对象初始化前，循环调用实现了BeanPostProcessor接口的预初始化方法 （postProcessBeforeInitialization）</li><li>Bean对象初始化：顺序执行@PostConstruct注解方法、InitializingBean接口方法、init-method方法</li><li>Bean对象初始化后，循环调用实现了BeanPostProcessor接口的后初始化方法 （postProcessAfterInitialization）</li><li>容器关闭时，执行Bean对象的销毁方法，顺序是：@PreDestroy注解方法、DisposableBean接口方法、destroy-method</li></ol><h3 id="bean创建过程"><a href="#bean创建过程" class="headerlink" title="bean创建过程"></a>bean创建过程</h3><p>getBean-&gt;实例化-&gt;属性填充-&gt;初始化（自行bean的初始化方法，如afterPropertiesSet）</p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171132.png" data-fancybox="group" data-caption="image-20220426163422045" class="fancybox"><img alt="image-20220426163422045" title="image-20220426163422045" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171132.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="循环依赖"><a href="#循环依赖" class="headerlink" title="循环依赖"></a>循环依赖</h3><h4 id="问题出现"><a href="#问题出现" class="headerlink" title="问题出现"></a>问题出现</h4><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171154.png" data-fancybox="group" data-caption="image-20220426163511580" class="fancybox"><img alt="image-20220426163511580" title="image-20220426163511580" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171154.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h4 id="半成品提前暴露"><a href="#半成品提前暴露" class="headerlink" title="半成品提前暴露"></a>半成品提前暴露</h4><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171200.png" data-fancybox="group" data-caption="image-20220426163608653" class="fancybox"><img alt="image-20220426163608653" title="image-20220426163608653" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171200.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><strong>当b需要a 的时候，去单例池中寻找a，没找到；去半成品池中寻找a，找到以后赋值并将b放入单例池；然后将b赋值给a，并将半成品池中的a移除</strong></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171208.png" data-fancybox="group" data-caption="image-20220426163827610" class="fancybox"><img alt="image-20220426163827610" title="image-20220426163827610" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171208.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><p><strong>二级缓存就解决了循环依赖问题，为什么还需要三级缓存？</strong></p><p><strong>解决aop引用问题，当对象有aop增强的时候，a引用的是b的代理对象，而不是b的原始对象，b同理，需要a的代理对象。此时b再去半成品池去取对象，取得是a的原始对象，而不是代理对象。</strong></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171219.png" data-fancybox="group" data-caption="image-20220426164008035" class="fancybox"><img alt="image-20220426164008035" title="image-20220426164008035" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171219.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h3 id="aop的代理实现"><a href="#aop的代理实现" class="headerlink" title="aop的代理实现"></a>aop的代理实现</h3><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171222.png" data-fancybox="group" data-caption="image-20220426162945335" class="fancybox"><img alt="image-20220426162945335" title="image-20220426162945335" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171222.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><strong>aop是初始化的后置处理中进行增强，如上图所示，bean的后置处理器中有一个aop处理器，有两个入口，一个事postProcessAfterInitialization（后置处理）和getEarlyBEanReference（提前处理）</strong></p><h3 id="添加工厂池"><a href="#添加工厂池" class="headerlink" title="添加工厂池"></a>添加工厂池</h3><p><strong>对象初始化完成之后，进行后置处理，当b对a有提前引用的时候，执行factory(a)，从而创建a的动态代理，并且将a的代理放到半成品池中，将a的半成品填充到b的属性中去，然后执行b的后置处理，将b放到单例池中去，（在执行createBeanInstance(“b”)的时候，也会去工厂池创建factory(b)，不过在创建b的过程中，没有人提前引用b，所以工厂池中的对象会被移除）</strong></p><p><strong>当a获取到b的代理对象之后，没必要在执行后置处理，而是直接从半成品池中的a移动到单例池中去，并且移除工厂池中的a</strong></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171231.png" data-fancybox="group" data-caption="image-20220426164937768" class="fancybox"><img alt="image-20220426164937768" title="image-20220426164937768" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171231.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171241.png" data-fancybox="group" data-caption="image-20220426165309219" class="fancybox"><img alt="image-20220426165309219" title="image-20220426165309219" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171241.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171250.png" data-fancybox="group" data-caption="image-20220426165805873" class="fancybox"><img alt="image-20220426165805873" title="image-20220426165805873" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171250.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><p><a href="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171259.png" data-fancybox="group" data-caption="image-20220426165736641" class="fancybox"><img alt="image-20220426165736641" title="image-20220426165736641" data-src="https://cdn.jsdelivr.net/gh/Raptor1998/imghouse/untidy/20220426171259.png" src="https://cdn.jsdelivr.net/gh/raptor1998/imghouse/raptor1998_img/loading.gif" class="lazyload"></a></p><h1 id="分别用一二三级缓存解决循环依赖的方案"><a href="#分别用一二三级缓存解决循环依赖的方案" class="headerlink" title="分别用一二三级缓存解决循环依赖的方案"></a>分别用一二三级缓存解决循环依赖的方案</h1><h2 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h2><h3 id="不考虑aop使用—级缓存解决循环依赖"><a href="#不考虑aop使用—级缓存解决循环依赖" class="headerlink" title="不考虑aop使用—级缓存解决循环依赖"></a>不考虑aop使用—级缓存解决循环依赖</h3><ol><li>创建A对象,放到缓存中，这时候为A对象注入属性</li><li>创建B放到缓存，从缓存中获得A对象，将B对象返回给A对象(这时候如果不考虑aop 一级缓存就可以解决循环依赖的问题了)</li></ol><h3 id="考虑aop时-一级缓存无法解决循环依赖的问题"><a href="#考虑aop时-一级缓存无法解决循环依赖的问题" class="headerlink" title="考虑aop时,一级缓存无法解决循环依赖的问题"></a>考虑aop时,一级缓存无法解决循环依赖的问题</h3><p> 因为初始化操作必须放在aop代理之前, 否则导致初始化的时候无法改变代理对象的属性值，假设A和B对象互相引用，且A和B对象都使用aop进行了增强，则按照上面的逻辑，A对象放到缓存后，需要注入B对象,而缓存中没有B对象，则需要去创建B对象，这时候B对象可以从缓存中获得A对象，而B对象拿到的是没有进行aop增强的A对象，这时候就算把初始化B对象和为B对象生成aop代理的业务逻辑放在这，也只能保证A对象获得的是aop代理过的B对象，而B对象中的A对象是没有经过aop增强的，且经过jdk/cglib动态代理后对象的属性值是没有办法改变的，这时候为A生成aop增强过的对象也无法替换B对象中的A对象，所以一级缓存无法解决。</p><h2 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h2><p>二级缓存可以解决循环依赖，并且也可以解决循环依赖中的依赖对象被aop代理问题</p><p>就是普通对象初始化完成后，然后走到 getSingleton方法通过三级缓存创建对象,<br>假设A和B循环依赖,并且A和B都通过aop增强，假设先创建A，则当为A中注入B时，发现B没有，就会去创建B，如果使用二级缓存，这时候直接通过对象工厂创建A的aop对象<br>，放在一级缓存中，相当于A对象创建好了，这时候创建好B对象后，返回继续创建A对象，这时候按顺序，A的属性注入后该进行初始化A对象了，但这时候在创建B时已经把A对象放到一级缓存中了，这时候如果另一个线程来获取就会获得还没有完全初始化的<br>A对象（框架是单线程加载的，当框架加载好所有对象都创建好了，因该不会出现不安<br>全发布的情况），这时候也就会出现违背Spring创建对象的原则，即在对象没有完全初始化的时候就出现在了一级缓存中，Spring创建对象的原则是在对象被完全初始化后才能被放到缓存中，被外界获取。</p><h2 id="三级缓存-1"><a href="#三级缓存-1" class="headerlink" title="三级缓存"></a>三级缓存</h2><p><strong>A 假设和 B 相互引用，且都被 aop 增强</strong> </p><ol><li>A 对象先封装一个回调函数到三级循环中，这个接口里封装的是 aop 使用 bean 来创建 aop 代理类的方法</li><li>这时候如果为 A 对象中有 B 类的属性，需要把 B 注入到 A 中</li><li>这时候没有创建 B 类的对象，就去创建，也是封装一个回调函数到三级缓存中 </li><li>这时候需要往 B中注入 A ，发现 A 在三级循环中，这时候会调用回调函数的 getObject 方法获得 aop 增强过的 A 对象，放入二级缓存中，因为 A 对象没有初始化完成，这个对象是不完整的，其实也可直接放使用二级缓存来解决循环依赖 </li><li>但是用二级缓存的话会破坏 spring 创建对象的原则，一级缓存存放的是已经<br>初始化过的完整的对象，二级三级都是半成品， Spring 更喜欢把所有的普通 Bean 都初始化完成，再处理代理对象的初始化。</li></ol><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a href="https://blog.csdn.net/smilehappiness/article/details/119712824" target="_blank" rel="noopener">Spring框架中的单例bean是线程安全的吗?</a></p><p><a href="https://baijiahao.baidu.com/s?id=1677105782547823661&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">循环依赖问题</a></p><p><a href="https://blog.csdn.net/qq_39552268/article/details/122502988" target="_blank" rel="noopener">分别用一二三级缓存解决循环依赖的方案</a></p><p><a href="https://www.bilibili.com/video/BV1ET4y1N7Sp?spm_id_from=333.337.search-card.all.click" target="_blank" rel="noopener">第二次讲Spring循环依赖，时长16分钟，我保证每一秒都是精华</a></p></body></html>]]></content>
    
    <summary type="html">
    
      
      
        &lt;html&gt;&lt;head&gt;&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer
      
    
    </summary>
    
    
      <category term="Spring" scheme="http://raptor1998.top/categories/Spring/"/>
    
    
      <category term="Spring" scheme="http://raptor1998.top/tags/Spring/"/>
    
  </entry>
  
</feed>
